//
// The ConfigOptions.asciidoc is a specially formatted file that is parsed during the build process
// to generate the ConfigOptions.h header file, services JSON config files, and user documentation.
// Changing the default values in this file will change the way Hootenanny runs so be careful, this
// isn't just documentation.
//
// This file is also parsed by asciidoc to generate the user documentation. Look at that; our docs
// and code are in lock step! Nice. Please keep this in mind when writing documentation. This isn't
// just comments, this is user documentation. Try to include the following information in the
// description:
//
// * What does this configuration change?
// * If relevant, what are the units of the config option (e.g. meters)?
// * Where can the user go to get more information? Please reference the appropriate document. E.g.
//   "See `convert` in the _Command Line Reference_ for more information."
// * What other options may be of interest? E.g. "See also `big.perty.op.sigma`"
// * Please keep the list in Alphabetical order.
//
// The format is as follows:
//
// The section name is all lowercase and separated by periods. This shouldn't contain any special
// characters.
// === key.name
//
// * Data Type: <string, double, list, bool, int, long>
// * Default Value: <value>
//
// If the default value is for a list then the default value should be followed by a number of sub
// items in the list. E.g.
// * Default Value:
// ** `<Value 1>`
// ** `<Value 2>`
// The left ticks provide proper formatting in the documentation.
//
// Note that list entries may not contain the ';' character.
//
// Finally the section that contains the documentation. This is free-form
// asciidoc just make sure you don't start any lines with "=== ".
// http://www.methods.co.nz/asciidoc/
//
=== add.attributes.visitor.add.only.if.empty

* Data Type: bool
* Default Value: `false`

If true and an element already has a non-empty attribute (attribute without a default value) with
the same key as one specified in `add.attributes.visitor.kvps`, then the `AddAttributesVisitor` will
not add the attribute.  If false, then `AddAttributesVisitor` will add the attribute to the element
regardless.

=== add.attributes.visitor.chain.element.criteria

* Data Type: bool
* Default Value: `false`

If set to true and multiple criterion are specified in `add.attributes.visitor.element.criteria`,
the attributes of elements will be modified only if they satisfy all of the criteria. If set to
false, then only one of the specified criteria must be met in order to modify the attributes of an
element.

=== add.attributes.visitor.element.criteria

* Data Type: list
* Default Value: ``

One or more element criteria used for selecting elements whose attributes to modify. Delimit names
with '='. E.g. "TagCriterion;ReviewRelationCriterion"

=== add.attributes.visitor.kvps

* Data Type: list
* Default Value:
** ``

List of element attribute key/value pairs to add with the `AddAttributesVisitor` of the form
key=value. `AddAttributesVisitor` is generally used to repair a corrupted OSM output, as the
attributes are normally added to the output automatically.  Valid key values are: 'changeset',
'timestamp', 'user', 'uid', or 'version'.

=== add.ref.visitor.information.only

* Data Type: bool
* Default Value: `true`

Typically REF1/2 values are only applied to elements with informational tags (e.g. `name=foo`),
however setting this to false will apply REF1/2 values to all elements.

=== add.ref1.visitor.prefix

* Data Type: string
* Default Value: ``

Prefix to apply to REF1 values. REF1 values are typically used when training a model. See the
Developer Documentation for details.

=== add.review.tags.to.features

* Data Type: bool
* Default Value: `false`

If true, not only will review relations receive the `hoot:review:needs` tag, the features involved
in the review will receive them as well.

=== add.uuid.visitor.key

* Data Type: string
* Default Value: `uuid`

Tag key used by `AddUuidVisitor` for adding custom unique ID's to data.

=== address.allow.lenient.house.number.matching

* Data Type: bool
* Default Value: `true`

If true, conflation that uses address matching will allow house number subletter mismatches for the
addresses with the same house number. e.g. when enabled, "23a Elm Street" matches "23 Elm Street"

=== address.match.enabled

* Data Type: bool
* Default Value: `true`

If disabled, conflators that support address matching will not match addresses. If the data being
conflated is known to have poor address data, disabling this option may speed up conflation runtime
performance. Address matching also incurs a small initial startup time (~5s) per conflate job, as
well as the loading of a fairly large amount of address data.

=== address.scorer.enable.caching

* Data Type: bool
* Default Value: `true`

Allows address comparison to score addresses parsed from elements. This is generally only to be
turned off when running certain unit tests which are incompatible with it being enabled.

=== address.street.types

* Data Type: list
* Default Value:
** `highway=crossing`
** `avenue=ave`
** `boulevard=blvd`
** `circle=cir`
** `freeway=fwy`
** `highway=hwy`
** `lane=ln`
** `place=pl`
** `plaza=plz`
** `road=rd`
** `street=st`
** `tollway=twy`

Maps street types to their abbreviations. The token before '=' is the street type. Abbreviations
follow after the '='.

=== address.string.comparer

* Data Type: string
* Default Value: `ExactStringDistance`

String comparison algorithm to use for address comparison during conflation. Must be an
implementation of `StringDistance`.

=== address.tag.keys

* Data Type: list
* Default Value:
** `full_address=address,addr:full,ref:addr,source:addr,source:address`
** `house_number=addr:conscriptionnumber,addr:door,addr:housenumber,addr:provisionalnumber,addr:street:sym_ul,addr:streetnumber,addr:housename`
** `street=addr:street,addr:street:name`
** `street_prefix=addr:street:prefix`
** `street_suffix=addr:street:suffix,addr:street:type`

Maps a set of address components to OSM address tag keys. The token  before '=' is the address
component type. Mapped tag keys follow after the '=' and are delimited with ','.

=== address.translate.to.english

* Data Type: bool
* Default Value: `false`

If true, Hootenanny will attempt to translate to English the value of any tag that is part of an
address before normalizing it during conflation address matching (note that address normalization
may involve some form of language translation even when this setting is disabled). This can have
significant impact on the runtime performance of conflation when enabled and should only be enabled
if the source data is known to have non-English addresses. The configuration option,
`language.translation.translator`, controls which translator is used.

=== address.use.default.language.translation.only

* Data Type: bool
* Default Value: `true`

If true, conflation using address matching will use only libpostal for translating languages in
addresses, which occurs during address normalization.  If false, and `address.translate.to.english`
is enabled, POI/Polygon conflation will use additional to English language translation before
address normalization.  Disable this only if libpostal's language translation is not adequate for
your language translation needs.

=== angle.histogram.extractor.bins

* Data Type: int
* Default Value: `16`

The number of data bins used by `AngleHistogramExtractor` and `SampledAngleHistogramExtractor`.

=== angle.histogram.extractor.smoothing

* Data Type: double
* Default Value: `0.0`

Smoothing value in radians used by `AngleHistogramExtractor` and `SampledAngleHistogramExtractor`.

=== api.db.email

* Data Type: string
* Default Value: ``

Email address of the API database user. Can be set here for debugging and testing.

=== apidb.bulk.inserter.output.files.copy.location

* Data Type: string
* Default Value: ``

Use this option if you wish to retain the file data generated during an OSM/Hootenanny API database
write.  This option is not needed and will be ignored if writing OSM data to a SQL file that will be
applied/written to an OSM API database at a later time.  If this option is populated, any file data
files generated as a result of executing the hoot convert command with an OSM API database target
are copied to the specified location.  This option should be set to a full file path to a SQL
file (.sql).

=== apidb.bulk.inserter.run.validation.in.memory

* Data Type: bool
* Default Value: `false`

When set to true, this bypasses STXXL disk writing completely when performing data validation, is
equivalent to `apidb.bulk.inserter.validate.data=true` and
`apidb.bulk.inserter.stxxl.map.min.size=<infinity>`, and overrides values passed in for those
settings.  If the system does not have enough memory to support in memory validation of the loaded
features, an out of memory error will occur.

=== apidb.bulk.inserter.starting.node.id

* Data Type: long
* Default Value: `1`

First record ID to assign to written nodes when writing to an OSM/Hootenanny API database or SQL
file.  Must be a positive number.  Use this when working with an offline database and know the
ID range you want to assign to node records.  If writing to an OSM API databse, this option is
ignored if `osmapidb.bulk.inserter.reserve.record.ids.before.writing.data` is set to true.

=== apidb.bulk.inserter.starting.way.id

* Data Type: long
* Default Value: `1`

First record ID to assign to written ways when writing to an OSM/Hootenanny API database or SQL
file. Must be a positive number.  Use this when working with an offline database and know the ID
range you want to assign to way records.  If writing to an OSM API databse, this option is ignored
if `osmapidb.bulk.inserter.reserve.record.ids.before.writing.data` is set to true.

=== apidb.bulk.inserter.starting.relation.id

* Data Type: long
* Default Value: `1`

First record ID to assign to written relations when writing to an OSM/Hootenanny API database or
SQL file.  Must be a positive number.  Use this when working with an offline database and know the
ID range you want to assign to relation records.  If writing to an OSM API database, this option is
ignored if `osmapidb.bulk.inserter.reserve.record.ids.before.writing.data` is set to true.

=== apidb.bulk.inserter.stxxl.map.min.size

* Data Type: long
* Default Value: `10000000`

Size at which the ID mappings storage for the OSM/Hootenanny API database bulk inserter switches
from a `std::map` to an `stxxl::map`, which is a container optimized for very large amounts of data.
For debugging purposes only.

=== apidb.bulk.inserter.temp.file.dir

* Data Type: string
* Default Value: `/tmp`

Allows for customizing where the OSM/Hootenanny API database bulk inserter stores temp files.

=== apidb.bulk.inserter.validate.data

* Data Type: bool
* Default Value: `false`

If true, the OSM/Hootenanny API database bulk inserter will renumber element IDs, check for
duplicated element IDs, check for invalid way node references, and check for invalid relation member
references. Only duplicate element IDs and invalid way node references will cause a failure.
Invalid relation members will cause a warning to be logged. You should enable this setting if you
are loading data that has not been previously validated in another OSM API database.  Enabling this
setting may cause writing to an OSM API database to occur more slowly.

=== apidb.bulk.inserter.use.source.version

* Data Type: bool
* Default Value: `false`

If true, the OSM/Hootenanny API database bulk inserter will use the version number provided in the
source data for all elements.  For most purposes using the supplied version is desired but in some
testing cases defaulting all versions to `1` simplifies tests and is therefore more desirable.

=== apidb.reader.read.full.then.crop.on.bounded

* Data Type: bool
* Default Value: `false`

This changes the behavior for reads from API databases over a bounds using the `bounds` option to
read in the full dataset and crop the data after the reading is complete instead of cropping the
input as part of the query. This is more inefficient for memory consumption but can be faster
overall for significantly large datasets, as the cropped database query performs slowly at larger
input sizes.

=== area.overlap.review.threshold

* Data Type: double
* Default Value: `0.835`

Areas that do not match and have a percentage overlap at or above this value will be marked for
review.

=== area.type.threshold

* Data Type: double
* Default Value: `0.8`

Tag similarity threshold (0.0 to 1.0) at or above which an area feature is considered to have
similar tags during matching.

=== area.type.overlap.review.threshold

* Data Type: double
* Default Value: `0.9`

Tag similarity threshold (0.0 to 1.0) at or above which an area feature is considered to have
similar tags when determining overlap reviews.

=== arff.writer.precision

* Data Type: int
* Default Value: `17`

The precision of numeric values written to Attribute-Relation (.arff) files.

=== attribute.conflation.aggressive.highway.joining

* Data Type: bool
* Default Value: `false`

If true, allows Attribute Conflation to more aggressively rejoin ways with names and specific
highway attribution into those with less specific highway attribution and no names.  Enabling this
option may result in some false positive road joining.

=== attribute.conflation.allow.ref.geometry.changes.for.bridges

* Data Type: bool
* Default Value: `true`

If true, allows Attribute Conflation to modify the geometry of a reference road layer to accommodate
bridge features.  If false, any bridge features represented in the secondary dataset, but not in the
reference dataset will be lost.

=== attribute.conflation.allow.reviews.by.score

* Data Type: bool
* Default Value: `false`

If true, all reviews outside of the score range established by the configuration options
`review.score.criterion.max/min.threshold` will be removed.

=== attribute.conflation.suppress.building.tag.on.multipoly.relation.constituents

* Data Type: bool
* Default Value: `true`

If true, any buildings that are part of a multipolygon relation will have their `building=yes` tags
removed during Attribute Conflation.

=== attribute.score.extractor.use.weight

* Data Type: bool
* Default Value: `false`

Determines whether `AttributeScoreExtractor` uses weighting when extracting scores.

=== attribute.value.criterion.comparison.type

* Data Type: string
* Default Value: ``

The value comparison type used by `AttributeValueCriterion`. Valid values are: `NumericEqualTo`,
`NumericLessThan`, `NumericLessThanOrEqualTo`, `NumericGreaterThan`, `NumericGreaterThanOrEqualTo`,
`TextEqualTo`, `TextContains`, `TextStartsWith`, or `TextEndsWith`.

=== attribute.value.criterion.comparison.value

* Data Type: string
* Default Value: ``

The value to compare with `AttributeValueCriterion`.

=== attribute.value.criterion.type

* Data Type: string
* Default Value: ``

The type of attribute to compare with `AttributeValueCriterion`. Valid key values are: 'changeset',
'timestamp', 'user', 'uid', or 'version'.

=== autocorrect.options

* Data Type: bool
* Default Value: `true`

Temporary setting that addresses some Hootenanny iD Editor UI bugs. See
`MatchFactory::_tempFixDefaults()` for more info.

=== average.conflation.min.split.size.multiplier

* Data Type: double
* Default Value: `0.7`

Multiplier used in determining the minimum linear feature split size during Average Conflation.
The valid range is (0.0, 1.0]. The lesser of `way.merger.min.split.size` and the result of applying
this multiple to the length of the feature being conflated determines the actual minimum split size.
The higher this multiplier is, the larger the minimum split size becomes, if the feature being
conflated has a length greater than `way.merger.min.split.size`.

=== bounds

* Data Type: string
* Default Value: ``

A geographic bounds of the form: "minx,miny,maxx,maxy" ("min_lon,min_lat,max_lon,max_lat") for a
rectangular bounds or "x1,y1;x2,y2;x3,y3;..." ("lon1,lat1;lon2,lat2;lon3,lat3...") for a closed
polygon. The option is used by the `convert`, `conflate`, and `changeset-derive` commands and
others. When specified, supporting readers will limit data read from the source to only features
that intersect the specified bounds. The coordinates are specified in the projection of the input
data source. The `crop` command uses its own version of bounds options as `crop.bounds.*`.

Example Usage:

----
hoot convert -D bounds="106.851,-6.160,107.052,-5.913" input.osm output.osm
----

=== bounds.input.file

* Data Type: string
* Default Value: ``

A complete file path that contains the bounds of to be used. The bounds will be the min/max lat/lon
for the entire file.

Example Usage:

---
hoot convert -D bounds.input.file="$HOOT_HOME/test-files/ToyTestA.osm" input.osm output.osm
---

=== bounds.hoot.api.database

* Data Type: string
* Default Value: ``

Same as `bounds` but the resultant bounds filtering is only applied to Hootenanny API
database data sources when used with the convert and conflate commands. This setting takes
precendence over the `bounds` setting for Hootenanny API database data sources only.

=== bounds.keep.entire.features.crossing.bounds

* Data Type: bool
* Default Value: `true`

If enabled, operations supporting the `bounds` option other than `crop` will not break apart
features crossing the specified. This is analagous to `crop.keep.entire.features.crossing.bounds`
used with the `crop` command.

=== bounds.keep.immediately.connected.ways.outside.bounds

* Data Type: bool
* Default Value: `false`

If enabled, APIDB readers will also return ways that are outside of `bounds` but immediately
connected to ways crossing or within the bounds. Can be used in conjunction with
`bounds.tag.immediately.connected.out.of.bounds.ways`. Not supported by all readers.

=== bounds.keep.only.features.inside.bounds

* Data Type: bool
* Default Value: `false`

If enabled, operations supporting the `bounds` option other than `crop` will throw out any features
that do not fall completely within the specified bounds. This is analagous to
`crop.keep.entire.features.crossing.bounds` used with the crop command.

=== bounds.osm.api.database

* Data Type: string
* Default Value: ``

Same as `bounds` but the resultant bounds filtering is only applied to OSM API database
data sources when used with the convert and conflate commands. This setting takes precendence over
the `bounds` setting for OSM API database data sources only.

=== bounds.output.file

* Data Type: string
* Default Value: `tmp/bounds.osm`

Output location for a bounds file when the `--write-bounds` option is selected for supporting
commands.

=== bounds.remove.missing.elements

* Data Type: bool
* Default Value: `true`

If enabled, any call to commands supporting the `bounds` option will emove missing references to
missing elements as a result of map cropping.

=== bounds.tag.immediately.connected.out.of.bounds.ways

* Data Type: bool
* Default Value: `false`

If enabled, all ways that are outside of the bounds specified by `bounds` when performing a bounded
API database query but are immediately connected to a way that falls within or crosses the bounds
are tagged with a custom tag. Must be used in conjunction with
`bounds.keep.immediately.connected.ways.outside.bounds`. Not supported by all readers.

=== buffered.overlap.extractor.portion

* Data Type: double
* Default Value: `0.1`

The portion of the sqrt max of the area that `BufferedOverlapExtractor` buffers object by.

=== building.adjoining.tag.score.threshold

* Data Type: double
* Default Value: `0.8`

The minimum similarity score required for an adjoining building (`building=terrace`) to be
recognized during conflation.

=== building.changed.review

* Data Type: bool
* Default Value: `false`

If enabled, during building merging conflation will look for a "changed" building defined as a
matched building pair where their Intersection Over Union value (IoU) is greater than zero but falls
below the value specified in building.changed.review.iou.threshold. If the pair is classified as
"changed" they will be marked for review.

=== building.changed.review.iou.threshold

* Data Type: double
* Default Value: `0.2`

See `building.changed.review`.

=== building.date.format

* Data Type: string
* Default Value: `yyyy-MM-ddTHH:mm`

Date format string used by the building date tag value. See `QDateTime::fromString` for more
details.

=== building.date.tag.key

* Data Type: string
* Default Value: `source:date`

Tag key used by the `building.review.if.secondary.newer` configuration option.

=== building.force.contained.match

* Data Type: bool
* Default Value: `false`

If true, a building pair has been flagged for review, and one member of the pair is contained
completely inside the other, the pair will be matched instead.

=== building.keep.more.complex.geometry.when.auto.merging

* Data Type: bool
* Default Value: `true`

If true, when buildings are auto-merged during conflation the geometry of the more complex building
is the one that is kept. If false or the buildings are equally complex, then the geometry of the
reference building is the geometry kept. This does not apply to feature merging done during the
manual review process.

=== building.match.threshold

* Data Type: double
* Default Value: `${conflate.match.threshold.default}`

The threshold at which a match is called a match for buildings. The valid range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== building.merge.many.to.many.matches

* Data Type: bool
* Default Value: `false`

If false, many to many building matches will result in a review. If true, they will all be merged
together when matched.

=== building.miss.threshold

* Data Type: double
* Default Value: `${conflate.miss.threshold.default}`

The threshold at which a miss is called a miss for buildings. The valid range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== building.part.merger.thread.count

* Data Type: int
* Default Value: `8`

Number of threads used by `BuildingPartMergerOp` to process buildings. A value of less than one
allows for automatically determining the optimal thread count.

=== building.review.if.secondary.newer

* Data Type: bool
* Default Value: `false`

If true, any buildings in the secondary layer will be automatically reviewed against potentially
matching features in the reference layer if they are marked with a more recent date than that of the
reference feature.

=== building.review.matches.other.than.one.to.one

* Data Type: bool
* Default Value: `false`

If true, any building matches other than 1:1 matches are automatically marked for review.

=== building.review.threshold

* Data Type: double
* Default Value: `${conflate.review.threshold.default}`

The threshold at which a review is called a review for buildings. The valid range is (0.0, 1.0]. See
`conflate.review.threshold.default`.

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== changeset.allow.deleting.reference.features

* Data Type: bool
* Default Value: `true`

If true, changesets derived are allowed to issue delete statements for the reference dataset (first
dataset passed to the changeset deriver) if calculated.  If false, any delete statements calculated
for the reference dataset will be ignored and not added to changeset output.

=== changeset.apidb.size.max

* Data Type: long
* Default Value: `1000`

This is the maximum number of elements to write to an OSM API database in a changeset push.
This value is used when splitting a changeset into smaller pieces.

NOTE: This is different to `changeset.max.size` which is the maximum number of elements that the
database can handle in a single changeset.

=== changeset.apidb.timeout

* Data Type: int
* Default Value: `500`

Timeout for HTTP requests for `changeset-apply` operations in number of seconds

=== changeset.apidb.writer.debug.output

* Data Type: bool
* Default Value: `false`

When set to true the `OsmApiWriter` class will write each changeset upload request and
response to the `$HOOT_HOME/tmp` directory (by default) for debugging.

NOTE: Use with care, the 28 MB Djibouti test changeset ballooned into 37 MB of debug output
files

=== changeset.apidb.writer.debug.output.path

* Data Type: string
* Default Value: `tmp`

Directory path to store debug output files in for `changeset-appy` commands.

NOTE: Use with care, the 28 MB Djibouti test changeset ballooned into 37 MB of debug output
files

=== changeset.apidb.writers.max

* Data Type: int
* Default Value: `10`

The maximum number of writers to spawn for writing changesets in parallel to an OSM API database.

=== changeset.apidb.writers.throttle

* Data Type: bool
* Default Value: `false`

Flag to turn on throttling for OSM API changeset writes. When turned on, each processing thread
will wait `changeset.api.writers.throttle.time` seconds after a successful write before submitting
another changeset to the OSM API.

=== changeset.apidb.writers.throttle.cgimap

* Data Type: bool
* Default Value: `false`

Flag to turn on throttling if the OSM API uses CGImap in the back end instead of the rails port.
Checks the usage of CGImap and then enables `changeset.apidb.writers.throttle`.

=== changeset.apidb.writers.throttle.time

* Data Type: int
* Default Value: `10`

The number of seconds after a successful write before submitting another changeset to the OSM API.

=== changeset.apidb.writers.throttle.timespan

* Data Type: int
* Default Value: `0`

The number of seconds plus or minus for random throttling of the OSM API writer.

=== changeset.description

* Data Type: string
* Default Value: `Hootenanny ingest`

The text description that is written to the OSM API database with a changeset.

=== changeset.ignore.bounds

* Data Type: bool
* Default Value: `false`

If enabled, changeset writers will ignore the `bounds` configuration option. Otherwise, only
elements satisfying the configured geospatial bounds options will be used to generate changeset
statements. Currently this primarily used by the Cut and Replace workflow, as it handles the bounds
internally.

=== changeset.hashtags

* Data Type: string
* Default Value: `#hootbot`

Set of semicolon separated hashtags associated with a changeset, used for querying changesets and
for conflation campaigns

=== changeset.max.size

* Data Type: long
* Default Value: `10000`

The maximum allowed element size of an OSM changeset that can be written to an OSM API database
in a single changeset.

=== changeset.metadata.allowed.tag.keys

* Data Type: list
* Default Value:
** ``

This allows for writing metadata tags to the changeset output.

=== changeset.replacement.allow.deleting.reference.features.outside.bounds

* Data Type: bool
* Default Value: `true`

If disabled, replacement changesets generated by `changeset-derive` command with the `--replacement`
option will never add delete statements for reference features falling outside of `bounds`.

=== changeset.replacement.cut.only.implementation

* Data Type: string
* Default Value: `ChangesetCutOnlyCreator`

The `ChangesetReplacement` implementation used for changeset replacement derivation when only
cutting data.

=== changeset.replacement.implementation

* Data Type: string
* Default Value: `ChangesetReplacementCreator`

The `ChangesetReplacement` implementation used for changeset replacement derivation when cutting and
replacing data.

=== changeset.replacement.map.cleaner.transforms

* Data Type: list
* Default Value:
** `ReprojectToPlanarOp`
** `DuplicateNodeRemover`
** `UnlikelyIntersectionRemover`
** `DualHighwaySplitter`
** `RemoveInvalidMultilineStringMembersVisitor`

The map cleaning operations used by replacement changeset generation.

=== changeset.replacement.mark.elements.with.missing.children

* Data Type: bool
* Default Value: `false`

If enabled while deriving a replacement changeset, any encountered way having references to nodes
whose source elements do not exist or encountered relation having references to members whose source
elements do not exist will have a custom tag added to them to signal that the feature may require
manual cleanup.

=== changeset.replacement.retain.replacing.data.ids

* Data Type: bool
* Default Value: `true`

If true, replacement changesets will preserve the IDs of the elements used for replacement.
Generally, this is preferred when like datasets are being replaced with each other (e.g. replacing
public OSM with public OSM) that may have corresponding element IDs. Enabling this allows for modify
changeset statements to be generated appropriately in favor of create/delete statement for matching
elements between the datasets. If a replacement is being done against two dissimilar datasets which
may have ID conflicts for elements that are different from each other, then disabling this setting
may be desirable.

=== changeset.replacement.snap.exclude.types

* Data Type: list
* Default Value:
** `road_marking=solid_stop_line`
** `highway=steps`
** `noexit=yes`

Feature types that should never be snapped by `ChangesetReplacementCreator` when using
`UnconnectedWaySnapper`. Overrides `snap.unconnected.ways.exclude.types`.

=== changeset.source

* Data Type: string
* Default Value: `Hootenanny`

Specifies the source for the edits that have been made in the changeset.

=== changeset.user.id

* Data Type: long
* Default Value: `-1`

The user ID used by certain changeset writers when writing to an OSM API database.

=== changeset.xml.writer.add.timestamp

* Data Type: bool
* Default Value: `true`

If true, XML changesets will add the `timestamp` attribute to the element tags.  If false, the
timestamp attribute will not be added.  This generally should only be set to false for testing
purposes.

=== circular.error.default.value

* Data Type: double
* Default Value: `15.0`

Set the circular error tag on features to this value, in meters, by default if the tag isn't already
populated.

=== circular.error.tag.keys

* Data Type: list
* Default Value:
** `error:circular`
** `accuracy`

A list of tag keys whose values are known to contain circular error (CE; accuracy) data. Multiple
values may be specified for situations where input data uses different circular error tag keys. If
a feature contains more than one tag key from this list, only one of the values will be used. If
this list is empty, no circular error will be parsed from input features and a the value defined by
`circular.error.default.value` will be used for all features.

=== config.options.file

* Data Type: string
* Default Value: `conf/core/ConfigOptions.asciidoc`

Path to this file. Only modified during the testing of the `info` command.

=== conflate.element.criterion

* Data Type: string
* Default Value: ``

Criteria used for filtering elements before conflating them.

=== conflate.element.criterion.negate

* Data Type: bool
* Default Value: `false`

Negates `conflate.element.criterion`.

=== conflate.info.max.size.per.cache

* Data Type: int
* Default Value: `100000`

The maximum number of elements to cache information for per cache when running Conflation. This
maximum size is repeated across multiple internal element information caches. To disable caching,
completely specify a value less than one.

=== conflate.mark.merge.created.multilinestring.relations

* Data Type: bool
* Default Value: `true`

Marks any multilinestring relations created as a result of merging during conflation with a custom
tag. Individual mergers must enable this option independently. This option must be enabled in order
for `MultilineStringMergeRelationCollapser` to be able to run properly against conflated output.

=== conflate.match.building.model

* Data Type: string
* Default Value: `models/BuildingModel.rf`

Path to the RF building model. A new model can be created with `build-model`. Searches local path
and then `$HOOT_HOME/conf/`.

=== conflate.match.highway.classifier

* Data Type: string
* Default Value: `HighwayRfClassifier`

The classifier to use to classify road matches.

=== conflate.match.highway.median.classifier

* Data Type: string
* Default Value: `MedianToDividedRoadClassifier`

The highway match classifier to use to match road medians to divided highways if
`highway.median.to.dual.highway.match` is enabled.

=== conflate.match.highway.model

* Data Type: string
* Default Value: `models/HighwayModel.rf`

Path to the RF highway model. A new model can be created with `build-model`. Searches local path
and then `$HOOT_HOME/conf/`. This is only relevant if the `conflate.match.highway.classifier` is
set to `HighwayRfClassifier`.

=== conflate.match.only

* Data Type: bool
* Default Value: `false`

If enabled, features will be matched but not merged during conflation. Combine with
`writer.include.conflate.score.tags=true` to see conflate match scores in the output.

=== conflate.match.threshold.default

* Data Type: double
* Default Value: `0.6`

The default threshold at which a match is called a match. The valid range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== conflate.miss.threshold.default

* Data Type: double
* Default Value: `0.6`

The default threshold at which a miss is called a miss. The valid range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== conflate.post.ops

* Data Type: list
* Default Value:
** `RemoveMissingElementsVisitor`
** `InvalidWayRemover`
** `PoiPolygonInvalidReviewNodeRemover`
** `SuperfluousNodeRemover`
** `SmallHighwayMerger`
** `ReplaceRoundabouts`
** `RemoveMissingElementsVisitor`
** `RemoveInvalidReviewRelationsVisitor`
** `RemoveDuplicateReviewsOp`
** `BuildingOutlineUpdateOp`
** `WayJoinerOp`
** `RemoveInvalidRelationVisitor`
** `RemoveInvalidMultilineStringMembersVisitor`
** `SuperfluousWayRemover`
** `RemoveDuplicateWayNodesVisitor`
** `DuplicateWayRemover`
** `RemoveDuplicateRelationMembersVisitor`
** `RemoveEmptyRelationsOp`
** `RelationCircularRefRemover`
** `MultilineStringMergeRelationCollapser`
** `RoadCrossingPolyMarker`
** `RailwaysCrossingMarker`
** `ApiTagTruncateVisitor`
** `AddHilbertReviewSortOrderOp`

Runs during conflation just after the data is conflated, but before it is saved. The ordering here
is sensitive and addition of new operations may take experimentation to produce optimal conflated
output. `hoot info --operators` displays information about the available operations.

=== conflate.pre.ops

* Data Type: list
* Default Value:
** `RemoveMissingElementsVisitor`
** `BuildingOutlineRemoveOp`
** `RemoveRoundabouts`
** `MapCleaner`
** `HighwayCornerSplitter`
** `RemoveInvalidReviewRelationsVisitor`
** `RubberSheet`

Runs during conflation just after data is loaded. The ordering here is sensitive (although
generally not as sensitive as with `conflate.post.ops`) and addition of new operations may take
experimentation to produce optimal conflated output. `hoot info --operators` displays information
about the available operations.

See also: <<MapCleanerTransforms,map.cleaner.transforms>>

=== conflate.remove.superfluous.ops

* Data Type: bool
* Default Value: `true`

Enabling this option allows for removing any operators defined in `conflate.pre.ops`,
`conflate.post.ops`, or `map.cleaner.transforms` before running conflation that are not associated
with the feature types being conflated as specified in the `match.creators` option. Doing so can
increase runtime performance for some inputs. e.g. If you're only conflating buildings, then any
operators used strictly for road data cleaning will be automatically disabled. This is primarily
used for debugging purposes and should normally be left enabled. See the
`FilteredByGeometryTypeCriteria` interface for information about determining which feature types are
associated with conflate operators.

=== conflate.review.threshold.default

* Data Type: double
* Default Value: `0.6`

The default threshold at which a review is called a review. Reviews are also declared in some
other situations when the relationship is not clear. The valid range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== conflate.rubber.sheet.element.criteria

* Data Type: list
* Default Value:
** `RiverCriterion`
** `PowerLineCriterion`

Determines which type of features are rubbersheeted during conflation when rubbersheeting is part
of the conflation pre-operations. An empty list will rubbersheet all types of features.

=== conflate.score.tags.filter

* Data Type: list
* Default Value:
** `Match`
** `Miss`
** `Review`

Filters the conflate score tag output enabled with `writer.include.conflate.score.tags=true` by
match type. Valid values are: `Match`, `Miss`, or `Review`. By default, all types of score tags are
included.

=== conflate.tag.disable.value.truncation

* Data Type: bool
* Default Value: `false`

This will disable use of `ApiTagTruncateVisitor`, which truncates tag values down to size limit
acceptable by the OpenStreetMap API, if found in either `conflate.pre.ops` or `conflate.post.ops` by
either the `conflate` or `score-matches` commands. Setting this option to true is generally intended
for testing purposes only.

=== conflate.tag.filter

* Data Type: string
* Default Value: ``

A JSON tag filter that is applied to filter features before conflation. See the User Guide
"Feature Filtering" section for filter usage examples.

=== conflate.unifying.rubber.sheet.roads

* Data Type: bool
* Default Value: `false`

Forces pre-conflation rubbersheeting for roads when the Unifying Algorithm is used by adding an
entry to `conflate.rubber.sheet.element.criteria`.

=== conflate.use.data.source.ids.1

* Data Type: bool
* Default Value: `true`

Determines whether the reader used by the conflate command to read the first input dataset will
use the element ID's specified by the input datasets (true) or use internal ID management for the
inputs (false).

=== conflate.use.data.source.ids.2

* Data Type: bool
* Default Value: `false`

Determines whether the reader used by the conflate command to read the second input dataset will
use the element ID's specified by the input datasets (true) or use internal ID management for the
inputs (false).

=== contains.node.criterion.id

* Data Type: long
* Default Value: `0`

ID of the node that ContainsNodeCriterion should search for.

=== convert.ops

* Data Type: list
* Default Value:
** ``

Specifies one or more semi-colon delimited map operations or visitors to apply before writing
converted data. This is only applicable to the convert command. `hoot info --operators` displays
information about the available operations.

=== convert.require.area.for.polygon

* Data Type: bool
* Default Value: `true`

If true, an element must be classifiable as an area geometry in the schema in order to be converted
to a GEOS polygon.

=== convert.translate.multithreaded

* Data Type: bool
* Default Value: `false`

If enabled calling the convert command with a translation script will run a separate thread for
translating. Multi-threaded translation is memory bound.

=== cookie.cutter.alpha

* Data Type: double
* Default Value: `1000.0`

The size in meters used for alpha by the cookie cutter map operation, `CookieCutterOp`. A larger
value makes a smoother shape and a smaller value will create a rough shape with more holes. Value
in meters.

=== cookie.cutter.alpha.shape.buffer

* Data Type: double
* Default Value: `0.0`

The buffer, in meters, to add to the alpha shape before cutting by the cookie cutter map operation,
`CookieCutterOp`. A negative value will make the shape smaller.

=== cookie.cutter.alpha.shape.max.threads

* Data Type: int
* Default Value: `10`

Creating the alpha shape is a time consuming process that is sped up by merging and straggler
testing in parallel. This sets the number of processing threads to utilize for processing the alpha
shape in parallel. Warning: each thread has some memory overhead

=== cookie.cutter.output.crop

* Data Type: bool
* Default Value: `false`

Crops based on the polygon rather than doing a cookie cut when using the cookie cutter map
operation (see `CookieCutterOp`).

=== copy.map.subset.op.element.criteria

* Data Type: list
* Default Value: ``

One or more element criteria used for filtering maps with `CopyMapSubsetOp`.

=== create.bogus.review.tags

* Data Type: bool
* Default Value: `false`

Creates example review tags for debugging. All reviews created with this mechanism are invalid.

=== crop.bounds

* Data Type: string
* Default Value: ``

Bounds used by the map cropper when cropping a map. See the `bounds` option for format detail.

=== crop.invert

* Data Type: bool
* Default Value: `false`

If false, will keep the data falling within the crop bounds. If true, will keep only data outside
of the bounds.

=== crop.keep.entire.features.crossing.bounds

* Data Type: bool
* Default Value: `false`

If true, will not break apart features crossing the crop bounds. Ignored if `crop.invert` is
enabled.

=== crop.keep.only.features.inside.bounds

* Data Type: bool
* Default Value: `false`

If true, will throw out any features that do not fall completely within the crop bounds. Ignored if
`crop.invert` is enabled.

=== crop.random.max.node.count

* Data Type: int
* Default Value: `-1`

The maximum number of nodes to be cropped out when running either the `crop-random` command or
`RandomMapCropper`.

=== crop.random.pixel.size

* Data Type: double
* Default Value: `0.001`

The pixel size used when running either the `crop-random` command or `RandomMapCropper`.

=== data.summary.tag.sources

* Data Type: list
* Default Value:
** ``

List of valid values for data sources used to calculate the summary data for multiple conflations

=== debug.maps.class.exclude.filter

* Data Type: list
* Default Value: ``

A list of class names used for controlling debug map writing. This follows the same format as
`log.class.exclude.filter`.

=== debug.maps.class.include.filter

* Data Type: list
* Default Value: ``

A list of class names used for controlling debug map writing. This follows the same format as
`log.class.include.filter`.

=== debug.maps.filename

* Data Type: string
* Default Value: `tmp/debug.osm`

The filename to use when saving the debug map during conflation.

=== debug.maps.remove.missing.elements

* Data Type: bool
* Default Value: `true`

If enabled, debug maps will have missing element references removed upon their writing. This allows
the output to be viewed in JOSM.

=== debug.maps.write

* Data Type: bool
* Default Value: `false`

If true, multiple debug maps will be generated during a conflation job. The output path of the maps
is controlled by `debug.maps.filename`. The maps can be large and slow things down significantly.

=== debug.maps.write.detailed

* Data Type: bool
* Default Value: `false`

If enabled, debug maps are written from inside loops where enabled. `debug.maps.write` must already
be enabled for this option to be used. Enabling this option can create a lot of debug maps and slow
down debugging significantly, so use with caution.

=== differential.remove.linear.partial.matches.as.whole

* Data Type: bool
* Default Value: `false`

When disabled, Differential Conflation only removes the element geometric portions of linear matches
involved in the match from the differential output. Otherwise, elements are removed completely from
the differential, even if they are only partially involved in a match. Disabling this setting may
yield more accurate linear feature differentials. This setting may only be disabled when using the
Unifying Algorithm.

=== differential.remove.reference.data

* Data Type: bool
* Default Value: `true`

If false, when running Differential Conflation the reference elements will not be dropped from the
output. Setting this to true will not remove reference data in the output involved in snapping to
secondary features. Disabling this can be useful useful when debugging unconnected way snapping
issues.

=== differential.remove.reference.snapped.data

* Data Type: bool
* Default Value: `false`

If true, when running Differential Conflation all reference elements will be dropped from the
output regardless of whether they were snapped to a secondary feature. This overrides the
`differential.remove.reference.data` option. Do not enable this if Differential Conflation is to be
used to generate changeset output that will be written back to an authoritative data store.

=== differential.remove.river.partial.matches.as.whole

* Data Type: bool
* Default Value: `true`

Overrides `differential.remove.linear.partial.matches.as.whole` when dealing with river data.

=== differential.remove.unconflatable.data

* Data Type: bool
* Default Value: `true`

If true, Differential Conflation will remove all elements from output which conflation is unable to
match. If false, the unconflatable data will pass through to the output.

=== differential.sec.way.removal.criteria

* Data Type: list
* Default Value:
** ``

Optional criteria used to clean small secondary ways that are not connected to a reference way in
the differential output. The classes specified must inherit from `ConflatableElementCriterion`. An
example is: `HighwayCriterion`. The default value of an empty list causes no secondary way removal
to occur.

=== differential.sec.way.removal.length.threshold

* Data Type: double
* Default Value: `5.0`

The largest size, in meters, a secondary way may have in order to be removed when criteria are
specified in `differential.sec.way.removal.criteria`.

=== differential.snap.unconnected.features

* Data Type: bool
* Default Value: `false`

If true, when running Differential Conflation the Unconnected Way Snapper will snap unconnected
features to the nearest feature. See `snap.unconnected.ways.*` options for configurability.

=== differential.tag.ignore.list

* Data Type: list
* Default Value:
** ``

List of non-metadata tags to ignore when performing differential conflation with tags. Metadata tags
are always ignored.

=== differential.treat.reviews.as.matches

* Data Type: bool
* Default Value: `true`

If true, reviews are treated as matches by Differential Conflation and removed from the output if
`differential.remove.reference.data` is enabled. If set to false, reviews are not treated as matches
and will pass through to the differential output.

=== direction.finder.angle.threshold

* Data Type: double
* Default Value: `45.0`

Maximum angle different in degrees that two line features can have and still be considered as
going in the same direction by Attribute Conflation.

=== distance.node.criterion.center

* Data Type: string
* Default Value: ``

WGS84 coordinate in the format: "x,y" that `DistanceNodeCriterion` should use as a center when
searching for nodes.

=== distance.node.criterion.distance

* Data Type: double
* Default Value: `-1.0`

Distance in meters that `DistanceNodeCriterion` should search for nodes out from a center specified
by `distance.node.criterion.center`.

=== dual.highway.marker.mark.crossing.roads

* Data Type: bool
* Default Value: `false`

If enabled, `DualHighwayMarker` will tag roads crossing between divided roads in addition to the
divided roads themselves.

=== dual.highway.marker.crossing.roads.parallel.score.threshold

* Data Type: double
* Default Value: `0.4`

How perpendicular a road must be to a divided road to be considered as crossing it, with 0.0 being
the most perpendicular and 1.0 being the least.

=== dual.highway.marker.parallel.score.threshold

* Data Type: double
* Default Value: `0.9`

How parallel two roads must to be considered as part of the same divided highway, with 0.0 being the
least parallel and 1.0 being the most.

=== dual.highway.splitter.driving.side

* Data Type: string
* Default Value: `right`

When splitting divided highways, do we assume the drivers are on the right or left?

See also: <<MapCleanerTransforms,map.cleaner.transforms>>

=== dual.highway.splitter.split.size

* Data Type: double
* Default Value: `12.5`

By default how much space should be put between two divided roads when they're divided by
`DualHighwaySplitter`. Units are in meters.

See also: <<MapCleanerTransforms,map.cleaner.transforms>>

=== duplicate.name.case.sensitive

* Data Type: bool
* Default Value: `true`

If true, all cleaning and conflation merge operations will only remove duplicate names when their
case also matches.  If false, cleaning and conflation merge operations will consider names with
the same text but differing case as the same with each other.

See also: <<MapCleanerTransforms,map.cleaner.transforms>>

=== duplicate.name.preserve.original.name

* Data Type: bool
* Default Value: `false`

If true, `DuplicateNameRemover` will always preserve the original name tag.  Otherwise, it
will treat name and alternate name tags equally.

=== duplicate.node.remover.distance.threshold

* Data Type: double
* Default Value: `0.01`

When merging nodes with `DuplicateNodeRemover`, determines what tolerance should be used for
deciding if two nodes are identical. Larger values are more likely to merge nodes which are not true
duplicates of each other. The units are in meters, and the value must be greater than zero.

=== duplicate.way.remover.strict.tag.matching

* Data Type: bool
* Default Value: `true`

If true, when comparing duplicate ways, the ways and their name tags will only be merged together
when all other non-name tags between the two match.  If false, the ways and their name tags will be
merged together regardless of whether all of their non-name tags match.

=== edge.distance.extractor.spacing

* Data Type: double
* Default Value: `5.0`

The spacing, in meters, used by `EdgeDistanceExtractor`.

=== element.cache.size.node

* Data Type: long
* Default Value: `10000000`

Size of the in memory node cache used when streaming I/O is used with nodes.

=== element.cache.size.relation

* Data Type: long
* Default Value: `2000000`

Size of the in memory relation cache used when streaming I/O is used with relations.

=== element.cache.size.way

* Data Type: long
* Default Value: `2000000`

Size of the in memory way cache used when streaming I/O is used with ways.

=== element.criteria.chain

* Data Type: bool
* Default Value: `false`

Generic criteria chaining option used by classes which run in isolation from the command line and
do not require their own version of the option. If set to true and multiple criterion are specified,
an element must satisfy each criterion in order to pass the filter. If set to false, then only one
of the specified criteria must be satisified in order to pass the filter.

=== element.criteria.negate

* Data Type: bool
* Default Value: `false`

If true, element criteria passed to an `ElementCriterionConsumer` and other consuming classes will
be negated. Not honored by all `ElementCriterionConsumers`. Since this configuration option is
shared across all `ElementCriterionConsumers`, there may be undesirable effects in invocations
involving multiple `ElementCriterionConsumers`.

=== element.hash.visitor.non.metadata.ignore.keys

* Data Type: list
* Default Value:
** ``

List of tag keys for `ElementHashVisitor` to ignore during comparison when calculating element
hashes.

=== element.id.criterion.ids

* Data Type: list
* Default Value:
** ``

A list of element IDs to pass to `ElementIdCriterion`.

=== element.sorter.element.buffer.size

* Data Type: long
* Default Value: `-1`

The maximum number of elements allowed to be in memory during element sorting.  A value of -1
indicates no limit.

=== english.words.files

* Data Type: list
* Default Value:
** `/usr/share/dict/american-english-insane`
** `/usr/share/dict/american-english-huge`
** `/usr/share/dict/american-english-large`
** `/usr/share/dict/american-english-small`
** `/usr/share/dict/american-english`
** `/usr/share/dict/words`

Absolute file path to dictionaries of English words. The first file found will be loaded into the
dictionary of English words and used by some algorithms. If the files are not found then the English
words will be silently ignored.

=== expectation.intersection.max.cache.size

* Data Type: int
* Default Value: `100000`

The maximum size of any cache used by `ExpectationIntersection` or classes it depends on.

=== generic.line.matcher.heading.delta

* Data Type: double
* Default Value: `${way.matcher.heading.delta}`

The distance around a point on a power line to look when matching sublines with generic line
conflation. See `way.matcher.heading.delta`.

=== generic.line.matcher.max.angle

* Data Type: double
* Default Value: `90.0`

Sets that maximum angle that is still considered a generic line match, in degrees.

=== generic.line.subline.matcher

* Data Type: string
* Default Value: `MaximalSublineMatcher`

The way subline matcher to use when determining matching sublines with generic line conflation.

=== generic.line.type.threshold

* Data Type: double
* Default Value: `0.8`

Tag similarity threshold, in the range (0.0, 1.0], at or above which an linear element not
conflatable by specific conflation routines is considered to have similar tags.

=== generic.point.type.threshold

* Data Type: double
* Default Value: `0.8`

Tag similarity threshold, in the range (0.0, 1.0], at or above which an point element not
conflatable by specific conflation routines is considered to have similar tags.

=== generic.point.polygon.type.threshold

* Data Type: double
* Default Value: `0.8`

Tag similarity threshold, in the range (0.0, 1.0], at or above which a pair of point and polygon
elements not conflatable by specific conflation routines is considered to have similar tags.

=== generic.polygon.type.threshold

* Data Type: double
* Default Value: `0.8`

Tag similarity threshold, in the range (0.0, 1.0], at or above which an polygon element not
conflatable by specific conflation routines is considered to have similar tags.

=== geometry.linear.merger.default

* Data Type: string
* Default Value: `LinearSnapMerger`

The merger to use when merging features with linear geometries during conflation. Must inherit from
`LinearMergerAbstract`.

=== geometry.modifier.rules.file

* Data Type: string
* Default Value: `${HOOT_HOME}/conf/core/GeometryModifierRules.json`

Path to a json file containing the actions, filters and arguments used for `GeometryModifierOp`.

==== Rule File Format
-----
{
    "way_to_poly":    // Command: way_to_poly, collapse_poly, etc.
                      // See implementations of GeometryModifierAction
    {
        "filter":     // Filter for limiting the elements to process. The modifier uses the
                      // Feature Filtering logic as used for conflation (FeatureFiltering.asciidoc)
        {
            "must":
            [
                {
                    "tag": "aeroway=runway"
                }
            ]
        },
        "arguments":  // Arguments specific to the selected command
        {
            "default_width_m": 10,
            "width_tag_m" : "width"
        }
    },
    "collapse_poly":  // Next command: all commands defined are processed in sequence
    {
        "filter":
        {
        "must":
            [
                {
                    "tag": "building=yes"
                }
            ]
        },
        "arguments":
        {
            "max_area_in_m": 15000
        }
    }
}
-----

=== geonames.reader.string.cache.size

* Data Type: int
* Default Value: `100000`

The maximum number of parsed tag string values stored in an in-memory cache when reading
GeoNames data.

=== graph.comparator.max.threads

* Data Type: int
* Default Value: `10`

The maximum number of graph comparator threads that can be launched by the `compare` command.

=== hash.seed.zero

* Data Type: bool
* Default Value: `false`

Sets the Qt hash seed to 0 for consistent hash values and hash based container content order. This
is required for unit tests, but shouldn't be used in normal operation.

=== highway.corner.splitter.rounded.max.node.count

* Data Type: int
* Default Value: `6`

Maximum number of nodes in a row to consider for a bend in a way to determine if the way is a
rounded corner that should be split by the `HighwayCornerSplitter`. The higher the number, the more
heading calculations are required. The lower the number, the less accurate it will be.

=== highway.corner.splitter.rounded.split

* Data Type: bool
* Default Value: `false`

Rounded corners in one dataset can cause non-rounded corners in the secondary dataset to not
conflate when using `HighwayCornerSplitter`.

=== highway.corner.splitter.rounded.threshold

* Data Type: double
* Default Value: `55.0`

Threshold in degrees between the heading of rounded bends in way that constitutes a corner when
using `HighwayCornerSplitter`.

=== highway.corner.splitter.threshold

* Data Type: double
* Default Value: `55.0`

Threshold in degrees between the heading of two way segments that constitutes a corner when using
`HighwayCornerSplitter`.

=== highway.crossing.poly.rules

* Data Type: string
* Default Value: `${HOOT_HOME}/conf/core/RoadCrossingPolyRules.json`

Rules for which types of polygon features to check for roads crossing over them to flag as reviews
by `RoadCrossingPolyMarker`. See the "Crossing Roads" section in the "Feature Validation"
documentation for detail on the rule file format.

=== highway.match.threshold

* Data Type: double
* Default Value: `0.161`

The threshold at which a match is called a match for roads. The valid range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== highway.matcher.heading.delta

* Data Type: double
* Default Value: `${way.matcher.heading.delta}`

The distance around a point on a highway to look when calculating the heading. See
`way.matcher.heading.delta`.

=== highway.matcher.max.angle

* Data Type: double
* Default Value: `${way.matcher.max.angle}`

Sets that maximum angle, in degrees, that is still considered a highway match.

=== highway.max.enum.diff

* Data Type: double
* Default Value: `0.6`

If two highways have significantly different enumerated types then they will not be considered
for match. For example:

* `highway=primary` vs `highway=secondary` has a diff of 0.2.
* `highway=primary` vs `highway=footway` has a diff of 0.67.

=== highway.median.identifying.tags

* Data Type: list
* Default Value:
** `median=yes`

List of tag kvps used to identify a road median feature between two divided road features (dual
carriageways; arbitarily, the first tag found from the key list is used). The list is used to
identify one to many secondary match feature candidates if `highway.median.to.dual.highway.match` is
enabled and the conditions described in `highway.median.to.dual.highway.match` are satisfied for a
road match.

=== highway.median.to.dual.highway.match

* Data Type: bool
* Default Value: `false`

If true, road matching will attempt a one to many match from a single input 2 road median feature to
multiple input 1 divided road (dual carriageway) features. The road feature from input 2 must
contain at least one of the tags identified in `highway.median.identifying.tags`. Only tag merging
of selected tags identified in `highway.median.to.dual.highway.transfer.tags` will be performed with
no geometry merging and no removal of the median feature, regardless of the conflation workflow in
use.

=== highway.median.to.dual.highway.transfer.keys

* Data Type: list
* Default Value:
** ``

List of keys for tags to transfer from input 2 road median features to input 1 divided road (dual
carriageway) features if `highway.median.to.dual.highway.match` is enabled and the conditions
described in `highway.median.to.dual.highway.match` are satisfied for a road match.

=== highway.miss.threshold

* Data Type: double
* Default Value: `0.999`

The threshold at which a miss is called a miss for roads. The valid range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== highway.review.threshold

* Data Type: double
* Default Value: `0.25`

The threshold at which a review is called a review for roads. The valid range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== highway.subline.matcher

* Data Type: string
* Default Value: `${way.subline.matcher}`

The highway subline matcher to use when determining matching highways.

=== highway.subline.string.matcher

* Data Type: string
* Default Value: `${way.subline.string.matcher}`

The way subline string matcher to use when determining matching highways.

=== hoot.osm.auth.consumer.key

* Data Type: string
* Default Value: ``

OpenstreetMap OAuth Consumer Key found after registering Hootenanny iD Editor with OpenstreetMap (or
its derivatives) at `http://<OSM Domain>/user/<your username>/oauth_clients`

=== hoot.osm.auth.consumer.secret

* Data Type: string
* Default Value: ``

OpenstreetMap OAuth Private Consumer Key found after registering Hootenanny iD Editor with
OpenstreetMap (or its derivatives) at `http://<OSM Domain>/user/<your username>/oauth_clients`

=== hoot.osm.auth.access.token

* Data Type: string
* Default Value: ``

OpenstreetMap OAuth Access Token for gaining access to the OAuth protected OSM API

=== hoot.osm.auth.access.token.secret

* Data Type: string
* Default Value: ``

OpenstreetMap OAuth Private Access Token for gaining access to the OAuth protected OSM API

=== hoot.services.auth.access.token

* Data Type: string
* Default Value: ``

Web Services public access token required by some commands. Use the `login` command to retrieve
access tokens.

=== hoot.services.auth.access.token.secret

* Data Type: string
* Default Value: ``

Web Services private access token required by some commands.  Use the `login` command to retrieve
access tokens.

=== hoot.services.auth.host

* Data Type: string
* Default Value: `localhost`

Host name of the machine the Web Services are located on.

=== hoot.services.auth.port

* Data Type: int
* Default Value: `8080`

Port of the machine the Web Services are located on. If left empty, port 80 will be used.

=== hoot.services.auth.user.name

* Data Type: string
* Default Value: ``

Web Services user name associated with an authenticated login.

=== hoot.validators

* Data Type: list
* Default Value:
** `RoadCrossingPolyMarker`

List of Hootenanny validators to use during validation. See also: `josm.validators`.

=== hootapi.db.writer.copy.bulk.insert

* Data Type: bool
* Default Value: `false`

If set to true, the Hootenanny API database writer will insert new records using Postgres COPY
statements, which may increase performance when writing large datasets. This setting can only be
activated when writing new records and will not work when existing records need to be modified or
deleted. It also requires writing out temporary files, so extra disk space is needed.

=== hootapi.db.writer.create.user

* Data Type: bool
* Default Value: `false`

Should the hootapi services DB writer automatically create the specified user if it doesn't exist.
This is most useful when debugging and testing.

=== hootapi.db.writer.output.id.mappings

* Data Type: string
* Default Value: ``

If this value is set to a non-empty string, the system will attempt to open a file with the
specified name and output all the ID mappings (source to destination) used for nodes, ways, and
relations that were written to the database.

=== hootapi.db.writer.overwrite.map

* Data Type: bool
* Default Value: `false`

If set to true then if there is already a map with the specified name then it will be removed before
a new map is written.

=== hootapi.db.writer.preserve.version.on.insert

* Data Type: bool
* Default Value: `false`

If true, versions for elements are retained on new writes to the Hootenanny API database. If false,
versions are reset to an initial version of 1.

=== hootapi.db.writer.remap.ids

* Data Type: bool
* Default Value: `false`

If this value is set to true, then all incoming element IDs are remapped into new IDs as the
elements are written to a Hootenanny API database, otherwise the original IDs from the map
are preserved.

=== id.generator

* Data Type: string
* Default Value: `DefaultIdGenerator`

Sets the default ID generator class name. This determines how new element IDs are assigned as
they're created. The `DefaultIdGenerator` assigns IDs in a decrementing fashion (e.g. -1, -2, ...).
The `PositiveIdGenerator` increments the IDs (e.g. 1, 2, 3, ...).

Both generators maintain a different count for each element type. E.g. you can have a Node with ID
1 and a Way with ID 1. This will not cause any problems and is a legitimate way of assigning IDs
within OSM.

Example Usage:

----
hoot convert -D schema.translation.script=$HOOT_HOME/translations/Identity.js -D id.generator=PositiveIdGenerator -D id.generator.node.start=100 -D id.generator.relation.start=200 -D id.generator.way.start=300 myinput.osm myoutput.osm
----

=== id.generator.node.start

* Data Type: double
* Default Value: `0`

Sets the default start ID for nodes. The first value assigned is generator specific. (E.g. for
default the first assigned id will be -1)

=== id.generator.relation.start

* Data Type: double
* Default Value: `0`

Sets the default start ID for relations. The first value assigned is generator specific. (E.g.
for default the first assigned id will be -1)

=== id.generator.way.start

* Data Type: double
* Default Value: `0`

Sets the default start ID for ways. The first value assigned is generator specific. (E.g. for
default the first assigned id will be -1)

=== implicit.tagger.add.top.tag.only

* Data Type: bool
* Default Value: `true`

If true, implicit taggers will only add the implicit tag to the element with the highest tag
occurrence count for a given set of inputs name tokens.  Setting to true may be useful in reducing
false positive applied tags to elements.

=== implicit.tagger.additional.name.keys

* Data Type: list
* Default Value:
** `note`

A list of additional tag keys to be considered as names when tagging implicitly based on type.

=== implicit.tagger.allow.tagging.specific.entities

* Data Type: bool
* Default Value: `true`

If true, implicit taggers will attempt to add more specific tags to existing non-generic elements
(dependent on the element type filter; e.g. for POIs, elements with a tag more specific than
`poi=yes`). If false, implicit taggers will ignore all non-generic elements during implicit
tagging.

=== implicit.tagger.allow.words.involved.in.multiple.rules

* Data Type: bool
* Default Value: `false`

If true, implicit taggers will allow for returning tags for a name when that name is involved in
more than one tagging rule. Setting to false may be useful in reducing false positive applied tags
to elements.

=== implicit.tagger.match.end.of.name.single.token.first

* Data Type: bool
* Default Value: `true`

If true, implicit taggers will attempt to match the last token in a name to an implicit tag rule
first before attempting to match other parts of the name.  Setting to true can be useful in getting
better tagging performance for names that would otherwise be involved in multiple implicit tag
rules.

=== implicit.tagger.max.name.length

* Data Type: int
* Default Value: `75`

The maximum length a name tag value can have for the type tagger to try and derive a type from it.

=== implicit.tagger.rules.database

* Data Type: string
* Default Value: `${HOOT_HOME}/conf/core/implicit-tag-rules/osm-geonames-4-5-18.sqlite`

Database used by the POI implicit tagger to derive POI type tags implicitly based on a POI's name.

=== implicit.tagging.database.deriver.custom.rule.file

* Data Type: string
* Default Value: `${HOOT_HOME}/conf/core/implicit-tag-rules/implicitTagRulesCustomRuleList`

Flat file containing tab separated word key/value pairs to use as custom rules when deriving an
implicit tags database from POI names.

=== implicit.tagging.database.deriver.minimum.tag.occurrences.per.word

* Data Type: int
* Default Value: `1000`

The minimum number of times a tag must be associated with a word in order for an implicit tag rule
to be created that is associated with it.

=== implicit.tagging.database.deriver.minimum.word.length

* Data Type: int
* Default Value: `3`

The minimum allowed word length when associating word tokens with tags.

=== implicit.tagging.database.deriver.tag.ignore.list

* Data Type: list
* Default Value:
** `abandoned:place=populated`
** `bridge=yes`
** `capital=yes`
** `historic=yes`
** `junction=yes`
** `place=county`
** `place=hamlet`
** `place=locality`
** `place=municipality`
** `place=neighbourhood`
** `place=populated`
** `place=province`
** `place=region`
** `place=state`
** `place=suburb`
** `place=town`
** `place=village`

Key/value pairs to ignore when deriving an implicit tags database from POI names. Use this list to
fine tune tagging rules behavior based on the auto-generated rules database. Format: `key=value`.
Use `key=*` to ignore all tags for a given key. Keep the list alphabetized and in lower case.

=== implicit.tagging.database.deriver.translate.names.to.english

* Data Type: bool
* Default Value: `false`

If true, the implicit tag raw rules deriver will translate name words to English as implicit tag
rules are derived.

=== implicit.tagging.database.deriver.use.schema.tag.values.for.words.only

* Data Type: bool
* Default Value: `true`

If true, the implicit tag raw rules generator will only consider words that correspond to a OSM tag
value in the schema.

=== implicit.tagging.database.deriver.word.ignore.list

* Data Type: list
* Default Value:
** `air`
** `and`
** `animal`
** `area`
** `art`
** `bake`
** `basin`
** `beach`
** `bed`
** `before`
** `bin`
** `block`
** `boat`
** `boutique`
** `box`
** `building`
** `buildings`
** `bureau`
** `bus`
** `camp`
** `car`
** `care`
** `center`
** `centre`
** `club`
** `city`
** `community`
** `community service`
** `company`
** `corner`
** `county`
** `country`
** `course`
** `court`
** `cross`
** `dairy`
** `dean`
** `department`
** `depot`
** `discount`
** `district`
** `dry`
** `education`
** `eng`
** `engineering`
** `entrance`
** `estate`
** `facility`
** `faculty`
** `fast`
** `first`
** `fish`
** `food`
** `for`
** `former`
** `free`
** `game`
** `garage`
** `gas`
** `gate`
** `general`
** `gold`
** `government`
** `ground`
** `guest`
** `hall`
** `health`
** `historical`
** `home`
** `homes`
** `host`
** `house`
** `housing`
** `hut`
** `information`
** `inlet`
** `institute`
** `island`
** `junction`
** `landing`
** `lane`
** `life`
** `light`
** `lot`
** `mini`
** `motor`
** `mud lake`
** `municipal`
** `national`
** `neighborhood`
** `number historical`
** `ocean`
** `office historical`
** `oil`
** `parish`
** `park road`
** `parts`
** `pet`
** `place`
** `plant`
** `platform`
** `plaza`
** `point`
** `post`
** `public`
** `recreation`
** `rental`
** `repair`
** `rescue`
** `reservoir number`
** `residence`
** `rest`
** `ride`
** `ring`
** `road`
** `rock`
** `sales`
** `sea`
** `service`
** `service station`
** `sport`
** `sports`
** `stand`
** `state`
** `station`
** `stop`
** `store`
** `street`
** `strip`
** `studio`
** `subdivision`
** `terminal`
** `the`
** `the box`
** `town`
** `track`
** `tree`
** `under`
** `village`
** `water`
** `wood`
** `zone`

Exact match words in names to always ignore when deriving an implicit tags database from POI names
(longer phrases containing these words will not be ignored). Use this list to fine tune tagging
rules behavior based on the auto-generated rules database. Items in this list generally are too
common and/or often have multiple meanings/applications. Keep the list alphabetized and in lower
case. Notes: 1) Would like to bring this one back and only match it at the end of the name: mission
2) Want to ignore this: center

=== implicit.tagging.element.criterion

* Data Type: string
* Default Value: `ImplicitTagEligiblePoiPolyCriterion`

Criterion class inheriting from `ImplicitTagEligibleCriterion`; The default,
`ImplicitTagEligiblePoiPolyCriterion`, derives tag information from POIs, buildings, and areas. To
pass in more complicated nested criteria, use the Javascript interface instead.

=== implicit.tagging.keep.temp.files

* Data Type: bool
* Default Value: `false`

If true, the implicit tag raw rules/database derivers will keep all temporary file output. For
debugging only.

=== implicit.tagging.max.cache.size

* Data Type: int
* Default Value: `10000`

The maximum cache size used by the implicit tag raw rules/database derivers.

=== implicit.tagging.name.cleaning.tokens

* Data Type: list
* Default Value:
** `(|e`
** `)|e`
** `.|e`
** `/|s`
** `<|e`
** `>|e`
** `[|e`
** `]|e`
** `@|e`
** `&|and`
** `(historical)|e`
** `-|s`

Tokens that should be ignored in names when deriving implicit type tagging rules or when
determining whether to type tag an element using implicit tagging. The format is:
"<token to replace>|<token to replace with>", where "e" is used to replace the token with an empty
string and "s" is used to replace the token with a single space. Anything else entered as replaced
text will be used as is.

=== implicit.tagging.raw.rules.deriver.skip.filtering

* Data Type: bool
* Default Value: `false`

If true, the implicit tag raw rules deriver will skip node filtering.  Only set to true if the input
data has been filtered with `ImplicitTagEligiblePoiCriterion` beforehand.

=== implicit.tagging.raw.rules.deriver.sort.parallel.count

* Data Type: int
* Default Value: `-1`

The number of parallel processes used when sorting output by the implicit tag raw rules deriver.
The default value of -1 uses a count equal to the number of processors on the machine. Valid values
are -1 or 1 up to the number of available processors.

=== implicit.tagging.translate.names.to.english

* Data Type: bool
* Default Value: `false`

If true, all implicit taggers will translate element name words to English before querying the
corresponding implicit tag rules database.

=== intersecting.way.criterion.source.way.ids

* Data Type: list
* Default Value:
** ``

List of way IDs to find intersecting ways for when using `IntersectingWayCriterion`.

=== javascript.schema.translator.path

* Data Type: list
* Default Value:
** `${HOOT_HOME}/translations`
** `${HOOT_HOME}/translations-local`
** `${HOOT_HOME}/rules`

A list of paths to include in the javascript translator search path.

=== in.bounds.criterion.bounds

* Data Type: string
* Default Value: ``

The bounding box used by `InBoundsCriterion`. See the `bounds` option for format detail.

=== in.bounds.criterion.strict

* Data Type: bool
* Default Value: `true`

If true, `InBoundsCriterion` requires features exist completely within `in.bounds.criterion.bounds`
in order for the criterion to be satisfied. If false, features that cross the bounds may also
satisfy the criterion.

=== jni.class.path

* Data Type: list
* Default Value:
** `${HOOT_HOME}/hoot-josm/target/hoot-josm.jar;${HOOT_HOME}/hoot-josm/target/dependency-jars/josm.jar`

A list of JAR files to place on the JAVA classpath where Hootenanny C++ code in the hoot-josm
project interacts with Hootenanny and JOSM Java code via JNI. At a minimum this path includes the
JOSM jar managed by `hoot-josm/pom.xml` (`josm.jar`) and the Hootenanny JOSM integration jar
(`hoot-josm.jar`). `hoot-josm.jar` should be placed before `josm.jar` in the path since it overrides
some of the class content in `josm.jar`.

=== jni.initial.memory

* Data Type: string
* Default Value: `256m`

JVM -Xms setting to use with hoot-josm JNI to configure the initial amount of memory available to
the JVM.

=== jni.max.memory

* Data Type: string
* Default Value: `2g`

JVM -Xmx setting to use with hoot-josm JNI to configure the maximum amount of memory available to
the JVM.

=== job.id

* Data Type: string
* Default Value: ``

This option allows for passing in a job ID for the currently executing command. This is useful when
trying to track multiple commands across a single job. When the Hootenanny API database is used
for job output storage, the ID will be stored in the job status table of the associated map.

=== josm.map.cleaner.add.detail.tags

* Data Type: bool
* Default Value: `false`

If true, cleaning/validation detail tags will be added to map outputs when cleaning maps with JOSM.

=== josm.map.validator.java.implementation

* Data Type: string
* Default Value: `hoot/josm/JosmMapValidator`

File path relative to root directory without file extension or prefixed namespace to Java class to
use as the JOSM Java map validator/cleaner implementation.

=== josm.max.elements.for.map.string

* Data Type: int
* Default Value: `2000000`

The maximum size in elements for a map allowed to be passed as a string between Hootenanny and JOSM.
The default value was determined experimentally and may need tweaking per environment.

=== josm.validators

* Data Type: list
* Default Value:
** `Addresses`
** `ApiCapabilitiesTest`
** `BarriersEntrances`
** `Coastlines`
** `ConditionalKeys`
** `ConnectivityRelations`
** `CrossingWays.Boundaries`
** `CrossingWays.SelfCrossing`
** `CrossingWays.Ways`
** `DirectionNodes`
** `DuplicateNode`
** `DuplicateRelation`
** `DuplicateWay`
** `DuplicatedWayNodes`
** `Highways`
** `InternetTags`
** `Lanes`
** `LongSegment`
** `MapCSSTagChecker`
** `MultipolygonTest`
** `NameMismatch`
** `OpeningHourTest`
** `OverlappingWays`
** `PowerLines`
** `PublicTransportRouteTest`
** `RelationChecker`
** `RightAngleBuildingTest`
** `SelfIntersectingWay`
** `SharpAngles`
** `SimilarNamedWays`
** `TagChecker`
** `TurnrestrictionTest`
** `UnclosedWays`
** `UnconnectedWays.UnconnectedHighways`
** `UnconnectedWays.UnconnectedNaturalOrLanduse`
** `UnconnectedWays.UnconnectedPower`
** `UnconnectedWays.UnconnectedRailways`
** `UnconnectedWays.UnconnectedWaterways`
** `UntaggedNode`
** `UntaggedWay`
** `WayConnectedToArea`
** `WronglyOrderedWays`

List of JOSM validator Java class names without namespace prefixes or file extensions (e.g.
`DuplicatedWayNodes`) to use during validation or cleaning. With each JOSM upgrade a check needs to
be made for new available validators by comparing the hardcoded list in the
`OsmValidator::CORE_TEST_CLASSES` member variable for the current version with the previous version.
See also: `hoot.validators`.

=== json.format.hootenanny

* Data Type: bool
* Default Value: `true`

Output JSON in a more specific way that includes metadata tags including `hoot:*`, `error:circluar`,
`type=node/way/relation`, tags in the `tags` section, etc.

`Generic Format`
-----
...
{
  "type":"Feature",
  "properties":{
    "type":"LineString",
    "REF1":"Panera",
    "access":{ "groups":[],"users":[] },
    "attributes":{
      "item_date":"2017-10-09T12:34:56.789Z",
      "category_id":"123456",
      "asset_id":"ABC123"
      },
    "alt_name":null,
    "building":"yes",
    "name":"Panera Bread",
    "item_type":[ "building","restaurant" ],
    },
  "geometry":{
    "type":"Polygon",
    "coordinates":[[[-104.8065566424573,39.59327717293566],
                    [-104.8061245919961,39.59330667331412],
                    [-104.8060931452853,39.59315284977403],
                    [-104.8065292974914,39.59311913497989],
                    [-104.8065566424573,39.59327717293566]]]
    }
},
...
-----
vs
`Hootenanny-specific Format`
-----
...
{
  "type":"Feature",
  "id":"-2",
  "properties":{
    "type":"way",
    "tags":{
      "REF1":"Panera",
      "access":{ "groups":[],"users":[] },
      "attributes":{
        "item_date":"2017-10-09T12:34:56.789Z",
        "category_id":"123456",
        "asset_id":"ABC123"
        },
      "alt_name":null,
      "building":"yes",
      "type":"way",
      "name":"Panera Bread",
      "item_type":[ "building","restaurant" ],
      "error:circular":"15"
      }
    },
  "geometry":{
    "type":"Polygon",
    "coordinates":[[[-104.8065566424573,39.59327717293566],
                    [-104.8061245919961,39.59330667331412],
                    [-104.8060931452853,39.59315284977403],
                    [-104.8065292974914,39.59311913497989],
                    [-104.8065566424573,39.59327717293566]]]
    }
},
...
-----

=== json.output.tasking.manager.aoi

* Data Type: bool
* Default Value: `false`

Output the GeoJSON in a format readable in Tasking Manager.  This includes per file or per feature
`source` tags and compatible geometries.

=== json.perserve.empty.tags

* Data Type: bool
* Default Value: `true`

Write out empty OSM tags to JSON such as `"text":""`.

=== json.pretty.print

* Data Type: bool
* Default Value: `false`

Write out JSON in a more legible manner.

=== language.detection.detector

* Data Type: string
* Default Value: `HootServicesLanguageDetectorClient`

`LanguageDetector` implementation to use for detecting source languages.  If using
`HootServicesLanguageDetectorClient`, a translation server must be set up and valid OAuth
credentials used.  Also, be sure to use an appropriate value for the `language.info.provider`
option.

=== language.detection.write.detected.lang.tags

* Data Type: bool
* Default Value: `false`

If true, source languages detected for tags will be written in new tags to output. If false, no
tags are written and only a summary of the source languages found will be printed at completion.

=== language.hoot.services.detection.min.confidence.threshold

* Data Type: string
* Default Value: `high`

The minimum language detection confidence threshold to use when detecting languages in text using
`HootServicesLanguageDetectorClient`. Valid values are: `low`, `medium`, `high`, or `none`.  =A
value of `none` or an empty string disables the threshold. Not all server side language detectors
specified in `language.hoot.services.detectors` support detection confidence. When listing server
side detectors via the API, confidence support information is included.

=== language.hoot.services.detectors

* Data Type: list
* Default Value:
** `TikaLanguageDetector`
** `OpenNlpLanguageDetector`

When using `HootServicesTranslatorClient` as the to English language translator or
`HootServicesLanguageDetectorClient` as a source language detector, one or more hoot-services Java
class names implementing `LanguageDetector`.  Language detectors are used in order of entry.
`hoot info --languages --detectors` displays information about the available server side detectors.
If no detectors are specified, then language translation will attempt to use as many detectors as
needed, in a pre-determined order, to get a positive detection.

=== language.info.provider

* Data Type: string
* Default Value: `HootServicesLanguageInfoClient`

`LanguageInfoProvider` implementation to use for determining language information needed by to
English translation. If using `HootServicesLanguageInfoClient`, a translation server must be
set up and valid OAuth credentials used.

=== language.max.cache.size

* Data Type: long
* Default Value: `10000`

Maximum result cache sized used for to English translation and source language detection.  Not
necessarily honored by all translators/detectors. A cache size of -1 disables the translation
cache.

=== language.ignore.pre.translated.tags

* Data Type: bool
* Default Value: `false`

If true and performing a to English translation with `ToEnglishTranslationVisitor`, the translator
will skip attempting to translate any tags whose owning elements have a pre-translated English tag
(`key=<tag name>:en`). If true and performing a non-English source language detection with
`NonEnglishLanguageDetectionVisitor`, the detector will ignore the fact that an English
pre-translated tag already exists on the associated element and attempt to detect the source
language of the pre-translated tag.

=== language.parse.names

* Data Type: bool
* Default Value: `false`

When performing a to English translation or source language detection, the translator/detector
by default uses the required `language.tag.keys` configuration option to determine which tags to
translate or detect source languages for.  If this option is enabled, `language.tag.keys` is no
longer a required option and all name tags will be parsed during translation/detection.  If
`language.tag.keys` is populated in addition to enabling this option, then any tag keys in
`language.tag.keys` that are not names will be parsed in addition to the name tags.

=== language.skip.words.in.english.dictionary

* Data Type: bool
* Default Value: `true`

When performing a to English translation or source language detection, the translator/detector
will skip the translation of any tags whose value is in an English dictionary.

=== language.tag.keys

* Data Type: list
* Default Value:
** ``

A list of keys of tags whose values are to either be translated to English by a
`ToEnglishTranslationVisitor` or just have their source languages detected by a
`LanguageDetectionVisitor` depending on the operation being performed.

=== language.translation.comparison.pretranslated.tag.keys

* Data Type: list
* Default Value:
** ``

A list of tag keys whose values are known to have been previously translated to the desired target
language. The list ordering should correspond to that of language.tag.keys.

=== language.translation.comparison.scorer

* Data Type: string
* Default Value: `LevenshteinDistance`

`StringDistance` implementation used to score to English translated tag values

=== language.translation.detected.language.overrides.specified.source.languages

* Data Type: bool
* Default Value: `false`

If source languages are specified that do not match the detected language for piece of text during
translation, setting this to true allows the detected language to override the specified source
languages.

=== language.translation.hoot.services.translator

* Data Type: string
* Default Value: `HootLanguageTranslator`

When using `HootServicesTranslatorClient` as the to English language translator, a
hoot-services Java class names implementing ToEnglishTranslator.  Valid values are
`JoshuaLanguageTranslator` and `HootLanguageTranslator`.

=== language.translation.perform.exhaustive.search.with.no.detection

* Data Type: bool
* Default Value: `false`

If more than one source language is specified for to English translation and the correct
source language cannot be detected, translation attempts will be made against each specified
languages until a translation is found.  Enabling this option can have a large impact on translation
performance due to language detection cost.

=== language.translation.source.languages

* Data Type: list
* Default Value:
** ``

ISO-639-1 language codes for the source languages for to English translation
(https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes).  Also, you can specify a single list item,
"detect", to attempt to auto-detect the appropriate source language before translation.  Specifying
multiple source languages can have a large impact on translation performance due to language
detection cost.

=== language.translation.string.distance.tokenize

* Data Type: bool
* Default Value: `true`

Set to true if the strings should be tokenized (split into words) before translating the values.
Only applies if `language.translation.translator` is set to `ToEnglishDictionaryTranslator`.

=== language.translation.string.distance.translate.all

* Data Type: bool
* Default Value: `true`

If true and `language.translation.translator` is set to `ToEnglishDictionaryTranslator`, will
attempt to retrieve multiple translations when scoring string comparisons.  Otherwise, only a single
translation is retrieved.

=== language.translation.translator

* Data Type: string
* Default Value: `HootServicesTranslatorClient`

`ToEnglishTranslator` implementation to use for to English translation.
`HootServicesTranslatorClient`, requires a translation server be set up and valid OAuth
credentials used.  Also, be sure to use an appropriate value for the `language.info.provider`
option.

=== levenshtein.distance.alpha

* Data Type: double
* Default Value: `1.15`

Raise the Levenshtein score to this power before returning this result. If alpha is greater than
1 then this makes low scores even lower. Valid values are > 0.

The default value was determined through experimentation with a Jakarta data set using
`MeanWordSetDistance` as the container classes. See Redmine ticket #2349 for some experiment
details. The "best" value varies depending on the input data as well as how the data is being used.

=== libpostal.data.dir

* Data Type: string
* Default Value: `/usr/share/libpostal`

Absolute path to the directory where the libpostal library, used for address parsing, stores its
data.

=== log.class.exclude.filter

* Data Type: list
* Default Value: ``

A list of class names used for controlling logging. If the list is not empty, all classes in this
list will not be allowed to write log statements. An empty list disables the filtering completely.
Wildcard regular expressions with '*' are allowed. `log.class.include.filter` is overriden by this
option.

=== log.class.include.filter

* Data Type: list
* Default Value: ``

A list of class names used for controlling logging. If the list is not empty, only classes in this
list will be allowed to write log statements. An empty list disables the filtering completely.
Wildcard regular expressions with '*' are allowed. `log.class.exclude.filter` overrides this option.

=== log.warn.message.limit

* Data Type: int
* Default Value: `3`

The maximum number of warn log messages that will be emitted per class before they are silenced.
A value of -1 passed to class will ensure that no warnings are logged by it, if it honors the
option. A setting of -1 is useful for tests where you do not have granular enough logging control.

=== log.warnings.for.completely.untyped.input.maps

* Data Type: bool
* Default Value: `true`

If true, warnings are logged any time an input map is loaded for conflation that does not contain
any feature with a type recognizable by the schema. This is generally only turned off when running
tests.

=== log.warnings.for.empty.input.maps

* Data Type: bool
* Default Value: `true`

If true, warnings are logged any time an empty map is loaded. This is generally only turned off
when running tests.

=== log.warnings.for.missing.elements

* Data Type: bool
* Default Value: `true`

Determines whether references in parent elements to child elements which do not exist in the input
trigger warning log messages.

[[MapCleanerTransforms]]
=== map.cleaner.transforms

* Data Type: list
* Default Value:
** `ReprojectToPlanarOp`
** `InvalidWayRemover`
** `DuplicateNodeRemover`
** `RemoveDuplicateWayNodesVisitor`
** `OneWayRoadStandardizer`
** `DuplicateWayRemover`
** `SuperfluousWayRemover`
** `IntersectionSplitter`
** `UnlikelyIntersectionRemover`
** `DualHighwaySplitter`
** `HighwayImpliedDividedMarker`
** `DuplicateNameRemover`
** `SmallHighwayMerger`
** `RemoveEmptyAreasVisitor`
** `RemoveDuplicateRelationMembersVisitor`
** `RelationCircularRefRemover`
** `RemoveInvalidMultilineStringMembersVisitor`
** `RemoveEmptyRelationsOp`
** `RemoveDuplicateAreasVisitor`
** `NoInformationElementRemover`

A list of map operations to be applied to a map for cleaning purposes, in order.
`hoot info --operators` displays information about the available transforms.

=== map.comparator.ignore.tag.keys

* Data Type: list
* Default Value: ``

A list of tag keys that `MapComparator`, used by the `diff` command, will ignore when comparing
maps.

=== map.comparator.print.full.mismatch.elements.on.map.size.diff

* Data Type: bool
* Default Value: `false`

If true, when comparing maps with the `compare` command it will print out the details for all
elements identified as different between the two maps when there is a size difference (up to a
default limit). This is useful in debugging remote test errors.

=== map.factory.reader

* Data Type: string
* Default Value: ``

Specifies the reader that the `OsmMapReaderFactory` will use. This overrides any information derived
from the URL.

=== map.factory.writer

* Data Type: string
* Default Value: ``

Specifies the writer that the `OsmMapWriterFactory` will use. This overrides any information derived
from the URL.

=== map.merge.ignore.duplicate.ids

* Data Type: bool
* Default Value: `false`

Option to allow for multiple datasets to be merged into one dataset, while ignoring duplicate
element IDs. This allows for two neighboring cells to contain the same way that spans both cells
and is included in both datasets to not be duplicated when read in.

=== map.reader.add.child.refs.when.missing

* Data Type: bool
* Default Value: `false`

By default, file based readers will not add child references (node ref, elements members) to parent
elements if those elements are not present in the data.  For external sorting and translations
where partial chunks of elements only may be present, or workflows where you are working with
remote sourced data with missing element children, the default value may need to be changed. This
option is not supported by all file based readers.

=== map.stitcher.threshold

* Data Type: double
* Default Value: `3`

Size, in meters, of the overlap buffer on either side of the intersection of maps where the maps
are stitched.  All endpoints of ways in both maps inside this buffer are considered for the stitching
process.

=== map.writer.schema

* Data Type: string
* Default Value: ``

Sets the value for a `schema` attribute when writing a map to OSM XML. NOTE: this will only be
written if the value is not empty.

=== map.writer.skip.empty

* Data Type: bool
* Default Value: `false`

If true, the OSM map writer will NOT write a file if the map is empty. The default is to write a
file even if the map is empty.

[[match.creators]]
=== match.creators

* Data Type: list
* Default Value:
** `BuildingMatchCreator`
** `HighwayMatchCreator`
** `PoiPolygonMatchCreator`
** `ScriptMatchCreator,Area.js`
** `ScriptMatchCreator,River.js`
** `ScriptMatchCreator,Poi.js`
** `ScriptMatchCreator,Railway.js`
** `ScriptMatchCreator,PowerLine.js`
** `ScriptMatchCreator,Point.js`
** `ScriptMatchCreator,Line.js`
** `ScriptMatchCreator,Polygon.js`
** `ScriptMatchCreator,PointPolygon.js`
** `ScriptMatchCreator,Relation.js`

List of match creators to use during conflation. This can modify what features will be conflated
(e.g. buildings, roads, etc.).  The ordering must match that in `merger.creators`.
`hoot info --matchers` displays information about the available matchers.

=== match.parallel.exponent

* Data Type: double
* Default Value: `1`

Used in the calculation of the match parallel score, cos (delta) ^ match.parallel.exponent

=== max.elements.per.partial.map

* Data Type: long
* Default Value: `100000`

Maximum number of elements that will be read into memory at one time during a partial OSM map
reading. This shouldn't need to be changed.  Reducing the value may cause errors on some data
formats that read large numbers of entries at one time. Increasing the value will use more RAM in
some situations.

=== max.memory.usage

* Data Type: string
* Default Value: `-1`

Allows for artificially limiting the amount of virtual memory that is used. If more than this amount
of virtual memory is needed then a bad_alloc will likely be thrown. In some cases you will receive a
totally unrelated error message.

Size is specified in bytes unless followed by one of these suffixes.

* KB = size * 1000
* MB = size * 1000 * 1000
* GB = size * 1000 * 1000 * 1000

For instance, setting the value to 500KB is equivalent to 500000 bytes.

The Linux utility RLIMIT_AS is used for limiting virtual memory. This is analagous to RAM, but
less RAM will be utilized than the value specified. Typically this is most useful when limiting
RAM usage of applications in a shared server environment.

=== maximal.subline.max.recursions

* Data Type: int
* Default Value: `-1`

Maximum recursive calls allowed in when using maximal subline matching during conflation. A value of
-1 indicates an internally determined limit. Setting this too low may degrade linear conflate
performance. Setting it too high may result in runaway line matching processing times.

=== maximal.subline.spacing

* Data Type: double
* Default Value: `2.0`

Spacing in meters used by the MaximalSublineMatcher during point discretization performed between
matching ways. Larger values may increase runtime performance but decrease conflation quality.

=== max.tag.length

* Data Type: int
* Default Value: `255`

The OSM API imposes a 255 character limit to tag values even though the database doesn't. It is
possible to update the OSM API to a different limit and allow for a larger upper limit to tag
key/value pairs.

=== memory.usage.checker.enabled

* Data Type: bool
* Default Value: `true`

Determines whether memory usage checking is enabled.

=== memory.usage.checker.interval

* Data Type: int
* Default Value: `100000`

If memory usage checking is run in an element processing loop, use this to control how often a
memory usage check is made.

=== memory.usage.checker.threshold

* Data Type: int
* Default Value: `95`

Percentage value (1 to 100) of used system memory above which memory usage checking logs a
notification. The same threshold value is used separately for both used physical and virtual memory.

[[merger.creators]]
=== merger.creators

* Data Type: list
* Default Value:
** `BuildingMergerCreator`
** `HighwayMergerCreator`
** `PoiPolygonMergerCreator`
** `ScriptMergerCreator`
** `ScriptMergerCreator`
** `ScriptMergerCreator`
** `ScriptMergerCreator`
** `ScriptMergerCreator`
** `ScriptMergerCreator`
** `ScriptMergerCreator`
** `ScriptMergerCreator`
** `ScriptMergerCreator`
** `ScriptMergerCreator`

List of merger creators to use during conflation. This can modify what features will be conflated
(e.g. buildings, roads, etc.). The ordering must match that in `match.creators`.
`hoot info --mergers` displays information about the available mergers.

=== metadata.dataset.indicator.tag

* Data Type: list
* Default Value:
** `source:metadata`
** `dataset`

Single tag/value pair indicating that an element is a dataset used as import source or export
destination for metadata values.

=== metadata.grid.cell.size

* Data Type: double
* Default Value: `0.25`

Cell size of the dataset grid created when exporting metadata tags to dataset elements. If this
value is set to 0 a single polygon using the bounds of the source data is being created instead.

=== metadata.tags

* Data Type: list
* Default Value:
** `attribution`
** `test-attribution`
** `source`
** `test-source`

List of tag/value pairs of metatdata tags with default values to be distributed (import) or
collected (export).

=== multilinestring.relation.collapser.types

* Data Type: list
* Default Value:
** `*`

A list of type keys or key/value pairs eligible for moving from multilinestring relations to
their relation members when using `MultilineStringMergeRelationCollapser`. Use a single list with
the item, '*', to collapse relations of any type.

=== name.criterion.case.sensitive

* Data Type: bool
* Default Value: `false`

If true, `NameCriterion` will only identify names whose case matches exactly with the name values in
`name.criterion.names`. If false, the cases of the names do not have to match.

=== name.criterion.names

* Data Type: list
* Default Value: ``

A list of names to use with `NameCriterion`.

=== name.criterion.partial.match

* Data Type: bool
* Default Value: `false`

Determines whether `NameCriterion` allows partial name matching against the `name.criterion.names`
input. Partial matching is very basic, where the input name string must be contained within the
feature name in order to match.

=== network.conflicts.aggression

* Data Type: double
* Default Value: `8.8`

A larger value will conflate more aggressively (fewer reviews) when using network conflation. Users
may want to consider changing this value. Reasonable range is [1, ~10].

=== network.conflicts.conflicting.score.threshold.modifier

* Data Type: double
* Default Value: `0.3`

Added to a conflicting match score to allow for match pruning

=== network.conflicts.matcher.threshold

* Data Type: double
* Default Value: `0.35`

The score threshold used to compare whole networks with the `ConflictsNetworkMatcher`. The valid
range is (0.0, 1.0].

=== network.conflicts.outbound.weighting

* Data Type: double
* Default Value: `0.25`

A value of 0 will cause an edge to contribute (1 * score * weight) to each neighbor when using
network conflation. A value of 1 will give approx (1 / n * score * weight) influence to each
neighbor. This value is generally not changed by users. A reasonable range is [0, 2].

=== network.conflicts.partial.handicap

* Data Type: double
* Default Value: `0.2`

A larger value will increase the weight of partial matches when using network conflation. A
smaller value prefers whole matches over partial matches. This value is generally not changed by
users. A reasonable range is (0, ~2].

=== network.conflicts.sanity.check.min.separation.distance

* Data Type: double
* Default Value: `5.0`

Minimum separation distance, in meters, for match distance separation to use when sanity checking
match relationships.

=== network.conflicts.sanity.check.separation.distance.multiplier

* Data Type: double
* Default Value: `2.5`

Distance multiplier to use when santiy checking match relationships.

=== network.conflicts.stub.handicap

* Data Type: double
* Default Value: `1.7`

A larger value will increase the weight of stubs when using network conflation. This value is
generally not changed by users. A reasonable range is (0, ~2].

=== network.conflicts.stub.through.weighting

* Data Type: double
* Default Value: `0.5`

A value of 0 will cause edges that are connected by a stub to contribute directly as neighbors when
using network conflation.  Higher values will reduce that contribution. This value is generally
not changed by users. A reasonable range is [0, ~10].

=== network.conflicts.weight.influence

* Data Type: double
* Default Value: `0.68`

A value of 0 will cause all edges to have the same weight with each neighbor, a higher value will
give matches with more support a higher weight when using network conflation. This value is
generally not changed by users. A reasonable range is [0, 2].

=== network.edge.match.set.finder.max.iterations

* Data Type: int
* Default Value: `20`

The maximum number of optimization iterations used to calculate edge match sets.

=== network.match.scoring.function.max

* Data Type: double
* Default Value: `1.0`

Maximum possible value for the logistic function applied to conflation matches with the Network
Algorithm. This value is generally not changed by users.

=== network.match.scoring.function.curve.mid.x

* Data Type: double
* Default Value: `0.5`

X value curve midpoint value for the logistic function applied to conflation matches with the
Network Algorithm. This value is generally not changed by users.

=== network.match.scoring.function.curve.steepness

* Data Type: double
* Default Value: `2.0`

Curve steepness value for the logistic function applied to conflation matches with the Network
Algorithm. This value is generally not changed by users.

=== network.match.threshold

* Data Type: double
* Default Value: `0.15`

The threshold at which a network match is called a match when using network conflation. The valid
range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== network.matcher

* Data Type: string
* Default Value: `ConflictsNetworkMatcher`

An internal option for manipulating the way network matching occurs. This should only be used for
debug and test. The parameter must be a class that is registered with the factory and subclasses
`NetworkMatcher`.

=== network.max.stub.length

* Data Type: double
* Default Value: `20.0`

The maximum allowable length of a stub connection (way to node match) when using network conflation.
Value in meters.

=== network.merger.min.large.match.overlap.percentage

* Data Type: double
* Default Value: `80.0`

The minimum network match overlap percentage allowed for a network merge to occur.

=== network.miss.threshold

* Data Type: double
* Default Value: `0.85`

The threshold at which a network miss is called a miss. The valid range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== network.optimization.iterations

* Data Type: int
* Default Value: `10`

The number of optimization iterations the network match creator will run when performing network
conflation.

=== network.partial.match.min.valid.score

* Data Type: double
* Default Value: `0.01`

This is the minimum valid similarity score for partial matches created by the Network Algorithm
during conflation. Setting the value lower will create more (likely overzealous) matches. Setting
the value higher will drop less confident matches.

=== network.review.threshold

* Data Type: double
* Default Value: `0.5`

The threshold at which a network review is called a review. Reviews are also declared in some
other situations when the relationship is not clear. The valid range is (0.0, 1.0].

See also:

 * _Estimate Pairwise Relationships_, <<hootuser>>

=== network.subline.max.cache.size

* Data Type: int
* Default Value: `100000`

The maximum subline cache size used by the Network Algorithm during conflation.

=== node.comparison.circular.error.sensitivity

* Data Type: int
* Default Value: `6`

The number of decimal places taken into account when comparing node circular error values. Used by
node hash calculation.

=== node.comparison.coordinate.sensitivity

* Data Type: int
* Default Value: `7`

The number of decimal places taken into account when comparing node coordinates. Used by node
hash calculation.

=== node.matcher.angle.calc.delta

* Data Type: double
* Default Value: `0.001`

The distance moved along a way, in meters, before calculating the outbound heading for a node on
that way by the `NodeMatcher`.

=== node.matcher.fail.on.bad.angle.spots

* Data Type: bool
* Default Value: `false`

If false, the `NodeMatcher` will allow angle calculation if any situations are found where it is
passed a node which is not at the beginning or end of a way.  If true, it will fail in the
aforementioned situation.

=== node.matcher.strictness

* Data Type: double
* Default Value: `2`

Determines how strictly the angle should be considered when calculating intersection tie points for
rubber sheeting. A value of 0 will ignore angle entirely. Large will make the angle comparison more
strict.

=== nodes.per.way.visitor.element.criterion

* Data Type: string
* Default Value: ``

An element criterion to be used for filtering ways whose nodes are counted. The elements must be
ways for their nodes to be counted, otherwise the criterion will be ignored.

=== non.conflatable.criterion.ignore.relation.members

* Data Type: bool
* Default Value: `false`

If false, in order for a relation to be deemed not conflatable all of its members must also not be
conflatable. If true, a relation can be deemed not conflatable even if any of its members are also
conflatable.

=== non.osm.convert.merge.nearby.nodes

* Data Type: bool
* Default Value: `true`

Merges nearby nodes together when converting from a non-OSM format to OSM.

=== non.osm.convert.simplify.complex.buildings

* Data Type: bool
* Default Value: `false`

Implicitly merges certain individual building parts into a single part when converting from a non-OSM
format to OSM.

=== offset.intersection.max

* Data Type: double
* Default Value: `5`

The offset intersection merger joins two closely spaced intersections within this max threshold to
form one single intersection.

=== ogr.add.uuid

* Data Type: bool
* Default Value: `true`

If true, translation files will add a UUID to features.

=== ogr.append.data

* Data Type: bool
* Default Value: `false`

If the OGR output file/layer exists when exporting, append the data instead of trying to create a
new file/layer.

=== ogr.debug.addfcode

* Data Type: bool
* Default Value: `false`

Debugging: Add the FCODE as the OSM source:fcode tag during translation.

=== ogr.debug.dumptags

* Data Type: bool
* Default Value: `false`

Debugging: Print out Attributes and OSM Tag values during translation. For each feature, this will
show what keys and values go into the translation and what the translated output is.

=== ogr.debug.dumpvalidate

* Data Type: bool
* Default Value: `false`

Debugging: Print out which attributes are dropped during export validation.

=== ogr.debug.lookupclash

* Data Type: bool
* Default Value: `false`

Debugging: When building internal lookup tables, print values that clash.

=== ogr.debug.lookupcolumn

* Data Type: bool
* Default Value: `false`

Debugging: Print the columns that are not matched during one2one translation. This will show all
Attribute columns and values that do not match a one2one rule.

=== ogr.esri.fcsubtype

* Data Type: bool
* Default Value: `true`

Add the ESRI specific FCSUBTYPE field to the output.

=== ogr.esri.fdname

* Data Type: string
* Default Value: `TDS`

The name to use for the ESRI Feature Dataset on export. Note: This only applies to ESRI File
Geodatabases.

=== ogr.text.field.number

* Data Type: int
* Default Value: `8`

The maximum number of O2S_[P,L,A] tags attributes and OSMTAGS attributes to create when writing a translated schema to a shapefile.
Unused OSM tags and values will be split and stored in these fields on export.

=== ogr.import.filter

* Data Type: string
* Default Value: ``

The regexp to be used to filter the layer names when importing layers from an ESRI File
Geodatabase. The default is to import all layers from a FGDB.  Setting this variable will
override the filter value that can be set by the layerNameFilter function inside a translation
script.

=== ogr.note.extra

* Data Type: string
* Default Value: `attribute`

When exporting to TDSv40 and TDSv61:
- "attribute" Add unused tags to the "ZI006_MEM" field.
- "file" Save the unused tags in a new layer (extra_[PLA]).
- "none" Don't save the unused tags, just drop them.

When exporting to MGCP:
- "attribute" Add unused tags to the "TXT" field.
- "file" Save the unused tags in a new layer (extra_[PLA]).
- "none" Don't save the unused tags, just drop them.

NOTE: According to the MGCP and Shapefile specifications, the "TXT" field has a maximum length of
255 characters. Extra text will be truncated.

=== ogr.reader.bounding.box.latlng

* Data Type: bool
* Default Value: `false`

If true, then the coordinates specified by `bounds` are assumed to be in the WGS84 coordinate
system.

A best effort will be made to convert between the two projections. The translated bounding box
will approximate the minimum bounding rectangle of the lat/lng bounding box. In some cases this
may be significantly larger.

=== ogr.reader.csv.keep.geom.fields

* Data Type: string
* Default Value: `NO`

From the GDAL docs:
If YES, the detected X,Y,Z or geometry columns will be stored as regular attribute fields.

=== ogr.reader.csv.latfield

* Data Type: string
* Default Value: `Lat*,lat*,LAT*`

From the GDAL docs:
A comma separated list of possible names for Y/latitude coordinate of a point. Each name might be a
pattern using the star character in starting and/or ending position. E.g.: prefix*, *suffix or
*middle*. The values in the column must be floating point values.

=== ogr.reader.csv.lonfield

* Data Type: string
* Default Value: `Lon*,lon*,LON*`

From the GDAL docs:
A comma separated list of possible names for X/longitude coordinate of a point. Each name might be
a pattern using the star character in starting and/or ending position. E.g.: prefix*, *suffix or
*middle*. The values in the column must be floating point values.

=== ogr.reader.csv.zfield

* Data Type: string
* Default Value: `Z,z`

From the GDAL docs:
A comma separated list of possible names for Z/elevation coordinate of a point. Each name might
be a pattern using the star character in starting and/or ending position. E.g.: prefix*, *suffix
or *middle*. The values in the column must be floating point values.

=== ogr.reader.epsg.override

* Data Type: int
* Default Value: `-1`

If specified the OGR reader will override the reported projection with the specified EPSG code. If
the value is < 0 then the projection reported by the source data set will be used. In most cases
the default value is fine.

This can sometimes be necessary when reading from a DB created with osm2pgsql. E.g.

----
hoot convert -D ogr.reader.epsg.override=900913 PG:"dbname='gis' host='localhost' port='5432' user='hoot' password='blahblah'" tmp/output.shp
----

=== ogr.reader.limit

* Data Type: int
* Default Value: `0`

Optional maximum number of OGR features to read from an input file. This can be useful when
debugging. A value < 1 indicates that there is no limit.

=== ogr.reader.node.id.field.name

* Data Type: string
* Default Value: ``

If set, the ogr reader will use the value at the specified field to populate node IDs.

=== ogr.reader.ogdi.launder.layer.names

* Data Type: string
* Default Value: `yes`

GDAL Option: When reading OGDI datasources (VPF etc), setting this to 'yes' causes the layer names
to be simplified. For example : watrcrsl_hydro instead of 'watrcrsl@hydro(*)_line'

=== ogr.output.format

* Data Type: string
* Default Value: ``

This is used to pass the output format (file extension: shp, gdb etc) to translation scripts to
enable output format specific translations. e.g. Setting this to 'shp' would be telling the
translation script to shorten attribute names to 10 characters and keep text attributes below the
255 character maximum length.

=== ogr.split.o2s

* Data Type: bool
* Default Value: `false`

If the list of o2s tags is > 255 char, split it into into 254 char long pieces. If this is false,
it will be exported as one big string.

=== ogr.strict.checking

* Data Type: string
* Default Value: `on`

Turn OGR related errors into warnings or turn them off. Valid values are: `on`, `off`, or `warn`.

=== ogr.tds.add.etds

* Data Type: bool
* Default Value: `true`

Add the eLTDS specific attributes (`SCAMIN`, `SCAMAX`, `LINK_ID`) to the output.

=== ogr.tds.extra

* Data Type: string
* Default Value: `note`

When exporting to TDSv40 and TDSv61:
- "note" Add unused tags to the "ZI006_MEM" field.
- "file" Save the unused tags in a new layer (extra_[PLA]).
- "none" Don't save the unused tags, just drop them.

NOTE: If exporting to Shapefile, this field will be truncated to 255 characters.

=== ogr.thematic.structure

* Data Type: bool
* Default Value: `true`

Where applicable, export data in Thematic Groups (TransportationGroundCrv, StructurePnt etc)
instead of one FCODE per file/layer (ROAD_L, BUILDING_P etc).

=== ogr.throw.error

* Data Type: bool
* Default Value: `false`

For the schema switcher, throw errors instead of returning a partial translation/o2s_X feature
from a translation.

=== ogr.writer.create.all.layers

* Data Type: bool
* Default Value: `false`

Create all layers when using the OGR writer whether or not the layers contain features. Setting
this to true can be useful when conforming to strict specifications.

=== ogr.writer.pre.layer.name

* Data Type: string
* Default Value: ``

Text prepended to a layer name when writing an OGR format.

=== ogr.writer.script

* Data Type: string
* Default Value: ``

Set the script to use with OGR writer. For example:

----
hoot convert \
  -D ogr.writer.script=test-files/io/SampleTranslation.js \
  -D ogr.writer.pre.layer.name=bar \
  test-files/io/SampleTranslation.osm \
  PG:"dbname='osm_gis2' host='localhost' port='5432' user='hoot' password='hoottest'"
----

=== osmapidb.bulk.inserter.disable.database.constraints.during.write

* Data Type: bool
* Default Value: `false`

If true, the OSM API database writer drops the database constraints before writing the data and
re-enables them after the writing is complete.  This can only be used with databases that have been
taken offline from other users.

=== osmapidb.bulk.inserter.disable.database.indexes.during.write

* Data Type: bool
* Default Value: `false`

If true, the OSM API database writer drops the database indexes before writing the data and
re-enables them after the writing is complete.  This can only be used with databases that have been
taken offline from other users.

=== osmapidb.bulk.inserter.reserve.record.ids.before.writing.data

* Data Type: bool
* Default Value: `false`

If true, the OSM API database writer will update the database to reserve the range of record IDs
parsed from the input data *before* writing the data to output. IMPORTANT: This option should
always be enabled in online environments (other writers present). If it is not enabled in online
environments, the risk of record ID conflicts will be present in the database. The output
destination must be an OSM API database or this setting will always be treated as being "false".
If the output destination is a SQL file, the SQL statements to update the record IDs will be
written to the SQL output for later execution.

=== osmapidb.bulk.inserter.write.sql.file.id.sequence.updates

* Data Type: bool
* Default Value: `true`

If true, the OSM API database bulk inserter write element ID sequence update SQL statements when
the output is a SQL file.  If false, the ID update statements will not be written.

=== osmapidb.id.aware.url

* Data Type: string
* Default Value: ``

This is required when using either the `OsmApiDbAwareHootApiDbReader` or the
`OsmApiDbAwareHootApiDbWriter` It forces database reading/writing use the specified OSM API database
as master for determining the sequencing of element ID's.

=== osm.add.bbox.tag

* Data Type: bool
* Default Value: `false`

Add a tag with the bounding box for each element

=== overpass.api.host

* Data Type: string
* Default Value: `overpass-api.de`

Overpass API URL host name. Used by the JSON readers to distinguish Overpass JSON web sources from
GeoJSON web sources.

=== pbf.writer.compression.level

* Data Type: int
* Default Value: `-1`

The compression level to use when writing an OSM PBF. Valid values are -1 to 9. -1 is "default" or equivalent to about 7.
0 is uncompressed. 1 is fastest. 9 is best compression.

=== pbf.writer.flush.output

* Data Type: bool
* Default Value: `true`

When `true`, the OSM PBF writer will regularly flush the output.

=== pbf.writer.granularity

* Data Type: int
* Default Value: `100`

The granularity of the written OSM PBF. The granuarlity is in units of nanodegrees. The larger the value the coarser the data
stored, but potentially higher compression. The default of 100nm introduces about 8.5mm of error on average and 15.5mm of
error maximum with 2000 random points.

=== pbf.writer.include.version

* Data Type: bool
* Default Value: `true`

Removes the version number from the output when writing OSM PBF. This is only useful for unit testing.

=== perty.csm.D

* Data Type: double
* Default Value: `1000`

The PERTY D value. D is used in e ^ (-`perty.grid.spacing` / D). Defaults to 1000. Larger values
result in a more correlated permutation grid.

=== perty.grid.spacing

* Data Type: double
* Default Value: `100`

The size of the PERTY grid spacing in meters.

=== perty.ops

* Data Type: list
* Default Value:
** `RandomWaySplitter`
** `RandomWayGeneralizer`
** `RandomElementRemover`
** `RandomNodeDuplicator`
** `RandomTagModifier`
** `RandomElementRenamer`

A list of operations that should be applied after the geometries have been shifted by PERTY.
`hoot info --operators | grep Random` displays information about the available operations.

=== perty.search.distance

* Data Type: double
* Default Value: `15`

Distance parameter (in meters) that determines how far out to search when trying to match features
during conflation of reference and perturbed datasets. This is equivalent in nature to the
circular error tag used in conflation, however this setting is used instead for PERTY scoring only.

=== perty.systematic.error.x

* Data Type: double
* Default Value: `50`

The sigma sx parameter, in meters, for PERTY. This controls how much correlated error in the X
direction is in the output permutation.

=== perty.systematic.error.y

* Data Type: double
* Default Value: `50`

The sigma sy parameter, in meters, for PERTY. This controls how much correlated error in the Y
direction is in the output permutation.

=== perty.test.allowed.score.variance

* Data Type: double
* Default Value: `0.025`

A score variance in the range [0.0, 1.0], by which a `perty-test` test run score may vary while
still allowing the test run's status to be described as passing. Test run score differences larger
than this value will cause the test run's status to be described as failing. If you are not sure
what your expected scores should be and want to bypass this check, create a list with all entries
equal to "1.0" of the same size as `perty.test.num.runs`, and then set
`perty.test.allowed.score.variance` to "1.0". This effectively disables the score validation.

=== perty.test.dynamic.variable.increment

* Data Type: double
* Default Value: `0.1`

Amount by which the dynamic input variables specified in `perty.test.dynamic.variables` are
incremented during each test run by `perty-test`.

=== perty.test.dynamic.variable.start.value

* Data Type: double
* Default Value: `0`

Dynamic variable value initially assigned to a PERTY test dynamic variable when executed by
`perty-test`.

=== perty.test.dynamic.variables

* Data Type: list
* Default Value:
** ``

A list of one or more numeric PERTY variables to be assigned a start value (specified in
`perty.test.dynamic.variable.start.value`) and then incremented once per test run by `perty-test`
(specified in `perty.test.dynamic.variable.increment`) to the value of. The list is restricted to
PERTY options (`perty.*`) of a numeric type only.

=== perty.test.expected.scores

* Data Type: list
* Default Value:
** `1.0`

A list of expected PERTY scores in the range of, in the range [0.0, 1.0], for a `perty-test` run.
The number of scores must match the value assigned to `perty.test.num.runs`. If you are not sure
what your expected scores should be and want to bypass this check, create a list with all entries
equal to "1.0" of the same size as `perty.test.num.runs`, and then set
`perty.test.allowed.score.variance` to "1.0". This effectively disables the score validation.

=== perty.test.fail.on.better.score

* Data Type: bool
* Default Value: `false`

If true, the `perty-test` will mark a test as failing if its test run score is higher than the
expected score and outside of the allowable score variance; if false, will always allow higher
test run scores to result in a passing test run, despite being outside of the allowable score
variance.

=== perty.test.generate.map.stats

* Data Type: bool
* Default Value: `false`

If true, map statistics files are output for all PERTY outputs created by `perty-test`.

=== perty.test.num.runs

* Data Type: int
* Default Value: `1`

The number of test runs executed by `perty-test`. A single input variable, or multiple variables
(specified in `perty.test.dynamic.variable`) assigned identical starting values (specified in
`perty.test.dynamic.variable.start.value`), is/are altered by an increment during each test
(specified in `perty.test.dynamic.variable.increment`).

=== perty.test.num.simulations

* Data Type: int
* Default Value: `3`

The number of simulations per test run executed by `perty-test`. A test run is made up of
multiple simulations.  Scores all simulation executed by the test run are averaged to give the
final PERTY score for the test run.

=== phone.number.additional.tag.keys

* Data Type: list
* Default Value:
** ``

By default, conflation examines all tags with keys containing the text "phone" for phone number
comparisons. You can expand the tag keys searched by populating this list.

=== phone.number.normalization.format

* Data Type: string
* Default Value: `NATIONAL`

The phone number format used when normalizing phone numbers. Valid values are: `E164`,
`INTERNATIONAL`, `NATIONAL`, and `RFC3966`.

=== phone.number.region.code

* Data Type: string
* Default Value: `US`

Optional geographical region code used when comparing phone numbers. See:
http://www.unicode.org/cldr/charts/30/supplemental/territory_information.html Specifying a region
code, if known for the input data, may increase phone number matching accuracy but may also have
runtime performance implications.

=== phone.number.search.in.text

* Data Type: bool
* Default Value: `false`

If true, conflation routines that parse phone numbers will attempt to search for phone numbers
within tag value text that may contain things other than phone numbers. If false, conflation will
assume the tag value is a phone number and will not search within its text.
`phone.number.region.code` must be set to a valid region code when enabling this option. Enabling
this option may have runtime performance implications.

=== plugin.context.includes

* Data Type: list
* Default Value:
** `HootLib.js`

A list of scripts to include before loading the user's plugin script. The path will be search as:
current directory (CWD), $CWD/rules, $HOOT_HOME/rules.

=== poi.ignore.type.if.name.present

* Data Type: bool
* Default Value: `false`

If true, POI to POI conflation will ignore the types of the features being compared completely as
long as those being compared have a populated name field.

=== poi.polygon.additional.search.distance

* Data Type: double
* Default Value: `50.0`

The maximum distance, in meters, added to the circular error of the features being compared, the
total of which allows the features to be considered for match or review based on distance criteria
only. If a value of zero is specified, then only the feature circular error will factor into the
search distance. Higher values for this option can cause large increases in conflation runtime for
dense datasets.

=== poi.polygon.allow.cross.conflation.merging

* Data Type: bool
* Default Value: `false`

If false, when a match found by Building Conflation involves the same feature in a match found by
POI to Polygon Conflation, a review will be generated. If true, then that situation will result in
a merge between all features involved in the Building and POI to Polygon conflation matches.

=== poi.polygon.auto.merge.many.poi.to.one.poly.matches

* Data Type: bool
* Default Value: `false`

If true, instances where multiple POIs were matched to a single polygon will result in all of those
POIs being automatically merged into the polygon. If false, then each matched POI will generate a
review against the polygon instead.

=== poi.polygon.calculate.match.distance.truth

* Data Type: bool
* Default Value: `false`

If true, debug match distance output will be obtained from manually matched source data if running
`score-matches` with POI to Polygon conflation.

=== poi.polygon.disable.intradataset.conflation.1

* Data Type: bool
* Default Value: `false`

Enabling this option prevents all POIs and Polygons within the first input dataset from being
matched. Enabling this causes `poi.polygon.disable.same.source.conflation` to be ignored.

=== poi.polygon.disable.intradataset.conflation.2

* Data Type: bool
* Default Value: `false`

Enabling this option prevents all POIs and Polygons within the second input dataset from being
matched. Enabling this causes `poi.polygon.disable.same.source.conflation` to be ignored.

=== poi.polygon.disable.same.source.conflation

* Data Type: bool
* Default Value: `false`

If true, POI to Polygon conflation will not attempt to conflate two features with the same source
tag value. e.g. both have the `source=osm` tag  The source tag key is specified by
`poi.polygon.source.tag.key`. How strictly the source tag key must be matched is controlled by
`poi.polygon.disable.same.source.conflation.match.tag.key.prefix.only`. This setting is useful when
you have a data layer where data has been collected as both POIs and polygons for the same source
and you never want the two source to be conflated together.

=== poi.polygon.disable.same.source.conflation.match.tag.key.prefix.only

* Data Type: bool
* Default Value: `true`

If set to false and `poi.polygon.disable.same.source.conflation` is set to true, POI to polygon
conflation will disable conflation only between features who have the exact same source tag value.
e.g. both have the `source=osm` tag  If set to true and `poi.polygon.disable.same.source.conflation`
is set to true, then the tag matcher is less strict and will attempt to match the prefix of the
source tag value when delimited by a colon. e.g. `source=mgcp:buildp_clip;osm` will match
`source=mgcp:builda_clip;osm` since both tag values begin with `mgcp:`.

=== poi.polygon.enable.review.reduction

* Data Type: bool
* Default Value: `true`

If true, POI to Polygon conflation will attempt to reduce unnecessary reviews without increasing
incorrect matches.  This setting may be runtime expensive when enabled for large datasets.

=== poi.polygon.keep.closest.matches.only

* Data Type: bool
* Default Value: `false`

If this setting is true, POI to Polygon conflation will attempt to match the closest feature pairs
only. This is useful, for example, when you know the POIs on top of buildings are the only correct
match in your data. With this setting enabled, the conflation will not match additional features at
greater distances, even if they are within the match distance threshold. Multiple features matches
are still possible in the case of exact distance ties. If this setting is false, then multiple POIs
found within the match distance threshold of a polygon are treated as reviews.

=== poi.polygon.match.distance.threshold

* Data Type: double
* Default Value: `5.0`

The maximum distance, in meters, between a POI and a polygon where they can still be considered
a match based on distance criteria only.

=== poi.polygon.match.evidence.threshold

* Data Type: int
* Default Value: `3`

The minimum evidence score at which a POI will be matched to a polygon. Valid values are 1 to 4.
If an evidence score for a feature pair falls below this value, the relationship between the
features will be classified as a review or miss, depending on the value of
`poi.polygon.review.evidence.threshold`. Generally, this setting should not be changed except
when working with specific POI/Polygon conflation use cases that require it.

=== poi.polygon.match.takes.precedence.over.poi.to.poi.review

* Data Type: bool
* Default Value: `true`

For all intra-dataset matching, the default is to throw out all matches for a feature if it is also
involved in another match or review. It has been found that POI/Polygon Conflation performs better
if these matches are kept when they have features that overlap with a POI/POI match/review, as the
overall number of reviews can increase substantially otherwise. Disabling this setting will force
all POI/Polygon matches to be converted to reviews if they contain a feature that overlaps with a
POI/POI review.

=== poi.polygon.name.score.threshold

* Data Type: double
* Default Value: `0.8`

The minimum similarity the name scores, in the range (0.0, 1.0], of two features can have and be
considered a name match, with 0.0 being the least similar and 1.0 being the most similar (-1.0 if
there are no names present (null).

=== poi.polygon.name.string.comparer

* Data Type: string
* Default Value: `KskipBigramDistance`

String comparison algorithm to use for name comparison with POI/Polygon conflation. Must be an
implementation of `StringDistance`.

=== poi.polygon.name.translate.to.english

* Data Type: bool
* Default Value: `false`

If true, a to English translations will be attempted on the value of any name tag. This can have
significant impact on the runtime performance of conflation when enabled and should only be enabled
if the source data is known to have non-English names. The configuration option,
`language.translation.translator`, controls which translator is used.

=== poi.polygon.phone.number.match.enabled

* Data Type: bool
* Default Value: `true`

If true, POI/Polygon conflation will compare phone number as one of the criteria for matching
features. If the data being conflated is known to have poor telephone number data, this option need
not be enabled and disabling it may speed up conflation runtime performance.

=== poi.polygon.poi.ignore.tags

* Data Type: list
* Default Value:
** `aeroway=gate`
** `amenity=atm`
** `amenity=bench`
** `amenity=drinking_water`
** `amenity=parking_entrance`
** `amenity=post_box`
** `amenity=recycling`
** `amenity=sanitary_dump_station`
** `amenity=shower`
** `amenity=telephone`
** `amenity=vending_machine`
** `amenity=waste_basket`
** `barrier=entrance`
** `barrier=gate`
** `barrier=obstacle`
** `barrier=toll_booth`
** `barrier=wall`
** `building=entrance`
** `emergency=fire_hydrant`
** `emergency=suction_point`
** `highway=*`
** `information=guidepost`
** `landuse=grass`
** `leisure=firepit`
** `leisure=picnic_table`
** `man_made=surveillance`
** `natural=tree`
** `place=city`
** `place=village`
** `power=pole`
** `public_transport=stop_position`
** `railway=crossing`
** `railway=platform`
** `railway=tram_stop`
** `railway=turntable`
** `traffic_sign=*`

A list of POI feature tags to ignore. Any POIs containing these tags will be skipped by POI to
Polygon conflation matching. Supports value wildcards; e.g. `amenity=*`. Keep the list alphabetized
and in lower case.

=== poi.polygon.poly.ignore.tags

* Data Type: list
* Default Value:
** `barrier=city_wall`
** `barrier=fence`
** `barrier=wall`
** `boundary=administrative`
** `highway=residential`
** `landuse=grass`
** `landuse=residential`
** `leisure=bleachers`
** `natural=coastline`
** `natural=fell`
** `natural=glacier`
** `natural=scrub`
** `natural=tree_row`
** `place=city`
** `place=neighbourhood`
** `railway=platform`

A list of polygon feature tags to ignore. Any polygons containing these tags will be skipped by POI
to Polygon conflation matching. Supports value wildcards; e.g. `amenity=*`. Keep the list
alphabetized and in lower case.

=== poi.polygon.promote.points.with.addresses.to.pois

* Data Type: bool
* Default Value: `false`

If true, POI to polygon conflation will classify all points with OSM address tags as POIs even if
they do not have specific type tags.

=== poi.polygon.review.evidence.threshold

* Data Type: int
* Default Value: `1`

The minimum evidence score at which a POI will be reviewed against a polygon, if the evidence score
does not meet the threshold defined by `poi.polygon.match.evidence.threshold`. Valid values are
0 to 3. If an evidence score for a feature pair falls below this value, the relationship between
the features will be classified as a miss. If the value is set to 0, all feature pairs which did
not match will be reviewed.  If the value is set greater than or equal to
`poi.polygon.match.evidence.threshold`, an error will occur. Generally, this setting should not be
changed except when working with specific POI/Polygon conflation use cases that require it.

=== poi.polygon.review.if.matched.types

* Data Type: list
* Default Value:
** ``

List of key value pairs in the format `key=value` or `key,value` (UI only) for features to always
review if marked as matches with POI to polygon conflation. Delimit the individual types with ';'.
e.g. `amenity=school;shop=mall` or `amenity,school;shop,mall`.

=== poi.polygon.review.multiuse.buildings

* Data Type: bool
* Default Value: `false`

If true, POI to polygon conflation always marks matches between POIs and polygons where multi-use
building polygons are present as needing review. The definition of multi-use buildings is controlled
by the schema.

=== poi.polygon.source.tag.key

* Data Type: string
* Default Value: `source`

The source tag key to be used in conjunction with `poi.polygon.disable.same.source.conflation`.

=== poi.polygon.tag.merger

* Data Type: string
* Default Value: `PreserveTypesTagMerger`

The tag merger used by POI/Polygon conflation. See `tag.merger.default` for more information. If
`poi.polygon.auto.merge.many.poi.to.one.poly.matches` is set to true then `PreserveTypesTagMerger`
is always used and changes to this option value are ignore.

=== poi.polygon.type.score.threshold

* Data Type: double
* Default Value: `0.7`

The minimum similarity the type scores, in the range (0.0, 1.0], a POI and polygon can have and be
considered a type match, with 0.0 being the least similar and 1.0 being the most similar.

=== poi.polygon.type.to.names

* Data Type: list
* Default Value:
** `amenity=school|college,elementary school,junior high,high school,middle school,university`

This list maps common name texts that represent different types of features to specific OSM types
for POI to Polygon matching. Format: '<OSM tag>|<name text 1>,<name text 2>,...' List one entry per
line in alphabetical order by tag. Keep subtypes in alphabetical order and in lower case. Each
name text should correspond to text commonly associated with a unique subtype of the OSM type.

=== poi.polygon.type.translate.to.english

* Data Type: bool
* Default Value: `false`

If true, a to English translation will be attempted on the value of any tag having a key in its
schema. This can have significant impact on the runtime performance of conflation when enabled
and should only be enabled if the source data is known to have non-English type values. The
configuration option, `language.translation.translator`, controls which translator is used.

=== poi.search.radii

* Data Type: string
* Default Value: `${HOOT_HOME}/conf/core/PoiSearchRadii.json`

This specifies per feature search radius distances to use during POI to POI conflation. It may
either by a path to a JSON file or a JSON string. See `${HOOT_HOME}/conf/core/PoiSearchRadii.json`
for details on the JSON format.

=== power.line.auto.calc.search.radius

* Data Type: bool
* Default Value: `true`

Automatically calculates the search radius to be used during conflation of power lines using rubber
sheet tie point distances.

=== power.line.matcher.distance.weight.coefficient

* Data Type: double
* Default Value: `0.01`

A weighting coefficient value, in the range [0.0, 1.0], for the applying distance weighting to power
line matches. This will favor feature that are closer together. The higher the coefficient value,
the higher the weighting applied. A value of 0.0 will disable distance weighting.

=== power.line.matcher.heading.delta

* Data Type: double
* Default Value: `${way.matcher.heading.delta}`

The distance around a point on a power line to look when calculating the heading. See
`way.matcher.heading.delta`.

=== power.line.matcher.max.angle

* Data Type: double
* Default Value: `155.0`

Sets that maximum angle, in degrees, that is still considered a power line match.

=== power.line.subline.matcher

* Data Type: string
* Default Value: `FrechetSublineMatcher`

The way subline matcher to use when determining matching power line sublines.

=== quantile.aggregator.quantile

* Data Type: double
* Default Value: `0.0`

A quantile value, in the range [0.0, 1.0], for `QuantileAggregator`.

=== progress.var.print.length.max

* Data Type: int
* Default Value: `30`

Maximum length, in characters, allowed when logging a variable value during progress logging. Not
honored by all progress logging.

=== railway.angle.sample.distance

* Data Type: double
* Default Value: `20.0`

Distance, in meters, used for sampling railway data during angle histogram extraction with
`SampledAngleHistogramExtractor`.

=== railway.matcher.heading.delta

* Data Type: double
* Default Value: `150.0`

The distance around a point on a railway to look when calculating the heading. See
`way.matcher.heading.delta`.

=== railway.matcher.max.angle

* Data Type: double
* Default Value: `90.0`

Sets that maximum angle, in degrees, that is still considered a railway match.

=== railway.one.to.many.identifying.keys

* Data Type: list
* Default Value:
** `passenger_lines`

List of tag keys with values identifying how many tracks a particular rail feature uses (arbitarily,
the first tag found from the key list is used). The list is used to identify one to many secondary
match feature candidates if `railway.one.to.many.match` is enabled and the conditions described in
`railway.one.to.many.match` are satisfied. The default value of this option maps to the
OpenStreetMap tagging standard for railways. If your input data has other tag keys that identify
your track count, either translate them to the default value here before hand or add them as
additional entry values to this option.

=== railway.one.to.many.match

* Data Type: bool
* Default Value: `false`

If true, railway matching will attempt a one to many match from a single input 2 rail feature to
multiple input 1 rail features. The rail feature from input 2 must contain at least one of the tag
having a key matching that in `railway.one.to.many.identifying.keys`. Only tag merging of selected
tags identified in `railway.one.to.many.transfer.keys` will be performed with no geometry merging,
regardless of the conflation workflow in use.

=== railway.one.to.many.transfer.all.tags

* Data Type: bool
* Default Value: `false`

When this and `railway.one.to.many.match` are enabled, all tags from secondary rail features
involved in a one to many match are transferred over to reference features. This overrides
`railway.one.to.many.transfer.keys`.

=== railway.one.to.many.transfer.keys

* Data Type: list
* Default Value:
** ``

List of tags to transfer from input 2 rail features to input 1 rail features if
`railway.one.to.many.match` is enabled and the conditions described in `railway.one.to.many.match`
are satisfied for a railway match.

=== railway.subline.matcher

* Data Type: string
* Default Value: `MaximalSublineMatcher`

The way subline matcher to use when determining matching sublines.

=== railway.type.threshold

* Data Type: double
* Default Value: `0.8`

Tag similarity threshold, in the range (0.0, 1.0], at or above which a railway feature is considered
to have tags similar enough with another rail feature to be considered match.

=== railways.crossing.marker.ignore.types

* Data Type: list
* Default Value:
** `bridge=yes`
** `railway=level_crossing`
** `railway=subway`
** `railway=tram`
** `service=yard`
** `tunnel=yes`

List of tag key/value pairs that `RailwaysCrossingMarker` will ignore when marking railways which
cross each other. Add to this list tags rail features possess where rail crossing is deemed
acceptable.

=== railways.crossing.marker.mark.intra.dataset.crossings

* Data Type: bool
* Default Value: `false`

If true, `RailwaysCrossingMarker` will skip marking any crossing railways for review that are from
the same input dataset. Primarily meant to be utilized in conjunction with the `conflate` command.
It is still possible when this option is disabled that portions of features originally from the same
dataset may be marked for review due to the merging of features during conflation. If using
`RailwaysCrossingMarker` with the `convert` command on a single dataset, this option should be
enabled.

=== random.element.remover.probability

* Data Type: double
* Default Value: `0.05`

The probability that a feature will be removed randomly by `RandomElementRemover`.

=== random.element.renamer.change.probability

* Data Type: double
* Default Value: `0.05`

The probability of a random change to each character in the name. when using `RandomElementRenamer`.
The expected number of changes is this option's value * str.size().

=== random.element.renamer.probability

* Data Type: double
* Default Value: `0.05`

The probability that a name will be modified randomly by `RandomElementRenamer`.

=== random.forest.model.trees

* Data Type: int
* Default Value: `40`

The number of trees used to train a random forest conflation model.

=== random.node.duplicator.move.multiplier

* Data Type: double
* Default Value: `1.0`

The distance that a feature is moved is based on the circular error of the source point when using
`RandomNodeDuplicator`. The new point will be put within N(0, sigma^2) * moveMultiplier meters of
the source point where sigma is the standard deviation associated with the source point.

=== random.node.duplicator.probability

* Data Type: double
* Default Value: `0.10`

The probability of at least one duplicate node being randomly created when using
`RandomNodeDuplicator`. See `random.node.duplicator.sigma` to determine how many duplicates will be
created.

=== random.node.duplicator.sigma

* Data Type: double
* Default Value: `1.0`

The number of duplicate randomly generated nodes is set as `round(abs(N(0, sigma^2))) + 1` when
using `RandomNodeDuplicator`. Setting sigma to 0 will guarantee that there will always be exactly
one duplicate.

=== random.seed

* Data Type: int
* Default Value: `-1`

A random seed integer passed to the random number generator accessed by map operations and
visitors that modify elements randomly (used by PERTY, `RandomMapCropper`, etc.). to give consistent
results over multiple runs. A value of -1 will generate a seed based on the time to provide
pseudo-random results in the output.

=== random.tag.modifier.exempt.tag.keys

* Data Type: list
* Default Value:
** ``

A list of tag keys which are exempt from the random tag removal done by `RandomTagModifier`. This is
useful for preventing the removal of custom tags which are needed in the output. By default, all
metadata and ref tags are exempted.

=== random.tag.modifier.probability

* Data Type: double
* Default Value: `0.05`

The probability that a tag will be randomly removed when using `RandomTagModifier`.

=== random.tag.modifier.substitution.keys

* Data Type: list
* Default Value:
** `highway`

A list of tag keys which, rather than being randomly removed by the `RandomTagModifier`, will have
their values replaced instead.  The tag keys in the list match one to one with the replacement
values in `random.tag.modifier.subsitution.values`.

=== random.tag.modifier.substitution.values

* Data Type: list
* Default Value:
** `road`

A list of tag values which should be substituted by `RandomTagModifier` when randomly modifying
tags. The tag values in the list match one to one with the replacement values in
`random.tag.modifier.subsitution.keys`.

=== random.way.generalizer.epsilon

* Data Type: double
* Default Value: `1.0`

Distance parameter, in meters, that determines to what degree a way is randomly generalized by
`RandomWayGeneralizer`. Higher values result in a higher degree of generalization (more nodes
removed).

=== random.way.generalizer.probability

* Data Type: double
* Default Value: `0.1`

The probability, in the range [0.0, 1.0], that a way will be randomly generalized by
`RandomWayGeneralizer`.

=== random.way.splitter.min.node.spacing

* Data Type: double
* Default Value: `1`

The minimum spacing, in meters, that may occur between nodes created by `RandomWayGeneralizer` way
splits.

=== random.way.splitter.probability

* Data Type: double
* Default Value: `0.1`

The probability, in the range [0.0, 1.0], that a way will randomly be split into multiple features
by `RandomWayGeneralizer`.

=== reader.add.source.datetime

* Data Type: bool
* Default Value: `true`


By default add the `source:datetime` or `source:ingest:datetime` stamp when reading files.  Not
honored by all readers.

=== reader.drop.defaults

* Data Type: string
* Default Value: `true`

This setting tells a translation to drop default values when converting from a translated schema to OSM.
This means that attributes with values like "UNK", "NoInformation" etc will be dropped during the translation.

=== reader.http.bbox.max.download.size

* Data Type: double
* Default Value: `1.0`

Maximum size of an overall bounding box, in degrees, before a download request is rejected.

=== reader.http.bbox.max.size

* Data Type: double
* Default Value: `0.25`

Maximum size of an HTTP request's bounding box, in degrees, before it is split up into smaller
bounding boxes and run in parallel.

=== reader.http.bbox.thread.count

* Data Type: int
* Default Value: `4`

Number of threads in the thread pool to process HTTP requests that contain bounding boxes that are
too large to query at once (see `reader.http.bbox.max.size`).

=== reader.keep.status.tag

* Data Type: bool
* Default Value: `false`

If `reader.use.file.status` is true, the default action is to drop the status tag from the file
during reading. Setting this to true preserves the status tag on the element. Not honored by all
readers.

=== reader.preserve.all.tags

* Data Type: bool
* Default Value: `false`

If true, all tags from the input data will be preserved. Not honored by all readers.  e.g.
an `accuracy` tag will not be replaced by a `error:circular` tag; both tags will be kept.

=== reader.set.default.status

* Data Type: string
* Default Value: `unknown1`

Sets the status on data being read. Valid values are `unknown1` and `unknown2`. Not honored by all
readers.

=== reader.use.data.source.ids

* Data Type: bool
* Default Value: `true`

If true, the element IDs in the source data will be assigned to written elements. Otherwise,
element IDs are managed internally. Not honored by all readers.

=== reader.use.file.status

* Data Type: bool
* Default Value: `false`

By default should a reader use the file status from the file. Not honored by all readers.

=== reader.warn.on.zero.version.element

* Data Type: bool
* Default Value: `false`

If true, supporting map readers will log a warning when an element is encountered with a version of
zero. This is useful to track when deriving changesets where the reference data is expected to be
pre-existing.

=== relation.criterion.type

* Data Type: string
* Default Value: ``

Allows for requiring a type tag match when using `RelationCriterion`.

=== relation.name.threshold

* Data Type: double
* Default Value: `0.9`

Name similarity threshold, in the range (0.0, 1.0], at or above which a relation feature is
considered to have a name match.

=== relation.type.threshold

* Data Type: double
* Default Value: `0.8`

Tag similarity threshold, in the range (0.0, 1.0], at or above which an relation feature is
considered to have similar tags.

=== relation.with.members.of.type.criterion.allow.mixed.children

* Data Type: bool
* Default Value: `false`

If enabled, implementations of `RelationWithMembersOfTypeCriterion` will be satisfied if any member
meets their member criterion. If disabled, all members must satisfy the member criterion.

=== relation.with.most.members.op.member.criterion

* Data Type: string
* Default Value: ``

The criterion used by `RelationWithMostMembersOp` to filter relation members.

=== relation.with.most.members.op.relation.criterion

* Data Type: string
* Default Value: ``

The criterion used by `RelationWithMostMembersOp` to filter relations.

=== remove.attributes.visitor.types

* Data Type: list
* Default Value:
** ``

List of element attributes to remove with `RemoveAttributesVisitor`. Valid values are: `changeset`,
`timestamp`, `user`, `uid`, or `version`.

=== remove.duplicate.areas.diff

* Data Type: string
* Default Value: `ExactTagDifferencer`

Use this class for calculating the difference between element tags. If the difference is exactly
0 then they'll be a candidate for merging.

=== remove.elements.visitor.chain.element.criteria

* Data Type: bool
* Default Value: `false`

If set to true and multiple criterion are specified in `remove.elements.visitor.element.criteria`,
elements will be removed only if they satisfy all of the criteria. If set to false, then only
one of the specified criteria must be satisified in order to remove an element.

=== remove.elements.visitor.element.criteria

* Data Type: list
* Default Value: ``

One or more element criteria used for selecting elements to remove.

=== remove.elements.visitor.recursive

* Data Type: bool
* Default Value: `true`

Determines if `RemoveElementsVisitor` removes elements recursively.

=== replace.tag.visitor.match.tag

* Data Type: string
* Default Value: ``

The tag `ReplaceTagVisitor` replaces, of the form key=value.

=== replace.tag.visitor.replace.tag

* Data Type: string
* Default Value: ``

The tag `ReplaceTagVisitor` uses as a replacement tag; of the form: `key=value`.

=== resolve.review.type

* Data Type: string
* Default Value: `keep`

Post conflation operation that either keeps all reviews, removes all reviews, or resolves all
reviews. Valid values: `keep`, `remove`, or `resolve`.

=== review.score.criterion.invert.thresholding

* Data Type: bool
* Default Value: `false`

If true, reviews outside of the score range specified by `review.score.criterion.min/max.threshold`
will pass the filter.

=== review.score.criterion.max.threshold

* Data Type: double
* Default Value: `1.0`

The score threshold above which reviews will not pass the filter. A value of 1.0 signifies no
maximum score threshold.  This currently works with Attribute Conflation only and can be enabled
with `attribute.conflation.allow.reviews.by.score.`

=== review.score.criterion.min.threshold

* Data Type: double
* Default Value: `0.0`

The score threshold below which reviews will not pass the filter, in the range [0.0, 1.0],.  A value
of 0.0 signifies no minimum score threshold.  This currently works with Attribute Conflation only
and can be enabled with `attribute.conflation.allow.reviews.by.score`.

=== river.angle.sample.distance

* Data Type: double
* Default Value: `20.0`

Distance, in meters, used for sampling river data during angle histogram extraction with
`SampledAngleHistogramExtractor`.

=== river.auto.calc.search.radius

* Data Type: bool
* Default Value: `true`

Automatically calculates the search radius to be used during conflation of rivers using rubber
sheet tie point distances.

=== river.matcher.heading.delta

* Data Type: double
* Default Value: `150.0`

The distance around a point on a river to look when calculating the heading. See
`way.matcher.heading.delta`.

=== river.matcher.max.angle

* Data Type: double
* Default Value: `90.0`

Sets that maximum angle, in degrees, that is still considered a river match.

=== river.maximal.subline.auto.optimize

* Data Type: bool
* Default Value: `true`

Enabling this allows River Conflation to optimize the manner it uses maximal subline matching for
runtime performance.

=== river.name.threshold

* Data Type: double
* Default Value: `0.9`

Name similarity threshold, in the range (0.0, 1.0], at or above which a river feature is considered
to have a name match.

=== river.rubber.sheet.minimum.ties

* Data Type: int
* Default Value: `5`

Sets the minimum number of tie points that will be used when calculating a rubber sheeting solution
with river data.

=== river.rubber.sheet.ref

* Data Type: bool
* Default Value: `true`

See `rubber.sheet.ref`. Used during river conflation.

=== river.subline.matcher

* Data Type: string
* Default Value: `MaximalSublineMatcher`

The way subline matcher to use when determining matching river sublines.

=== river.type.threshold

* Data Type: double
* Default Value: `0.7`

Tag similarity threshold, in the range (0.0, 1.0], at or above which a river feature is considered
to have similar tags.

=== rubber.sheet.debug

* Data Type: bool
* Default Value: `false`

If set to true, then debug symbols will be added to nodes and additional tags will be added to
matched nodes. This is a destructive operation that is only useful when debugging.

=== rubber.sheet.element.criteria

* Data Type: list
* Default Value: ``

Determines which type of features are rubbersheeted. An empty list will rubbersheet all types of
features.

=== rubber.sheet.fail.when.minimum.tie.points.not.found

* Data Type: bool
* Default Value: `false`

If set to true, rubber sheeting will return an error if less than `rubber.sheet.minimum.ties` tie
points are found.  Otherwise, a warning will be logged and rubber sheeting will be skipped.

=== rubber.sheet.log.missing.requirements.as.warning

* Data Type: bool
* Default Value: `false`

If set to true, rubber sheeting will log a warning if any requirement for rubber sheeting is not
met. e.g less than `rubber.sheet.minimum.ties` tie points are found. Otherwise, an info level log
statement will be logged instead. This setting is completely ignored if
`rubber.sheet.fail.when.minimum.tie.points.not.found` is set to true.

=== rubber.sheet.max.allowed.ways

* Data Type: int
* Default Value: `500000`

A threshold above which rubber sheeting will not attempt to align a dataset. A value of -1 will
impose no upper limit. This is in place for performance reasons, as rubbersheeting is a very
expensive process and can be increased on a per usage basis. This option's default value may need
some tweaking based on experiences with operational data.

=== rubber.sheet.max.interpolator.iterations

* Data Type: int
* Default Value: `200`

The maximum number of interpolation optimization iterations, per optimization loop, an interpolator
is allowed to run during rubber sheeting. Use -1 for no iteration limit. Not supported by all
interpolators. Can prevent runaway optimizations with some interpolators. Lower values may result
in the selection of a suboptimal interpolator.

=== rubber.sheet.minimum.ties

* Data Type: int
* Default Value: `4`

The minimum number of tie points required to calculate a rubbersheeting solution.

=== rubber.sheet.ref

* Data Type: bool
* Default Value: `true`

If this configuration setting is set to true, then the first layer is treated as the reference
layer and will not be moved. If set to false the two layers will be moved towards each other. The
weighting is determined based on the circular error.

=== schema.translation.direction

* Data Type: string
* Default Value: ``

The optional direction that the translation script should translate in, used by the convert command,
SchemaTranslationOp, and SchemaTranslationVisitor. Valid values are: `toogr` and `toosm`. `toogr`
will translate in a direction appropriate for an OGR output. `toosm` will translate in a direction
appropriate for an OSM output. The script specified by the schema.translation.script configuration
option must be compatible with the translation direction chosen. If no translation direction is
specified when translating with the convert command, the convert command will attempt to determine
the correct direction and notify the user which direction was determined. If the convert command
cannot determine the direction, it will use the `toosm` direction and also notify the user.
`SchemaTranslationOp` and `SchemaTranslationVisitor` used outside of the convert command will return
an error if no direction was specified.

=== schema.translation.override

* Data Type: string
* Default Value: ``

Override the value of translated tags and attributes. This assumes that you know exactly what tags
you want to modify/delete.

VERY IMPORTANT NOTE: The changes apply to ALL elements and are applied to the OSM+ tags either
before or after the translation. E.g.
* After attributes are translated to OSM+ tags during Import
* Before OSM+ tags are translated to attributes on Export

=== schema.translation.script

* Data Type: string
* Default Value: ``

The script used by `SchemaTranslationVisitor` and `SchemaTranslationOp` for schema translation.
Required if converting to/from an OGR format. Use either the base name of a Python translation
file (without the `.py` extension) or the full path to a Javascript file (`.js`). If this
configuration option is added to a call to the convert command and neither
`SchemaTranslationVisitor` nor `SchemaTranslationOp` is specified the convert command will add the
translation operation as the first conversion operation. If you want the translation operation to
occur in a different order, then you must explicitly specify it in convert.ops. For more information
on translation files read the "Translation" section of the User Guide.

=== schema.translation.element.status

* Data Type: string
* Default Value: ``

Optional element status filter to use when performing schema translation. Valid values are <empty>,
`Unknown1`, and `Unknown2`. An empty value will cause no filtering to occur. A non-empty value will
only translate elements with the specified status.

=== score.graph.debug.images

* Data Type: bool
* Default Value: `false`

Export some of the images used when evaluating the graph connections between two maps with the
`score` command.

=== score.matches.allow.uuids.as.ids

* Data Type: bool
* Default Value: `false`

The current manual match ID format is a 6 character hex string created by the `AddRef*Visitor`
classes. This option allows backward compatibility support for UUID ID formats that exist in some
older manually matched input files.

=== score.matches.full.debug.output

* Data Type: bool
* Default Value: `false`

Adds more detail to manual match validation warning/error messages.

=== score.matches.remove.nodes

* Data Type: bool
* Default Value: `false`

Remove `REF` tags from nodes before match scoring when using the `score-matches` command.

=== score.matches.require.ref1

* Data Type: bool
* Default Value: `true`

In some situations manually matched input data may need to be cropped to allow for smaller test
runtimes. When this is done, sometimes `REF1` features will be removed from the input. Disabling
this option allows for score-matches to run when there are missing `REF1` features. Warnings will be
logged for any that are found.

=== search.radius.area

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius, in meters, to use when conflating areas. See `search.radius.default`

=== search.radius.building

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius, in meters, to use when conflating buildings. See `search.radius.default`.

=== search.radius.calculator.element.criterion

* Data Type: string
* Default Value: ``

`ElementCriterion` derived class which determines which input features are used for search radius
calculation. An empty value specifies that all input features are to be used. Conflation routines
making use of automatic search radius calculation should set this value appropriately.

=== search.radius.default

* Data Type: double
* Default Value: `-1.0`

The default search radius, in meters, to use globally when conflating features. If two features are
within the search radius then they will be considered for matching. If the value is set to the
default value of -1.0, then the circular error will be used to calculate an appropriate search
radius. This value may be overridden for specific feature types. Some feature matching routines may
not strictly honor the default value.

=== search.radius.generic.line

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius, in meters, to use when conflating generic lines. See `search.radius.default`.

=== search.radius.generic.point

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius, in meters, to use when conflating generic points. See `search.radius.default`.

=== search.radius.generic.point.polygon

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius, in meters, to use when conflating generic points with generic polygons. See
`search.radius.default`.

=== search.radius.generic.polygon

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius, in meters, to use when conflating generic polygons. See `search.radius.default`.

=== search.radius.highway

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius, in meters, to use when conflating highways. See `search.radius.default`.

=== search.radius.poi

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius, in meters, to use when conflating POIs. If `search.radius.default` is used, POI
conflation will calculate a custom search distance based on the input feature types. See
`search.radius.default`.

=== search.radius.power.line

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius to use when conflating power lines. This value is not used if
`power.line.auto.calc.search.radius=true`, and in that case the search radius is auto-calculated for
the entire input dataset. See `search.radius.default`.

=== search.radius.railway

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius, in meters, to use when conflating railways. See `search.radius.default`.

=== search.radius.relation

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius, in meters, to use when conflating relations. See `search.radius.default`.

=== search.radius.river

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius to use when conflating rivers. This value is not used if
`river.auto.calc.search.radius=true`, and in that case the search radius is auto-calculated for
the entire input dataset. See `search.radius.default`.

=== selective.overwrite.tag.merger.keys

* Data Type: list
* Default Value:
** ``

List of keys for tags to be transferred by the `TagMergers` descending from
`SelectiveOverwriteTagMerger`.

=== selective.overwrite.tag.merger.keys.exclude

* Data Type: list
* Default Value:
** ``

List of keys for tags not to be transferred by the `TagMergers` descending from
`SelectiveOverwriteTagMerger`. Overrides `selective.overwrite.tag.merger.keys`.

=== set.tag.value.visitor.append.to.existing.value

* Data Type: bool
* Default Value: `false`

If true, any element with a value populated for the key defined by the `set.tag.value.visitor.keys`
option will have the value specified in the `set.tag.value.visitor.value` option appended to it.

=== set.tag.value.visitor.chain.element.criteria

* Data Type: bool
* Default Value: `false`

If set to true and multiple criterion are specified in `set.tag.value.visitor.element.criteria`,
the tags of elements will be modified only if they satisfy all of the criteria. If set to
false, then only one of the specified criteria must be met in order to modify the tags of an
element.

=== set.tag.value.visitor.element.criteria

* Data Type: list
* Default Value: ``

The element criteria used to select elements to add or modify tags on used by `SetTagValueVisitor`
and `RecursiveSetTagValueOp`. To pass in complex nested criteria, use the Javascript interface
instead.

=== set.tag.value.visitor.keys

* Data Type: list
* Default Value: ``

Sets the key member in `SetTagValueVisitor` and `RecursiveSetTagValueOp`. The number of keys in
`set.tag.value.visitor.keys` should match the number of keys in `set.tag.value.visitor.values`.
Separate list items with a semicolon.

=== set.tag.value.visitor.overwrite

* Data Type: bool
* Default Value: `true`

If true, `SetTagValueVisitor` and `RecursiveSetTagValueOp` will overwrite any existing tag they find
with a key matching any key in `set.tag.value.visitor.keys`, otherwise they will skip updating the
tag.

=== set.tag.value.visitor.values

* Data Type: list
* Default Value: ``

Set the value member in `SetTagValueVisitor` and `RecursiveSetTagValueOp`. The number of keys in
`set.tag.value.visitor.values` should match the number of keys in `set.tag.value.visitor.keys`.
Separate list items with a semicolon.

=== shape.file.writer.cols

* Data Type: list
* Default Value:
** ``

Optional list of keys to use for shape file output columns. Valid only when converting from OSM to
shape file and cannot be used in combination with a translation.  If this option is not specified,
then the list of columns will be automatically determined based on the most frequently populated
tags.

=== small.disconnected.way.remover.max.node.count

* Data Type: int
* Default Value: `2`

The maximum number of nodes a way can have to be considered for removal by
`SmallDisconnectedWayRemover`.

=== small.disconnected.way.remover.max.length

* Data Type: double
* Default Value: `2.0`

The maximum length a way can have to be considered for removal by `SmallDisconnectedWayRemover`.

=== small.highway.merger.diff

* Data Type: string
* Default Value: `ExactTagDifferencer`

Use this class for calculating the difference between element tags. If the difference is exactly 0
then they'll be a candidate for merging.

=== small.highway.merger.threshold

* Data Type: double
* Default Value: `15`

If highways are smaller than threshold and the tags matched, then they will be merged together into
a single way.

=== snap.unconnected.ways.add.circular.error.to.search.radius

* Data Type: bool
* Default Value: `false`

If true, all tolerances use by `UnconnectedWaySnapper` will have the circular error of the snap node
candidate added to them.

=== snap.unconnected.ways.discretization.spacing

* Data Type: double
* Default Value: `1.0`

The spacing granularity to which a unconnected way node is snapped back to a way with
`UnconnectedWaySnapper`. Setting this too low could result in lower algorithm performance, and
setting it too high may result in less accurate way snapping.

=== snap.unconnected.ways.exclude.types

* Data Type: list
* Default Value:
** `noexit=yes`

Feature types that should never be snapped by `UnconnectedWaySnapper`.

=== snap.unconnected.ways.existing.way.node.tolerance

* Data Type: double
* Default Value: `0.5`

Maximum distance used by `UnconnectedWaySnapper`, in meters, allowed between an unconnected way
endpoint node and a neighboring way node for the way endpoint node to be snapped directly to the
existing way node instead of adding the way endpoint node as a new way node on the way.

=== snap.unconnected.ways.favor.reference.way.node

* Data Type: bool
* Default Value: `false`

When enabled, `UnconnectedWaySnapper` will attempt to maximize the number of reference (status=1)
way nodes kept during snapping.

=== snap.unconnected.ways.mark.only

* Data Type: bool
* Default Value: `false`

If true, no ways will be actually snapped by `UnconnectedWaySnapper` and any way that would have
been snapped otherwise with the current configuration will be marked depending upon the enablement
of `snap.unconnected.ways.mark.snapped.ways` and `snap.unconnected.ways.review.snapped.ways`. Useful
for debugging purposes.

=== snap.unconnected.ways.mark.snapped.nodes

* Data Type: bool
* Default Value: `false`

If true, all way nodes snapped by `UnconnectedWaySnapper` to another way or way node will be marked
with a custom tag. Useful for debugging purposes.

=== snap.unconnected.ways.mark.snapped.ways

* Data Type: bool
* Default Value: `false`

If true, all ways snapped by `UnconnectedWaySnapper` to another way or way node will be marked with
a custom tag. Useful for debugging purposes.

=== snap.unconnected.ways.minimum.type.match.score

* Data Type: double
* Default Value: `-1.0`

The feature type similarity score at or above which two ways being snapped by
`UnconnectedWaySnapper` must score. Valid values are, -1.0 and the range (0.0, 1.0],. A value of
-1.0 disables the feature type match requirement completely and only the snap criteria will
influence the snapping.

=== snap.unconnected.ways.review.snapped.ways

* Data Type: bool
* Default Value: `false`

If true, any snapped way by `UnconnectedWaySnapper` will be marked for review. Useful if you want
the opportunity to manually correct any snaps made.

=== snap.unconnected.ways.snap.criteria

* Data Type: list
* Default Value:
** ``

Optional criteria used to filter both the types of ways being snapped by `UnconnectedWaySnapper`
(sources) and the types of ways being snapped to (targets). The classes specified must inherit from
`ConflatableElementCriterion`. An example is: `HighwayCriterion`. The default value of an
empty list allows for snapping any type of linear feature. This option combines with
`snap.unconnected.ways.snap.way.statuses` and `snap.unconnected.ways.snap.to.way.statuses` to
determine which ways are eligible to be involved in snapping. This option is overridden by the
options `snap.unconnected.ways.snap.way.criteria` and/or
`snap.unconnected.ways.snap.to.way.criteria` to allow for more granularity in selecting the types to
snap.

=== snap.unconnected.ways.snap.to.way.criteria

* Data Type: list
* Default Value:
** ``

Optional criteria used to filter the types of ways being snapped to (targets) by
`UnconnectedWaySnapper`. The classes specified must inherit from `ConflatableElementCriterion`. An
example is: `HighwayCriterion`. This option combines with
`snap.unconnected.ways.snap.to.way.statuses` to determine which ways are eligible to be snapped to
and overrides `snap.unconnected.ways.snap.criteria`.

=== snap.unconnected.ways.snap.to.way.statuses

* Data Type: list
* Default Value:
** `Input1`

Statuses of ways or way nodes being snapped to by `UnconnectedWaySnapper`. Valid values are
`Input1`, `Input2`, or `Conflated`. Specify `Input1` to snap secondary ways to reference ways or
`Input2` to snap reference ways to secondary ways. You may add multiple statuses and separate them
with a semicolon. For example, to snap to both reference and conflated ways use: `Input1;Conflated`.
If no statuses are specified, then feature status is ignored for ways or way nodes being snapped to.
This option combines with `snap.unconnected.ways.snap.to.way.criteria` to determine which ways are
eligible to be snapped to.

=== snap.unconnected.ways.snap.tolerance

* Data Type: double
* Default Value: `5.0`

Maximum distance used by `UnconnectedWaySnapper`, in meters, allowed between an unconnected way
endpoint node and a neighboring way for the way endpoint node to be snapped to the closest section
of the neighboring way.

=== snap.unconnected.ways.snap.way.criteria

* Data Type: list
* Default Value:
** ```

Optional criteria used to filter the types of ways being snapped (sources) by
`UnconnectedWaySnapper`. The classes specified must inherit from `ConflatableElementCriterion`. An
example is: `HighwayCriterion`. This option combines with `snap.unconnected.ways.snap.way.statuses`
to determine which ways are eligible for snapping and overrides
`snap.unconnected.ways.snap.criteria`.

=== snap.unconnected.ways.snap.way.statuses

* Data Type: list
* Default Value:
** `Input2`

Statuses of the ways being snapped by `UnconnectedWaySnapper`. Valid values are `Input1`, `Input2`,
or `Conflated`. Specify `Input1` to snap reference ways to secondary ways or `Input2` to snap
secondary ways to reference ways. You may add multiple statuses and separate them with a semicolon.
For example, to snap both reference and conflated ways use: `Input1;Conflated`. If no statuses are
specified, then feature status is ignored for ways or way nodes being snapped. This option combines
with `snap.unconnected.ways.snap.way.criteria` to determine which ways are eligible for snapping.

=== snap.unconnected.ways.use.existing.way.nodes

* Data Type: bool
* Default Value: `true`

If true, when `UnconnectedWaySnapper` snaps way endpoint nodes to neighboring ways, it will attempt
to reuse existing way nodes on the way being snapped to instead of adding the endpoint way node to
the way.

=== spark.changeset.writer.element.payload.format

* Data Type: string
* Default Value: `json`

The format used to write the element payload portion of the Spark changeset file. Valid options are
'json' or 'xml'.

=== stats.generic.data.file

* Data Type: string
* Default Value: `${HOOT_HOME}/conf/core/GenericStats.json`

Path to a json file containing definitions for the generic set of statistics values.

=== stats.translate.script

* Data Type: string
* Default Value: `${HOOT_HOME}/translations/TDSv61.js`

Path to the translation script to use when translating tags for stats. If the path is empty, then
all translation stats are disabled.

=== status.criterion.status

* Data Type: string
* Default Value: `Invalid`

The default status to match with a status criterion. Valid values are: `Conflated`, `Invalid`,
`Unknown1`, or `Unknown2`. This option is used by various element visitors and map operations.

=== status.update.visitor.only.update.invalid.status

* Data Type: bool
* Default Value: `false`

If true, `SetTagValueVisitor` will only update statuses on elements when the existing status is
'Invalid'.

=== status.update.visitor.status

* Data Type: string
* Default Value: ``

Adds the specified status to elements. Valid values are: `Conflated`, `Invalid`, `Unknown1`,
`Unknown2`. If left empty, all elements will receive tag additions.

=== subline.matcher.secondary

* Data Type: string
* Default Value: `FrechetSublineMatcher`

This subline matcher is used as a backup if the primary linear subline merging runs for too long.
See `maximal.subline.max.recursions`.

=== superfluous.node.remover.exclude.ids

* Data Type: list
* Default Value: ``

A list of node IDs that `SuperfluousNodeRemover` will skip removing, even if they are superfluous.

=== superfluous.node.remover.unallowed.orphan.kvps

* Data Type: list
* Default Value:
** `highway=crossing`
** `highway=traffic_signals`
** `highway=turning_circle`
** `public_transport=stop_position`
** `railway=level_crossing`

List of node key/value pairs that should never be orphaned from ways. `SuperfluousNodeRemover` will
remove these if they are not part of a way or relation. Generally, only add to this list node
features that conflation is unable to merge correctly. Fixing their handling during conflation is
preferred to adding them to this list. Keep the list alphabetized by key, then value (we may want to
eventually move it to its own config file).

=== superfluous.way.remover.exclude.ids

* Data Type: list
* Default Value: ``

A list of way IDs that `SuperfluousWayRemover` will skip removing, even if they are superfluous.

=== tag.ancestor.differencer.name

* Data Type: string
* Default Value: ``

The default ancestor to use when using `TagAncestorDifferencer` for comparing tags. Primarily, this
is useful within the node.js interface.

=== tag.category.differencer.name

* Data Type: string
* Default Value: ``

The default category to use when using `TagCategoryDifferencer` class for comparing tags. Primarily,
this is useful within the node.js interface.

=== tag.contains.criterion.case.sensitive

* Data Type: bool
* Default Value: `true`

If true, `TagContainsCriterion` will only identify partial tag values whose case matches exactly
with the tag key values in `tag.contains.criterion.kvps.` If false, the cases of the tag values do
not have to match.

=== tag.contains.criterion.kvps

* Data Type: list
* Default Value: ``

Key/value pairs to use with `TagContainsCriterion`. Delimit keys and values with '='.  E.g.
"name=Java;name=Shop"

=== tag.criterion.case.sensitive

* Data Type: bool
* Default Value: `true`

If true, `TagCriterion` will only identify tag strings whose cases match exactly with the values in
`tag.criterion.kvps`. If false, the cases of the tag strings do not have to match.

=== tag.criterion.kvps

* Data Type: list
* Default Value: ``

Key/value pairs to use with `TagCriterion`. Delimit keys and values with '='. E.g.
"highway=road;amenity=school"

=== tag.filter.element.criterion

* Data Type: string
* Default Value: ``

The name of an `ElementCriterion` derived class used to select tags to keep/remove used by
`RemoveTagsVisitor`. To pass in complex nested criteria for tag filtering, use the Javascript
interface instead.

=== tag.filter.keys

* Data Type: list
* Default Value:
** ``

A list of tag keys the `KeepTagsVisitor`/`RemoveTagsVisitor` will keep/remove on/from elements.
Wildcard matching is supported with '*'.

=== tag.key.contains.criterion.text

* Data Type: string
* Default Value: ``

Text that `TagKeyContainsCriterion` uses to filter elements.

=== tag.key.criterion.keys

* Data Type: list
* Default Value: ``

Tag keys that `TagKeyCriterion` uses to filter elements.

=== tag.merger.default

* Data Type: string
* Default Value: `OverwriteTag2Merger`

Specifies the default way of merging tags. This is used by most merge routines, but may be
overridden depending on the specifics of the merger. `hoot info --tag-mergers` displays information
about the available mergers.

=== tag.merger.overwrite.accumulate.values.keys

* Data Type: list
* Default Value:
** ``

This allows `OverwriteTagMerger` to preserve the values of select tags during tag merging. This
does not apply to name tags or tags marked as type "text" or "metadata" in the schema. Any tag key
in the option list found in the set of tags used to overwrite will result in corresponding tag
values in the target feature being appended to each other. e.g. A: { myField1=1, myField2=1 }
merged with B: { myField2=1, myField3=1 } results in C: { myField1=1, myField2=1;2, myField3=1 }

=== tag.merger.overwrite.exclude

* Data Type: list
* Default Value:
** ``

A list of tag keys not to be overwritten on target features during tag merging when using
`OverwriteTagMerger` or `ReplaceTagMerger`. Please keep the list alphabetized.

=== tag.merger.types.overwrite.reference

* Data Type: bool
* Default Value: `false`

If true, in cases where tags between features being merged tie in type specificity when being merged
by `MostSpecificTagMerger` or `PreserveTypesTagMerger`, the tag from the secondary feature will be
kept. If false, then the tag from the reference feature is kept. Generally, if `OverwriteTag2Merger`
is used as the default tag merger, this should be set to false or if `OverwriteTag1Merger` is used,
it should be set to true. This is necessary since some conflator will override the default tag
merging logic under certain circumstances.

=== tag.printing.format

* Data Type: string
* Default Value: `asciidoc`

Output format to use when printing OSM+ Tag documentation. Valid formats are: 'csv', 'html', and
'asciidoc'.

=== tag.printing.script

* Data Type: string
* Default Value: `${HOOT_HOME}/translations/PrintOsmDocs.js`

The translation script to use when printing OSM+ Tag documentation.

=== tag.rename.visitor.new.key

* Data Type: string
* Default Value: ``

The key to used to replace an existing by the `TagRenameKeyVisitor`. `TagRenameKeyVisitor` allows
for renaming existing tag keys on all elements in a map.

=== tag.rename.visitor.old.key

* Data Type: string
* Default Value: ``

The key to be replaced by `TagRenameKeyVisitor`. `TagRenameKeyVisitor` allows for renaming existing
tag keys on all elements in a map.

=== tag.value.numeric.range.criterion.keys

* Data Type: list
* Default Value:
** ``

The keys the `TagValueNumericRangeCriterion` examines the numeric value of. Tags for all keys must
meet the numeric range requirement for the criterion to be met.

=== tag.value.numeric.range.criterion.max

* Data Type: long
* Default Value: `-1`

Minimum tag numeric value that will allow `TagValueNumericRangeCriterion` to be satisified.

=== tag.value.numeric.range.criterion.min

* Data Type: long
* Default Value: `-1`

Minimum tag numeric value that will allow `TagValueNumericRangeCriterion` to be satisified.

=== tags.visitor.keys

* Data Type: list
* Default Value:
** ``

List of tag keys for that `AverageNumericTagsVisitor`, `SumNumericTagsVisitor`, or
`TagKeyCountVisitor` uses.

=== task.status.update.interval

* Data Type: int
* Default Value: `1000`

For commands supporting it, the iteration count at which a status message should be logged. This
setting may have a negative impact on performance if set to a very low value.

=== test.case.conflate.cmd

* Data Type: string
* Default Value: `ConflateCmd`

Set the `conflate` command that should be used in a test case. This is only useful when writing
test cases (`test-files/cases/`) and was originally added to support the now dormant Multiary
Conflation capability.

=== test.case.conflate.differential

* Data Type: bool
* Default Value: `false`

When activated, this runs the conflate case test conflate command with the `--differential` option.

=== test.case.conflate.differential.include.tags

* Data Type: bool
* Default Value: `false`

When activated, this runs the conflate case test conflate command with both the `--differential`
and `--include-tags` options (setting this to true automatically sets
`test.case.conflate.differential` to true).

=== test.force.orthographic.projection

* Data Type: bool
* Default Value: `false`

Enabling this always forces the orthographic projection when determining a proper planar projection.
In typical usage this will never be used (the automatically selected projection should always be at
least as good). This is most useful if you want to get consistent results even if the list of
potential projections change over time. Very handy in unit tests.

=== test.script.max.exec.time

* Data Type: int
* Default Value: `900`

For script test debugging only. Sets a maximum allowed time, in seconds, for a script test to run.
If the script runs longer than the specified time, then it is forcefully stopped by the system. If
the value is set to -1, then there is no time limit for script tests. This is useful when
debugging tests which may hang on a remote build server.

=== test.validation.enable

* Data Type: bool
* Default Value: `true`

Enables validation of test output for selected tests.

=== token.keep.non.words

* Data Type: bool
* Default Value: `false`

This does a rudimentary check to see if the string contains any letters/numbers. If the string
doesn't contain any letters or numbers then it will be dropped. Examples that would be dropped
if the value is `true` include:

* `&`
* `--`

Examples that will be kept if the value is `true` include:

* `1&2`
* `Joe's`

=== token.min.size

* Data Type: double
* Default Value: `3`

This is the minimum string size that the string tokenizer should accept as a token. If the string
length is less than this value, then it will not be accepted. Set the value to 0 if you want to
accept all strings.

This setting primarily applies to string comparison functions and will eliminate comparing very
short strings such as "of" or "&".

=== token.separator

* Data Type: string
* Default Value: `\s+`

The token separator defined as a regular expression. This is used in some methods for tokenizing
names. The default value matches multiple whitespace characters.

Another useful option is `[\s-,';]+`. This will split on white space, or several forms of
punctuation. See http://doc.qt.io/qt-4.8/QRegExp.html for a useful list of regular expression
options.

=== translated.tag.differencer.ignore.list

* Data Type: string
* Default Value: ``

Semi-colon delimited list of tags that should be ignored when comparing a list of tags using
`TranslatedTagDifferencer`.

See also:
* `translated.tag.differencer.script`

=== translated.tag.differencer.script

* Data Type: string
* Default Value: ``

Path to the translation script when using the `TagDifferencer`, `TranslatedTagDifferencer`.
This `TagDifferencer` is most useful when deciding how difference between two sets of tags should be
calculated. It can be used with:

* `small.highway.merger.diff`
* `remove.duplicate.areas.diff`

=== transliteration.max.cache.size

* Data Type: int
* Default Value: `-1`

The maximum size of the cache used by `ToEnglishDictionaryTranslator` for transliterations. A cache
size of -1 disables the transliteration cache.

=== unify.enable.optimal.constrained.matches

* Data Type: bool
* Default Value: `true`

Enable the calculation of Optimal Constrained Matches during conflation. When enabled, either
Optimal Constrained Matches (via GLPK) or Greedy Constrained Matches will be used. If disabled, only
Greedy Constrained Matches will be used.

=== unify.optimizer.time.limit

* Data Type: double
* Default Value: `60`

The maximum amount of time in seconds to wait for the optimizer to complete. A value of -1 makes the
wait time limit unlimited.

If this value is set to something other than -1, your conflation results may change between multiple
runs. Especially if the environment is under heavy load. If the "CM Score:" value is changing
between runs and GLPK isn't finding an optimal solution then this is likely causing different
output. Just because the output is changing doesn't mean it is wrong, but this can be problematic if
you're doing testing or expecting repeatable output for other.

=== unlikely.road.remover.heading.delta

* Data Type: double
* Default Value: `5.0`

Way heading delta, in degrees, used by `UnlikelyRoadRemover`. See `way.matcher.heading.delta`.

=== unlikely.road.remover.max.heading.variance

* Data Type: double
* Default Value: `60.0`

The heading variance, in degrees, a road may have at or above which it will be considered for removal by
`UnlikelyRoadRemover`.

=== unlikely.road.remover.max.length

* Data Type: double
* Default Value: `25.0`

The maximum length a road may have to be considered for removal by `UnlikelyRoadRemover`, in meters.

=== unlikely.road.remover.num.bins

* Data Type: int
* Default Value: `16`

Number of histogram bins used by `UnlikelyRoadRemover`. See `angle.histogram.extractor.bins`.

=== unlikely.road.remover.sample.distance

* Data Type: double
* Default Value: `1.0`

Way sample distance, n meters, used by `UnlikelyRoadRemover`. See `way.angle.sample.distance`.

=== uuid.helper.repeatable

* Data Type: bool
* Default Value: `false`

Creates a repeatable unique ID for conflated features. This is useful for debugging, but shouldn't
be used in normal operation.

=== way.angle.sample.distance

* Data Type: double
* Default Value: `10.0`

Distance, in meters, used for sampling way data during angle histogram extraction with
`SampledAngleHistogramExtractor`.

=== way.generalizer.criterion

* Data Type: string
* Default Value: ``

`ElementCriterion` derived class used for filtering by `WayGeneralizeVisitor`. All filtered elements
must be ways, so any contradicting filters will be ignored.

=== way.generalizer.epsilon

* Data Type: double
* Default Value: `0.1`

Distance parameter, in meters, that determines to what degree a way is generalized by
`WayGeneralizeVisitor`. Higher values result in more generalization (more nodes removed).

=== way.generalizer.remove.nodes.shared.by.ways

* Data Type: bool
* Default Value: `false`

If true, `WayGeneralizeVisitor` disregards nodes shared by ways when removing them. If false, it
won't remove them.

=== way.joiner

* Data Type: string
* Default Value: `WayJoinerBasic`

The way joining implementation used by `WayJoinerOp` to repair way splits after a conflation job.

This option can use the following implementations:
* `WayJoinerBasic`              - default implementation
* `WayJoinerAdvanced`           - has some additional features compared to the default
                                  implementation; currently used by Attribute Conflation and
                                  conflation done during Cut and Replace
* `ReplacementSnappedWayJoiner` - has way joining features specific to Cut and Replace

=== way.joiner.advanced.strict.name.match

* Data Type: bool
* Default Value: `false`

If enabled, `WayJoinerAdvanced` will not consider the `alt_name` tag when performing name
comparisons.

=== way.joiner.leave.parent.id

* Data Type: bool
* Default Value: `false`

If enabled, `WayJoinerOp` will leave a way's parent ID populated after joining.

=== way.joiner.write.parent.id.to.child.id

* Data Type: bool
* Default Value: `false`

If enabled, at the end of way joining `WayJoinerOp` will replace the ID of any element with a
parent ID with the parent ID's value. In the case of multiple elements with the same parent ID, only
the first element's ID will be updated. This can be useful when performing a bounded conflate and
the source data has relation with some members falling outside of the bounds.

=== way.matcher.heading.delta

* Data Type: double
* Default Value: `5.0`

The distance around a point on a way, in degrees, to look when calculating the heading. A larger
value will smooth out the heading values on a line. A smaller value will make the heading values
correspond directly to the heading on the way at that point. This is primarily used in subline
matching and may be overridden for certain feature types.

=== way.matcher.max.angle

* Data Type: double
* Default Value: `60.0`

Sets the maximum angle, in degrees, that can exist between ways and they are still considered a way
match.

=== way.max.nodes.per.way

* Data Type: int
* Default Value: `1900`

If empty or set to zero, there will be no maximum number of nodes for a way. If the value is set to
a positive value, all ways which contain more nodes than this value will be broken up into two or
more separate ways, and all of them will contain this number of nodes (or less). The original way
will be removed from the map.

=== way.merger.min.split.size

* Data Type: double
* Default Value: `5`

The minimum size, in meters, that a way should be split into for merging.

=== way.node.copier.duplicate.node.tolerance

* Data Type: double
* Default Value: `0.05`

Distance tolerance, in the range (0.0, 1.0], allowed for `WayNodeCopier` to consider two nodes
duplicates and not copy them. The higher the value, the more likely two nearby nodes would be
considered to be duplicates.

=== way.splitter.max.length

* Data Type: double
* Default Value: `5000`

When using `WaySplitterOp`, if a way is longer than this length, in meters, then it will be split
into smaller ways.

=== way.subline.matcher

* Data Type: string
* Default Value: `MaximalNearestSublineMatcher`

The way subline matcher to use when determining matching sublines. This may be overridden for
specific feature types.

=== way.subline.string.matcher

* Data Type: string
* Default Value: `MaximalSublineStringMatcher`

The way subline string matcher to use when determining matching sublines. This may be overridden for
specific feature types.

=== weighted.metric.distance.extractor.point.aggregator

* Data Type: string
* Default Value: `MeanAggregator`

Type of point aggregator used by `WeightedMetricDistanceExtractor`.

=== weighted.metric.distance.extractor.search.radius

* Data Type: double
* Default Value: `-1.0`

The search radius, in meters, used by `WeightedMetricDistanceExtractor`. Defaults to a value
computed from the circular error for each way being examined.

=== weighted.word.distance.abridged.dictionary

* Data Type: string
* Default Value: `dictionary/WordsAbridged.sqlite`

Location of the abridged word frequency dictionary. This is not ideal for some types of conflate
matching and you'll get repeated warnings if you use it, but you won't have to download a large
file.

=== weighted.word.distance.dictionary

* Data Type: string
* Default Value: `dictionary/words.sqlite`

Location of the word frequency dictionary. If the absolute file path isn't found, then
the local `conf` and `$HOOT_HOME/conf` directories will be searched.

This file is typically downloaded from:
https://hoot-support.s3.amazonaws.com/words1.sqlite.bz2

=== weighted.word.distance.probability

* Data Type: double
* Default Value: `1.0`

The weight used will be `1.0 / (w ^ p)` where w is the frequency. Valid values are >= 0, but
generally it should be `1 >= p >= 0`.

=== writer.clean.review.tags

* Data Type: bool
* Default Value: `true`

If true, review tags are treated as metadata tags and will be removed by the
`NoInformationElementRemover` cleaning operation.

=== writer.include.circular.error.tags

* Data Type: bool
* Default Value: `true`

When true, writers will include circular error information. Not necessarily honored by all writers.
This should be left enabled by default to prevent custom accuracy tags from being dropped by writers
in intermediary steps during a conflation workflow. Disable the option only on the final write for
a dataset.

=== writer.include.conflate.review.detail.tags

* Data Type: bool
* Default Value: `true`

Add detailed review tags to review relations during conflation. Turning this setting off is
generally only done in debugging environments. This setting allows for partitioning the level of
detail in the review relation tags into two groups. Turning this setting off can be useful during
debugging in situations where you are comparing map outputs and want to see reviews in the output
but are not concerned with a higher level of review detail. Disabling this setting will also
disable `AddHilbertReviewSortOrderOp`.

=== writer.include.conflate.score.tags

* Data Type: bool
* Default Value: `false`

Add match/miss/review score values to elements with matches during Unifying Conflation. This is
useful for debugging.

=== writer.include.debug.tags

* Data Type: bool
* Default Value: `false`

When true, writers will include debug information (`hoot:*` tags). Not honored by all writers.

=== writer.include.matched.by.tag

* Data Type: bool
* Default Value: `false`

If true, the `hoot:matchedBy` tag will be added to element output when
`writer.include.debug.tags=true`.

=== writer.precision

* Data Type: int
* Default Value: `16`

Set the output precision when writing. Not honored by all writers.

=== writer.sort.tags.by.key

* Data Type: bool
* Default Value: `false`

If true, sorts all tag key/value pairs alphabetically when written out. Not honored by all writers.

=== writer.sort.tags.imagery.source

* Data Type: bool
* Default Value: `false`

If true, sorts the `source:imagery` tag's value on output. Not honored by all writers.

=== writer.text.status

* Data Type: bool
* Default Value: `false`

Add `hoot:status` values as text: `Reference`, `Secondary`, or `Merged` instead of numbers: `1`,
`2`, or `3`.

=== writer.xml.sort.by.id

* Data Type: bool
* Default Value: `true`

If true, OSM elements written to XML file output (`.osm`) are sorted by ID. Setting this to true
will require reading the entire source dataset into memory. Setting it to false may result in
using smaller amounts of memory during writing if the data source being written is also a streamable
format (see the "Supported Data Formats" section in README.md).

=== writer.xml.format

* Data Type: bool
* Default Value: `true`

Turns on autoformatting (line breaks, indentation etc) for XML output.
