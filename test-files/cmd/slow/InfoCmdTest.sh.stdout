Listing all option names...

add.ref.visitor.information.only
add.ref1.visitor.prefix
add.review.tags.to.features
api.db.email
apidb.bulk.inserter.output.files.copy.location
apidb.bulk.inserter.run.validation.in.memory
apidb.bulk.inserter.starting.node.id
apidb.bulk.inserter.starting.way.id
apidb.bulk.inserter.starting.relation.id
apidb.bulk.inserter.stxxl.map.min.size
apidb.bulk.inserter.temp.file.dir
apidb.bulk.inserter.validate.data
attribute.count.values
attribute.score.extractor.use.weight
autocorrect.options
building.date.format
building.date.tag.key
building.keep.more.complex.geometry.when.auto.merging
building.match.threshold
building.miss.threshold
building.review.if.secondary.newer
building.review.matches.other.than.one.to.one
building.review.threshold
changeset.allow.deleting.reference.features
changeset.buffer
changeset.max.size
changeset.user.id
changeset.xml.writer.add.timestamp
circular.error.default.value
config.options.file
conflate.enable.old.roads
conflate.match.building.model
conflate.match.highway.classifier
conflate.match.highway.model
conflate.match.poi.model
conflate.match.threshold.default
conflate.miss.threshold.default
conflate.post.ops
conflate.pre.ops
conflate.review.threshold.default
conflate.stats.types
conflator.manipulators
conflator.min.valid.score
convert.bounding.box
convert.bounding.box.hoot.api.database
convert.bounding.box.osm.api.database
convert.ops
cookie.cutter.alpha
cookie.cutter.alpha.shape.buffer
cookie.cutter.output.crop
create.bogus.review.tags
crop.bounds
debug.map.filename
dual.way.splitter.driving.side
dual.way.splitter.split.size
duplicate.name.case.sensitive
duplicate.way.remover.strict.tag.matching
edge.distance.extractor.spacing
element.cache.size.node
element.cache.size.relation
element.cache.size.way
english.words.files
generic.line.match.threshold
generic.line.matcher.max.angle
generic.line.miss.threshold
generic.line.review.threshold
generic.line.subline.matcher
generic.polygon.match.threshold
generic.polygon.miss.threshold
generic.polygon.review.threshold
highway.match.threshold
highway.matcher.heading.delta
highway.matcher.max.angle
highway.max.enum.diff
highway.miss.threshold
highway.review.threshold
highway.subline.matcher
highway.subline.string.matcher
hootapi.db.writer.copy.bulk.insert
hootapi.db.writer.create.user
hootapi.db.writer.output.id.mappings
hootapi.db.writer.overwrite.map
hootapi.db.writer.remap.ids
id.generator
id.generator.node.start
id.generator.relation.start
id.generator.way.start
implicit.tagger.add.top.tag.only
implicit.tagger.allow.tagging.specific.entities
implicit.tagger.allow.words.involved.in.multiple.rules
implicit.tagger.match.end.of.name.single.token.first
implicit.tagger.poi.rules.database
implicit.tagging.database.deriver.minimum.tag.occurrences.per.word
implicit.tagging.database.deriver.minimum.word.length
implicit.tagging.database.deriver.poi.custom.rule.file
implicit.tagging.database.deriver.poi.tag.ignore.file
implicit.tagging.database.deriver.poi.word.ignore.file
implicit.tagging.database.deriver.use.schema.tag.values.for.words.only
implicit.tagging.keep.temp.files
implicit.tagging.raw.rules.deriver.skip.filtering
implicit.tagging.raw.rules.deriver.sort.parallel.count
implicit.tagging.translate.all.names.to.english
javascript.translator.path
json.add.bbox
json.format.hootenanny
json.perserve.empty.tags
json.pretty.print
keep.tags.visitor.keys
levenshtein.distance.alpha
log.format
log.warn.message.limit
map.cleaner.transforms
match.creators
match.parallel.exponent
max.elements.per.partial.map
max.memory.usage
merge.nearby.nodes.distance
merger.creators
network.conflicts.aggression
network.conflicts.outbound.weighting
network.conflicts.partial.handicap
network.conflicts.stub.handicap
network.conflicts.stub.through.weighting
network.conflicts.weight.influence
network.match.threshold
network.match.write.debug.maps
network.matcher
network.max.stub.length
network.miss.threshold
network.optimization.iterations
network.review.threshold
node.comparison.circular.error.sensitivity
node.comparison.coordinate.sensitivity
node.matcher.strictness
ogr.append.data
ogr.debug.addfcode
ogr.debug.dumptags
ogr.debug.dumpvalidate
ogr.debug.lookupclash
ogr.debug.lookupcolumn
ogr.esri.fcsubtype
ogr.esri.fdname
ogr.import.filter
ogr.note.extra
ogr.reader.bounding.box
ogr.reader.bounding.box.latlng
ogr.reader.epsg.override
ogr.reader.node.id.field.name
ogr.split.o2s
ogr.strict.checking
ogr.tds.add.etds
ogr.tds.extra
ogr.thematic.structure
ogr.throw.error
ogr.writer.create.all.layers
ogr.writer.pre.layer.name
ogr.writer.script
ogr2osm.ops
osmapidb.bulk.inserter.disable.database.constraints.during.write
osmapidb.bulk.inserter.disable.database.indexes.during.write
osmapidb.bulk.inserter.reserve.record.ids.before.writing.data
osmapidb.bulk.inserter.write.sql.file.id.sequence.updates
osmapidb.id.aware.url
osm.map.reader.factory.reader
osm.map.writer.factory.writer
osm.map.writer.format.xml
osm.map.writer.schema
osm.map.writer.skip.empty.map
osm2ogr.ops
perty.apply.rubber.sheet
perty.csm.D
perty.duplicate.poi.duplicate.sigma
perty.duplicate.poi.move.multiplier
perty.duplicate.poi.probability
perty.grid.spacing
perty.name.change.probability
perty.name.probability
perty.ops
perty.random.error.x
perty.random.error.y
perty.remove.random.probability
perty.remove.tag.probability
perty.remove.tag.visitor.exempt.tag.keys
perty.remove.tag.visitor.substitution.keys
perty.remove.tag.visitor.substitution.values
perty.search.distance
perty.seed
perty.systematic.error.x
perty.systematic.error.y
perty.test.allowed.score.variance
perty.test.dynamic.variable.increment
perty.test.dynamic.variable.start.value
perty.test.dynamic.variables
perty.test.expected.scores
perty.test.fail.on.better.score
perty.test.generate.map.stats
perty.test.num.runs
perty.test.num.simulations
perty.way.generalize.epsilon
perty.way.generalize.probability
perty.way.split.min.node.spacing
perty.way.split.probability
plugin.context.includes
poi.ignore.type.if.name.present
poi.match.threshold
poi.miss.threshold
poi.polygon.disable.same.source.conflation
poi.polygon.disable.same.source.conflation.match.tag.key.prefix.only
poi.polygon.enable.advanced.matching
poi.polygon.enable.review.reduction
poi.polygon.match.distance.threshold
poi.polygon.match.evidence.threshold
poi.polygon.match.threshold
poi.polygon.miss.threshold
poi.polygon.name.score.threshold
poi.polygon.print.match.distance.truth
poi.polygon.promote.points.with.addresses.to.pois
poi.polygon.review.distance.threshold
poi.polygon.review.evidence.threshold
poi.polygon.review.if.matched.types
poi.polygon.review.multiuse.buildings
poi.polygon.review.threshold
poi.polygon.source.tag.key
poi.polygon.type.score.threshold
poi.review.threshold
preserve.unknown1.element.id.when.modifying.features
progress.reporting.format
reader.add.source.datetime
reader.conflate.use.data.source.ids.1
reader.conflate.use.data.source.ids.2
reader.keep.status.tag
reader.preserve.all.tags
reader.set.default.status
reader.use.data.source.ids
reader.use.file.status
remove.attribute.visitor.types
remove.duplicate.areas.diff
remove.elements.visitor.filter
remove.elements.visitor.recursive
remove.tag.visitor.keys
rubber.sheet.debug
rubber.sheet.fail.when.minimum.tie.points.not.found
rubber.sheet.log.missing.requirements.as.warning
rubber.sheet.minimum.ties
rubber.sheet.ref
score.graph.debug.images
score.matches.remove.nodes
script.test.max.exec.time
search.radius.default
search.radius.generic.line
search.radius.generic.polygon
search.radius.highway
search.radius.waterway
set.tag.visitor.append.to.existing.value
set.tag.visitor.element.type
set.tag.visitor.key
set.tag.visitor.overwrite
set.tag.visitor.value
small.way.merger.diff
small.way.merger.threshold
spark.changeset.writer.element.payload.format
stats.format
stats.output
stats.script
stats.translate.script
status.criterion.status
status.update.visitor.only.update.invalid.status
status.update.visitor.status
tag.ancestor.differencer.name
tag.category.differencer.name
tag.criterion.kvp
tag.merger.default
tag.printing.format
tag.printing.script
tag.rename.visitor.new.key
tag.rename.visitor.old.key
task.status.update.interval
test.case.cmd
test.force.orthographic.projection
token.keep.non.words
token.min.size
token.separator
translate.string.distance.tokenize
translated.tag.differencer.ignore.list
translated.tag.differencer.script
translation.direction
translation.override
translation.script
unify.enable.optimal.constrained.matches
unify.optimizer.time.limit
unify.post.ops
unify.pre.ops
uuid.helper.repeatable
waterway.angle.sample.distance
waterway.auto.calc.search.radius
waterway.match.threshold
waterway.matcher.heading.delta
waterway.matcher.max.angle
waterway.miss.threshold
waterway.review.threshold
waterway.rubber.sheet.minimum.ties
waterway.rubber.sheet.ref
waterway.subline.matcher
way.angle.sample.distance
way.matcher.heading.delta
way.matcher.max.angle
way.max.nodes.per.way
way.merger.min.split.size
way.splitter.max.length
way.subline.matcher
way.subline.string.matcher
weighted.metric.distance.extractor.point.aggregator
weighted.metric.distance.extractor.search.radius
weighted.word.distance.abridged.dictionary
weighted.word.distance.dictionary
weighted.word.distance.probability
writer.clean.review.tags
writer.include.circular.error.tags
writer.include.conflate.review.detail.tags
writer.include.conflate.score.tags
writer.include.debug.tags
writer.precision
writer.text.status
writer.xml.sort.by.id

Listing all option names and descriptions...

=== add.ref.visitor.information.only

* Data Type: bool
* Default Value: `true`

Typically REF1/2 values are only applied to elements with informational tags (e.g. name=foo),
however setting this to false will apply REF1/2 values to all elements.

=== add.ref1.visitor.prefix

* Data Type: string
* Default Value: ``

Prefix to apply to REF1 values.

The REF1 values are typically used when training a model. See the Developer Documentation for
details.

=== add.review.tags.to.features

* Data Type: bool
* Default Value: `false`

If true, not only will review relations receive the hoot:review:needs tag, the features involved in
the review will receive them as well.

=== api.db.email

* Data Type: string
* Default Value: ``

Email address of the API database user.  Can be set here for debugging and testing.

=== apidb.bulk.inserter.output.files.copy.location

* Data Type: string
* Default Value: ``

Use this option if you wish to retain the file data generated during an OSM/Hootenanny API database
write.  This option is not needed and will be ignored if writing OSM data to a SQL file that will be
applied/written to an OSM API database at a later time.  If this option is populated, any file data
files generated as a result of executing the hoot convert command with an OSM API database target
are copied to the specified location.  This option should be set to a full file path to a SQL
file (.sql).

=== apidb.bulk.inserter.run.validation.in.memory

* Data Type: bool
* Default Value: `false`

When set to true, this bypasses STXXL disk writing completely when performing data validation, is
equivalent to apidb.bulk.inserter.validate.data=true and
apidb.bulk.inserter.stxxl.map.min.size=<infinity>, and overrides values passed in for those
settings.  If the system does not have enough memory to support in memory validation of the loaded
features, an out of memory error will occur.

=== apidb.bulk.inserter.starting.node.id

* Data Type: long
* Default Value: `1`

First record ID to assign to written nodes when writing to an OSM/Hootenanny API database or SQL
file.  Must be a positive number.  Use this when working with an offline database and know the
ID range you want to assign to node records.  If writing to an OSM API databse, this option is
ignored if "osmapidb.bulk.inserter.reserve.record.ids.before.writing.data" is set to true.

=== apidb.bulk.inserter.starting.way.id

* Data Type: long
* Default Value: `1`

First record ID to assign to written ways when writing to an OSM/Hootenanny API database or SQL file.  Must
be a positive number.  Use this when working with an offline database and know the ID range you
want to assign to way records.  If writing to an OSM API databse, this option is
ignored if "osmapidb.bulk.inserter.reserve.record.ids.before.writing.data" is set to true.

=== apidb.bulk.inserter.starting.relation.id

* Data Type: long
* Default Value: `1`

First record ID to assign to written relations when writing to an OSM/Hootenanny API database or
SQL file.  Must be a positive number.  Use this when working with an offline database and know the
ID range you want to assign to relation records.  If writing to an OSM API databse, this option is
ignored if "osmapidb.bulk.inserter.reserve.record.ids.before.writing.data" is set to true.

=== apidb.bulk.inserter.stxxl.map.min.size

* Data Type: long
* Default Value: `10000000`

Size at which the ID mappings storage for the OSM/Hootenanny API database bulk inserter switches
from a std::map to an stxxl::map, which is a container optimized for very large amounts of data.
For debugging purposes only.

=== apidb.bulk.inserter.temp.file.dir

* Data Type: string
* Default Value: `/tmp`

Allows for customizing where the OSM/Hootenanny API database bulk inserter stores temp files.

=== apidb.bulk.inserter.validate.data

* Data Type: bool
* Default Value: `false`

If true, the OSM/Hootenanny API database bulk inserter will renumber element IDs, check for
duplicated element IDs, check for invalid way node references, and check for invalid relation member
references.  Only duplicate element IDs and invalid way node references will cause a failure.
Invalid relation members will cause a warning to be logged.  You should enable this setting if you
are loading data that has not been previously validated in another OSM API database.  Enabling this
setting may cause writing to an OSM API database to occur more slowly.

=== attribute.count.values

* Data Type: int
* Default Value: `30`

The maximum number of values returned for each attribute by the attribute-count command.

=== attribute.score.extractor.use.weight

* Data Type: bool
* Default Value: `false`

Determines whether the AttributeScoreExtractor uses weighting when extracting scores.

=== autocorrect.options

* Data Type: bool
* Default Value: `true`

Temporary setting that addresses some Hootenanny iD Editor UI bugs.  See
MatchFactory::_tempFixDefaults() for more info.

=== building.date.format

* Data Type: string
* Default Value: `yyyy-MM-ddTHH:mm`

Date format string used by the building date tag value.  See QDateTime::fromString for more details.

=== building.date.tag.key

* Data Type: string
* Default Value: `source:date`

Tag key used by the building.review.if.secondary.newer configuration option.

=== building.keep.more.complex.geometry.when.auto.merging

* Data Type: bool
* Default Value: `true`

If true, when buildings are auto-merged during conflation the geometry of the more complex building
is the one that is kept.  If false or the buildings are equally complex, then the geometry of the
first building in the pair passed to the Building Merger is the geometry kept.  This does not apply
to feature merging done during the manual review process.

=== building.match.threshold

* Data Type: double
* Default Value: `${conflate.match.threshold.default}`

The threshold at which a match is called a match for buildings.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== building.miss.threshold

* Data Type: double
* Default Value: `${conflate.miss.threshold.default}`

The threshold at which a miss is called a miss for buildings.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== building.review.if.secondary.newer

* Data Type: bool
* Default Value: `false`

If true, any buildings in the secondary layer will be automatically reviewed against potentially
matching features in the reference layer if they are marked with a more recent date than that of the
reference feature.

=== building.review.matches.other.than.one.to.one

* Data Type: bool
* Default Value: `false`

If true, any building matches other than 1:1 matches are automatically marked for review.

=== building.review.threshold

* Data Type: double
* Default Value: `${conflate.review.threshold.default}`

The threshold at which a review is called a review for buildings.  See
`conflate.review.threshold.default`.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== changeset.allow.deleting.reference.features

* Data Type: bool
* Default Value: `true`

If true, changesets derived can issue delete statements for the reference dataset (first dataset
passed to the changeset deriver).  If false, no delete statements will be issued for the reference
dataset.

=== changeset.buffer

* Data Type: double
* Default Value: `0.0`

Value in degrees by which the specified AOI (convert.bounding.box) will be expanded when calculating
changesets.  Setting this too large with some datasets may greatly increase the changeset
derivation time.

=== changeset.max.size

* Data Type: long
* Default Value: `50000`

The maximum allowed element size of an OSM changeset written to an OSM API database.

=== changeset.user.id

* Data Type: long
* Default Value: `-1`

The user ID used by certain changeset writers when writing to an OSM API database.

=== changeset.xml.writer.add.timestamp

* Data Type: bool
* Default Value: `true`

If true, XML changesets will add the 'timestamp' attribute to the element tags.  If false, the
timestamp attribute will not be added.  This generally should only be set to false for testing
purposes.

=== circular.error.default.value

* Data Type: double
* Default Value: `15`

Set the circular error tag on features to this value, in meters, by default if the tag isn't already
populated.

=== config.options.file

* Data Type: string
* Default Value: `conf/core/ConfigOptions.asciidoc`

Path to this file.  Only modified during testing the Hootenanny options command.

=== conflate.enable.old.roads

* Data Type: bool
* Default Value: `false`

Enable the old road conflation. This is only necessary when using the `conflate` command. See the
_Command Line Reference_ for details on the `conflate` command.

By default the `conflate` command will first conflate roads using the circa 2012 conflation
algorithm and then conflate using the newer (circa 2014) unifying algorithm. If the unifying
algorithm has road conflation enable then the results could get interesting.

=== conflate.match.building.model

* Data Type: string
* Default Value: `models/BuildingModel.rf`

Path to the RF building model. A new model can be created with `model-build`. Searches local path
and then `$HOOT_HOME/conf/`.

=== conflate.match.highway.classifier

* Data Type: string
* Default Value: `hoot::HighwayRfClassifier`

The highway match classifier to use. This should only be used for testing and debugging.

=== conflate.match.highway.model

* Data Type: string
* Default Value: `models/HighwayModel.rf`

Path to the RF highway model. A new model can be created with `model-build`. Searches local path
and then `$HOOT_HOME/conf/`. This is only relevant if the `conflate.match.highway.classifier` is
set to `hoot::HighwayRfClassifier`.

=== conflate.match.poi.model

* Data Type: string
* Default Value: `models/PoiModel.rf`

Path to the POI match classifier model. A new model can be created with `model-build`. Searches
local path and then `$HOOT_HOME/conf/`.

=== conflate.match.threshold.default

* Data Type: double
* Default Value: `0.6`

The default threshold at which a match is called a match.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== conflate.miss.threshold.default

* Data Type: double
* Default Value: `0.6`

The default threshold at which a miss is called a miss.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== conflate.post.ops

* Data Type: list
* Default Value:
** `hoot::RemoveMissingElementsVisitor` - Removes non-existent element references from relations or ways with negative IDs.
** `hoot::RemoveEmptyRelationsOp` - Removes empty relations.
** `hoot::RemoveInvalidReviewRelationsVisitor` - Removes review relations whose members no longer exist after conflation.
** `hoot::RemoveDuplicateReviewsOp` - Removes any duplicate reviews
** `hoot::BuildingOutlineUpdateOp` - Updates any multi-part building outlines that may have changed during conflation.
** `hoot::RemoveInvalidMultilineStringMembersVisitor` - Removes invalid multilinestring relations.
** `hoot::SuperfluousWayRemover` - Remove all ways that contain no nodes or all the nodes are exactly the same.
** `hoot::RemoveDuplicateWayNodesVisitor` - Remove all nodes that are unnecessarily duplicated in a way.
** `hoot::AddHilbertReviewSortOrderOp` - Adds a sorting value to all reviews.  By processing reviews in sorted order the results are a little more logically ordered.

List of operations to run in the conflate command after data is conflated, after the ops in
unify.post.ops (if using Unifying Conflation), but before exporting.

=== conflate.pre.ops

* Data Type: list
* Default Value:
** `hoot::BuildingOutlineRemoveOp` - Updates the outline of the building by taking the union of all the building parts.
** `hoot::MapCleaner` - Performs a collection of map cleaning operations.

Runs in the conflate command after data is loaded, but before the conflation and before the ops in
unify.pre.ops (if using Unifying Conflation).

See also: <<MapCleanerTransforms,map.cleaner.transforms>>

=== conflate.review.threshold.default

* Data Type: double
* Default Value: `0.6`

The default threshold at which a review is called a review. Reviews are also declared in some
other situations when the relationship is not clear.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== conflate.stats.types

* Data Type: string
* Default Value: ``

The string that lists the types of conflation used in the user interface.  The possible values
are: reference, cookieCutter, average, and advancedConflation.

=== conflator.manipulators

* Data Type: list
* Default Value:
** `hoot::WayMerger`

List of manipulators to enable in the conflator.

Some of the possible options include:

* `hoot::WayMerger` -
* `hoot::WayTagMerger` -

=== conflator.min.valid.score

* Data Type: double
* Default Value: `0.01`

This is the minimum valid manipulation score in the legacy greedy optimization routine. Setting
the value lower will create more (likely overzealous) matches. Setting the value higher will drop
less confident matches.

=== convert.bounding.box

* Data Type: string
* Default Value: ``

If specified, supporting readers will limit data read from the data source to only features that
intersect the given bounding box. The format is "minx,miny,maxx,maxy" specified in the projection
of the input data source.  This setting can be used with both the convert and conflate commands.
See the documentation for more details.

Example Usage:

----
hoot convert -D convert.bounding.box=106.851,-6.160,107.052,-5.913 input output
----

=== convert.bounding.box.hoot.api.database

* Data Type: string
* Default Value: ``

Same as convert.bounding.box but the resultant bounds filtering is only applied to Hootenanny API
database data sources when used with the convert and conflate commands.  This setting takes
precendence over the convert.bounding.box setting for Hootenanny API database data sources only.

=== convert.bounding.box.osm.api.database

* Data Type: string
* Default Value: ``

Same as convert.bounding.box but the resultant bounds filtering is only applied to OSM API database
data sources when used with the convert and conflate commands.  This setting takes precendence over
the convert.bounding.box setting for OSM API database data sources only.

=== convert.ops

* Data Type: list
* Default Value:
** ``

Specifies one or more semi-colon delimited operations to perform before writing data. This is only
applicable to the convert command.

=== cookie.cutter.alpha

* Data Type: double
* Default Value: `1000.0`

The size in meters used for alpha by the cookie cutter map operation (CookieCutterOp). A larger
value makes a smoother shape and a smaller value will create a rough shape with more holes. Value
in meters.

=== cookie.cutter.alpha.shape.buffer

* Data Type: double
* Default Value: `0.0`

The buffer to add to the alpha shape before cutting by the cookie cutter map operation
(CookieCutterOp). A negative value will make the shape smaller.  Value in meters.

=== cookie.cutter.output.crop

* Data Type: bool
* Default Value: `false`

Crops based on the polygon rather than doing a cookie cut when using the cookie cutter map
operation (see CookieCutterOp).

=== create.bogus.review.tags

* Data Type: bool
* Default Value: `false`

Creates example review tags for debugging. All reviews created with this mechanism are invalid.

=== crop.bounds

* Data Type: string
* Default Value: ``

Bounds used by the map cropper when cropping a map, of the form: minx,miny,maxx,maxy

=== debug.map.filename

* Data Type: string
* Default Value: `tmp/debug.osm`

Debugging: The filename to use when saving the debug map during conflation.

=== dual.way.splitter.driving.side

* Data Type: string
* Default Value: `right`

When splitting divided highways, do we assume the drivers are on the right or left?

See also: <<MapCleanerTransforms,map.cleaner.transforms>>

=== dual.way.splitter.split.size

* Data Type: double
* Default Value: `12.5`

By default how much space should be put between two divided roads when they're divided by the
DividedHighwaySplitter. Units are in meters.

See also: <<MapCleanerTransforms,map.cleaner.transforms>>

=== duplicate.name.case.sensitive

* Data Type: bool
* Default Value: `true`

If true, all cleaning and conflation merge operations will only remove duplicate names when their
case also matches.  If false, cleaning and conflation merge operations will consider names with
the same text but differing case as the same with each other.

See also: <<MapCleanerTransforms,map.cleaner.transforms>>

=== duplicate.way.remover.strict.tag.matching

* Data Type: bool
* Default Value: `true`

If true, when comparing duplicate ways, the ways and their name tags will only be merged together
when all other non-name tags between the two match.  If false, the ways and their name tags will be
merged together regardless of whether all of their non-name tags match.

=== edge.distance.extractor.spacing

* Data Type: double
* Default Value: `5.0`

The spacing used by the EdgeDistanceExtractor.  Units in meters.

=== element.cache.size.node

* Data Type: long
* Default Value: `2000000`

Size of the in memory node cache used when streaming I/O is used with nodes.

=== element.cache.size.relation

* Data Type: long
* Default Value: `200000`

Size of the in memory relation cache used when streaming I/O is used with relations.

=== element.cache.size.way

* Data Type: long
* Default Value: `200000`

Size of the in memory way cache used when streaming I/O is used with ways.

=== english.words.files

* Data Type: list
* Default Value:
** `/usr/share/dict/american-english-insane`
** `/usr/share/dict/american-english-huge`
** `/usr/share/dict/american-english-large`
** `/usr/share/dict/american-english-small`
** `/usr/share/dict/american-english`
** `/usr/share/dict/words`

Absolute file path to dictionaries of English words. The first file found will be loaded into the
dictionary of English words and used by some algorithms. If the files are not found then the English
words will be silently ignored.

=== generic.line.match.threshold

* Data Type: double
* Default Value: `${conflate.match.threshold.default}`

The threshold at which a match is called a match for generic lines.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== generic.line.matcher.max.angle

* Data Type: double
* Default Value: `90.0`

Sets that maximum angle that is still considered a generic line match. Units in degrees.

=== generic.line.miss.threshold

* Data Type: double
* Default Value: `${conflate.miss.threshold.default}`

The threshold at which a miss is called a miss for generic lines.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== generic.line.review.threshold

* Data Type: double
* Default Value: `${conflate.review.threshold.default}`

The threshold at which a review is called a review for generic lines. See
`conflate.review.threshold.default`.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== generic.line.subline.matcher

* Data Type: string
* Default Value: `hoot::MaximalSublineMatcher`

The way subline matcher to use when determining matching sublines with generic line conflation.

=== generic.polygon.match.threshold

* Data Type: double
* Default Value: `${conflate.match.threshold.default}`

The threshold at which a match is called a match for generic polygons.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== generic.polygon.miss.threshold

* Data Type: double
* Default Value: `${conflate.miss.threshold.default}`

The threshold at which a miss is called a miss for generic polygons.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== generic.polygon.review.threshold

* Data Type: double
* Default Value: `${conflate.review.threshold.default}`

The threshold at which a review is called a review for generic polygons. See
`conflate.review.threshold.default`.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== highway.match.threshold

* Data Type: double
* Default Value: `0.161`

The threshold at which a match is called a match for roads.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== highway.matcher.heading.delta

* Data Type: double
* Default Value: `${way.matcher.heading.delta}`

The distance around a point on a highway to look when calculating the heading.  See
`way.matcher.heading.delta`.

=== highway.matcher.max.angle

* Data Type: double
* Default Value: `${way.matcher.max.angle}`

Sets that maximum angle that is still considered a highway match. Units in degrees.

=== highway.max.enum.diff

* Data Type: double
* Default Value: `0.6`

If two highways have significantly different enumerated types then they will not be considered
for match. For example:

* "highway=primary" vs "highway=secondary" has a diff of 0.2.
* "highway=primary" vs "highway=footway" has a diff of 0.67.

=== highway.miss.threshold

* Data Type: double
* Default Value: `0.999`

The threshold at which a miss is called a miss for roads.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== highway.review.threshold

* Data Type: double
* Default Value: `0.25`

The threshold at which a review is called a review for roads. See `conflate.review.threshold.default`.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== highway.subline.matcher

* Data Type: string
* Default Value: `${way.subline.matcher}`

The highway subline matcher to use when determining matching highway sublines.

=== highway.subline.string.matcher

* Data Type: string
* Default Value: `${way.subline.string.matcher}`

The way subline string matcher to use when determining matching sublines for highways.

=== hootapi.db.writer.copy.bulk.insert

* Data Type: bool
* Default Value: `false`

If set to true, the Hootenanny API database writer will insert new records using Postgres COPY
statements, which may increase performance when writing large datasets.  This setting can only
be activated when writing new records and will not work when existing records need to be modified
or deleted.  It also requires writing out temporary files, so extra disk space is needed.

=== hootapi.db.writer.create.user

* Data Type: bool
* Default Value: `false`

Should the hootapi services DB writer automatically create the specified user if it doesn't exist.
This is most useful when debugging and testing.

=== hootapi.db.writer.output.id.mappings

* Data Type: string
* Default Value: ``

If this value is set to a non-empty string, the system will attempt to open a file with the
specified name and output all the ID mappings (source to destination) used for nodes, ways, and
relations that were written to the database.

=== hootapi.db.writer.overwrite.map

* Data Type: bool
* Default Value: `false`

If set to true then if there is already a map with the specified name then it will be removed before
a new map is written.

=== hootapi.db.writer.remap.ids

* Data Type: bool
* Default Value: `true`

If this value is set to true, then all incoming element IDs are remapped into new IDs as the
elements are written to a Hootenanny API database. Setting it to true is appropriate if any of the
incoming IDs are non-positive.

=== id.generator

* Data Type: string
* Default Value: `hoot::DefaultIdGenerator`

Sets the default ID generator class name. This determines how Hootenanny will assign new element
IDs as they're created. The `DefaultIdGenerator` assigns IDs in a decrementing fashion (e.g. -1,
-2, ...). The `hoot::PositiveIdGenerator` increments the IDs (e.g. 1, 2, 3, ...).

Both generators maintain a different count for each element type. E.g. you can have a Node with ID
1 and a Way with ID 1. This will not cause any problems within Hootenanny and is a legitimate way
of assigning IDs within OSM.

Example Usage:

----
hoot convert-ogr2osm -D id.generator=hoot::PositiveIdGenerator -D id.generator.node.start=100 -D id.generator.relation.start=200 -D id.generator.way.start=300 $HOOT_HOME/translations/Identity.js myoutput.osm myinput.osm
----

=== id.generator.node.start

* Data Type: double
* Default Value: `0`

Sets the default start ID for nodes. The first value assigned is generator specific. (E.g. for
default the first assigned id will be -1)

=== id.generator.relation.start

* Data Type: double
* Default Value: `0`

Sets the default start ID for relations. The first value assigned is generator specific. (E.g.
for default the first assigned id will be -1)

=== id.generator.way.start

* Data Type: double
* Default Value: `0`

Sets the default start ID for ways. The first value assigned is generator specific. (E.g. for
default the first assigned id will be -1)

=== implicit.tagger.add.top.tag.only

* Data Type: bool
* Default Value: `true`

If true, implicit taggers will only add the implicit tag to the element with the highest tag
occurrence count for a given set of inputs name tokens.  Setting to true may be useful in reducing
false positive applied tags to elements.

=== implicit.tagger.allow.tagging.specific.entities

* Data Type: bool
* Default Value: `true`

If true, implicit taggers will attempt to add more specific tags to existing non-generic elements
(dependent on the element type filter; e.g. for POIs, elements with a tag more specific than
"poi=yes").  If false, implicit taggers will ignore all non-generic elements during implicit tagging.

=== implicit.tagger.allow.words.involved.in.multiple.rules

* Data Type: bool
* Default Value: `false`

If true, implicit taggers will allow for returning tags for a name when that name is involved in
more than one tagging rule.  Setting to false may be useful in reducing false positive applied tags
to elements.

=== implicit.tagger.match.end.of.name.single.token.first

* Data Type: bool
* Default Value: `true`

If true, implicit taggers will attempt to match the last token in a name to an implicit tag rule
first before attempting to match other parts of the name.  Setting to true can be useful in getting
better tagging performance for names that would otherwise be involved in multiple implicit tag
rules.

=== implicit.tagger.poi.rules.database

* Data Type: string
* Default Value: `${HOOT_HOME}/conf/core/implicit-tag-rules/poi-allCountries-planet-11-2-17-minwordocc=1000-schemaonly=true.sqlite`

Database used by the POI implicit tagger to derive POI type tags implicitly based on a POI's name.

=== implicit.tagging.database.deriver.minimum.tag.occurrences.per.word

* Data Type: int
* Default Value: `1000`

The minimum number of times a tag must be associated with a word in order for an implicit tag rule
to be created that is associated with it.

=== implicit.tagging.database.deriver.minimum.word.length

* Data Type: int
* Default Value: `3`

The minimum allowed word length when associating word tokens with tags.

=== implicit.tagging.database.deriver.poi.custom.rule.file

* Data Type: string
* Default Value: `${HOOT_HOME}/conf/core/implicit-tag-rules/poiImplicitTagRulesCustomRuleList`

Flat file containing tab separated word key/value pairs, one per line, to use as custom rules
when deriving an implicit tags database from POI names.

=== implicit.tagging.database.deriver.poi.tag.ignore.file

* Data Type: string
* Default Value: `${HOOT_HOME}/conf/core/implicit-tag-rules/poiImplicitTagRulesTagIgnoreList`

Flat file containing key/value pairs, one per line, to ignore when deriving an implicit tags
database from POI names.  Use 'key=*' to ignore all tags for a given key.

=== implicit.tagging.database.deriver.poi.word.ignore.file

* Data Type: string
* Default Value: `${HOOT_HOME}/conf/core/implicit-tag-rules/poiImplicitTagRulesWordIgnoreList`

Flat file containing words, one per line, to ignore when deriving an implicit tags database from
POI names.

=== implicit.tagging.database.deriver.use.schema.tag.values.for.words.only

* Data Type: bool
* Default Value: `true`

If true, the implicit tag raw rules generator will only consider words that correspond to a OSM tag
value in the Hootenanny schema.

=== implicit.tagging.keep.temp.files

* Data Type: bool
* Default Value: `false`

If true, the implicit tag raw rules/database derivers will keep all temporary file output.  For
debugging only.

=== implicit.tagging.raw.rules.deriver.skip.filtering

* Data Type: bool
* Default Value: `false`

If true, the implicit tag raw rules deriver will skip node filtering.  Only set to true if the input
data has been filtered with ImplicitTagEligiblePoiCriterion beforehand.

=== implicit.tagging.raw.rules.deriver.sort.parallel.count

* Data Type: int
* Default Value: `-1`

The number of parallel processes used when sorting output by the implicit tag raw rules deriver.
The default value of -1 uses a count equal to the number of processors on the machine.  Valid values
are -1 or 1 up to the number of available processors.

=== implicit.tagging.translate.all.names.to.english

* Data Type: bool
* Default Value: `true`

If true, the implicit tag raw rules deriver will translate name words to English as implicit tag
rules are derived.  Also, all implicit taggers will translate element name words to English before
querying the corresponding implicit tag rules database.  The value of this setting should be set the
same way when deriving raw implicit tag rules as it is when tagging elements with an implicit tagger.

=== javascript.translator.path

* Data Type: list
* Default Value:
** `${HOOT_TRANSLATE_PATH}`
** `${HOOT_HOME}/plugins`
** `${HOOT_HOME}/plugins-local`
** `${HOOT_HOME}/rules`

A list of paths to include in the javascript translator search path.

=== json.add.bbox

* Data Type: bool
* Default Value: `false`

When reading JSON, add a tag with the bounding box for each element

=== json.format.hootenanny

* Data Type: bool
* Default Value: `false`

Output JSON in a more Hootenanny specific way that includes Hootenanny-specific tags
including `hoot:*`, `error:circluar`, `type=node/way/relation`, tags in the `tags`
section, etc.

`Generic Format`
-----
...
{
  "type":"Feature",
  "properties":{
    "type":"LineString",
    "REF1":"Panera",
    "access":{ "groups":[],"users":[] },
    "attributes":{
      "item_date":"2017-10-09T12:34:56.789Z",
      "category_id":"123456",
      "asset_id":"ABC123"
      },
    "alt_name":null,
    "building":"yes",
    "name":"Panera Bread",
    "item_type":[ "building","restaurant" ],
    },
  "geometry":{
    "type":"Polygon",
    "coordinates":[[[-104.8065566424573,39.59327717293566],
                    [-104.8061245919961,39.59330667331412],
                    [-104.8060931452853,39.59315284977403],
                    [-104.8065292974914,39.59311913497989],
                    [-104.8065566424573,39.59327717293566]]]
    }
},
...
-----
vs
`Hootenanny-specific Format`
-----
...
{
  "type":"Feature",
  "id":"-2",
  "properties":{
    "type":"way",
    "tags":{
      "REF1":"Panera",
      "access":{ "groups":[],"users":[] },
      "attributes":{
        "item_date":"2017-10-09T12:34:56.789Z",
        "category_id":"123456",
        "asset_id":"ABC123"
        },
      "alt_name":null,
      "building":"yes",
      "type":"way",
      "name":"Panera Bread",
      "item_type":[ "building","restaurant" ],
      "error:circular":"15"
      }
    },
  "geometry":{
    "type":"Polygon",
    "coordinates":[[[-104.8065566424573,39.59327717293566],
                    [-104.8061245919961,39.59330667331412],
                    [-104.8060931452853,39.59315284977403],
                    [-104.8065292974914,39.59311913497989],
                    [-104.8065566424573,39.59327717293566]]]
    }
},
...
-----

=== json.perserve.empty.tags

* Data Type: bool
* Default Value: `true`

Write out empty OSM tags to JSON such as `"text":""`

=== json.pretty.print

* Data Type: bool
* Default Value: `false`

Write out JSON in a more legible manner

=== keep.tags.visitor.keys

* Data Type: list
* Default Value:
** ``

A list of tag keys for which the KeepTagsVisitor will retain on elements, while removing all
other tags from elements.

=== levenshtein.distance.alpha

* Data Type: double
* Default Value: `1.15`

Raise the Levenshtein score to this power before returning this result. If alpha is greater than
1 then this makes low scores even lower. Valid values are > 0.

The default alpha value of 1.15 was determined through experimentation with a Jakarta data set
using MeanWordSetDistance as the container classes. See Redmine ticket #2349 for some experiment
details.  The "best" value varies depending on the input data as well as how the data is being used.

=== log.format

* Data Type: string
* Default Value: `%d{HH:mm:ss.SSS} %-5p ...%.30F(%4L) %m%n`

If available, uses the formatting as defined in
to set the log format. If log4cxx isn't available then this has no effect.

Some example format strings and the associated output are below:

-----
# Default log message with lots of information
%d{HH:mm:ss.SSS} %-5p ...%.30F(%4L) %m%n
12:36:03.565 INFO  ...conflate/UnifyingConflator.cpp( 154) Pre-constraining match count: 11

# Log message w/ minimal information
%-5p..%.20F(%3L) %m%n
INFO ..nifyingConflator.cpp(154) Pre-constraining match count: 11

# Embed arbitrary strings in the log messages
Foo: %m%n
Foo: Pre-constraining match count: 11

# Print out time elapsed in ms along w/ other info
%6r %-5p..%.20F(%3L) %m%n
   289 INFO ..nifyingConflator.cpp(154) Pre-constraining match count: 11

# XML-ish log message. This allows parsing messages that span multiple lines,
# but you aren't guaranteed that all output from hoot goes through the logging
# mechanism.
<message time='%d' level='%p' file='%F' line='%L'>%m</message>%n
<message time='2014-10-28 13:09:35,339' level='INFO' file='src/main/cpp/hoot/core/conflate/UnifyingConflator.cpp' line='154'>Pre-constraining match count: 11</message>
-----

=== log.warn.message.limit

* Data Type: double
* Default Value: `3`

The maximum number of warn log messages that will be emittes per class before they are silenced.
Not necessarily utilized by all parts of the application.

[[MapCleanerTransforms]]
=== map.cleaner.transforms

* Data Type: list
* Default Value:
** `hoot::ReprojectToPlanarOp` - Before any cleaning, reproject to a planar projection (e.g. UTM).
** `hoot::DuplicateWayRemover` - Remove duplicate ways (lines) that are exact duplicates. If the lines partially overlap with exactly the same geometry then only the partial overlap is removed from the more complex geometry.
** `hoot::SuperfluousWayRemover` - Remove all ways that contain no nodes or all the nodes are exactly the same.
** `hoot::IntersectionSplitter` - Split all highway type ways that intersect.
** `hoot::UnlikelyIntersectionRemover` - Remove implied intersections that are likely incorrect. For example, a motorway overpass intersecting a residential street at a 90° is considered unlikely and "unsnapped". The geometry location is not modified.
** `hoot::DualWaySplitter` - Split highway types that are marked as divided into two separate geometries marked as oneway roads. A number of assumptions must be made to do this including assumptions about the direction of travel on roads (right or left hand drivers).
** `hoot::ImpliedDividedMarker` - If two roads implicitly should be marked as divided based on the surrounding roads, mark it as such. This is primarily caused by the FACC+ spec which does not allow bridges to be marked as divided.
** `hoot::DuplicateNameRemover` - Remove any duplicate names. See `duplicate.name.case.sensitive` for modifying the case sensitivity.
** `hoot::SmallWayMerger` - Merge any ludicrously small ways that have essentially the same attributes. Things like `UUID` are ignored. See `small.way.merger.threshold` for setting the threshold value.
** `hoot::RemoveEmptyAreasVisitor` - Remove all area elements that have a area of zero.
** `hoot::RemoveDuplicateAreaVisitor` - Remove any area elements that are essentially the same.
** `hoot::NoInformationElementRemover` - Remove any elements that don't have any tags with information. (E.g. only contains UUID and source, but not FCODE equivalent or other informative tags).

A list of map operations to be applied to a map for cleaning purposes, in order.

[[match.creators]]
=== match.creators

* Data Type: string
* Default Value: `hoot::BuildingMatchCreator;hoot::ScriptMatchCreator,PoiGeneric.js;hoot::HighwayMatchCreator;hoot::ScriptMatchCreator,LinearWaterway.js;hoot::PoiPolygonMatchCreator;hoot::ScriptMatchCreator,Area.js`

List of match creators to use during conflation. This can modify what features will be conflated
(e.g. buildings, roads, etc.).  The ordering must match that in merger.creators.

Some of the possible options include:

* `hoot::BuildingMatchCreator` - Matches building polygons.
* `hoot::HighwayMatchCreator` - Matches linear highway features using the Unify algorithm.
* `hoot::NetworkMatchCreator` - Matches linear highway features using the Network algorithm.
* `hoot::PoiPolygonMatchCreator` - Matches POIs with buildings or areas.
* `hoot::ScriptMatchCreator,Area.js` - Matches areas (non-building polygons marked as areas; e.g. parks, parking lots, etc.).
* `hoot::ScriptMatchCreator,PoiGeneric.js` - Matches POIs using the Unify algorithm.
* `hoot::ScriptMatchCreator,LinearWaterway.js` - Matches linear rivers and streams.
* `hoot::ScriptMatchCreator,<yourscript.js>` - Uses a custom match script. The script should be
  in `$HOOT_HOME/rules/<yourscript.js>`.

=== match.parallel.exponent

* Data Type: double
* Default Value: `1`

Used in the calculation of the match parallel score, cos (delta) ^ match.parallel.exponent

=== max.elements.per.partial.map

* Data Type: double
* Default Value: `100000`

Maximum number of elements that will be read into memory at one time during a partial OSM map
reading.  This shouldn't need to be changed.  Reducing the value may cause errors on some data
formats that read large numbers of entries at one time. Increasing the value will use more RAM in
some situations.

=== max.memory.usage

* Data Type: string
* Default Value: `-1`

Allows for artificially limiting the amount of virtual memory that Hootenanny will use. If
Hootenanny needs more than this amount of virtual memory then a bad_alloc will likely be thrown.
In some cases you will receive a totally unrelated error message.

Size is specified in bytes unless followed by one of these suffixes.

* KB = size * 1000
* MB = size * 1000 * 1000
* GB = size * 1000 * 1000 * 1000

For instance setting the value to 500KB is equivalent to 500000 bytes.

The Linux utility RLIMIT_AS is used for limiting virtual memory. This is analagous to RAM, but
less RAM will be utilized than the value specified. Typically this is most useful when limiting
RAM usage of applications in a shared server environment.

=== merge.nearby.nodes.distance

* Data Type: double
* Default Value: `1.0`

When merging nodes during convert-ogr2osm, determines what tolerance should be used for deciding two nodes
are identical. Units in meters and defaults to 1.0m.

[[merger.creators]]
=== merger.creators

* Data Type: string
* Default Value: `hoot::BuildingMergerCreator;hoot::ScriptMergerCreator;hoot::HighwaySnapMergerCreator;hoot::ScriptMergerCreator;hoot::PoiPolygonMergerCreator;hoot::ScriptMergerCreator`

List of merger creators to use during conflation. This can modify what features will be conflated
(e.g. buildings, roads, etc.).  The ordering must match that in match.creators.

Possible values include:

* `hoot::BuildingMergerCreator` - Required if `hoot::BuildingMatchCreator` is
  specified in `match.creators`.
* `hoot::HighwaySnapMergerCreator` - Required if `hoot::HighwayMatchCreator`
  is specified in `match.creators`.
* `hoot::NetworkMergerCreator` - Required if `hoot::NetworkMatchCreator`
is specified in `match.creators`.
* `hoot::PoiPolygonMergerCreator` - Required if `hoot::PoiPolygonMatchCreator`
  is specified in `match.creators`.
* `hoot::ScriptMergerCreator` - Required if one or more instances of
  `hoot::ScriptMatchCreator` is specified in `match.creators`. Note that the
  script name is not specified in this parameter.

=== network.conflicts.aggression

* Data Type: double
* Default Value: `8.8`

A larger value will conflate more aggressively (fewer reviews) when using network conflation. Users
may want to consider changing this value. Reasonable range is [1, ~10].

=== network.conflicts.outbound.weighting

* Data Type: double
* Default Value: `0.25`

A value of 0 will cause an edge to contribute (1 * score * weight) to each neighbor when using
network conflation. A value of 1 will give approx (1 / n * score * weight) influence to each
neighbor.  This value is generally not changed by users.  Reasonable range is [0, 2].

=== network.conflicts.partial.handicap

* Data Type: double
* Default Value: `0.2`

A larger value will increase the weight of partial matches when using network conflation.  A
smaller value prefers whole matches over partial matches. This value is generally not changed by
users. Reasonable range is (0, ~2].

=== network.conflicts.stub.handicap

* Data Type: double
* Default Value: `1.7`

A larger value will increase the weight of stubs when using network conflation. This value is
generally not changed by users. Reasonable range is (0, ~2].

=== network.conflicts.stub.through.weighting

* Data Type: double
* Default Value: `0.5`

A value of 0 will cause edges that are connected by a stub to contribute directly as neighbors when
using network conflation.  Higher values will reduce that contribution.  This value is generally
not changed by users.  Reasonable range is [0, ~10].

=== network.conflicts.weight.influence

* Data Type: double
* Default Value: `0.0`

A value of 0 will cause all edges to have the same weight with each neighbor, a higher value will
give matches with more support a higher weight when using network conflation. This value is
generally not changed by users. Reasonable range is [0, 2].

=== network.match.threshold

* Data Type: double
* Default Value: `0.15`

The threshold at which a network match is called a match when using network conflation.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== network.match.write.debug.maps

* Data Type: bool
* Default Value: `false`

If true debug maps will be generated at every iteration when using network conflation. This is
useful when debugging. The maps can be large and slow things down significantly.

=== network.matcher

* Data Type: string
* Default Value: `hoot::ConflictsNetworkMatcher`

An internal option for manipulating the way network matching occurs. This should only be used for
debug and test. The parameter must be a class that is registered with the factory and subclasses
`NetworkMatcher`.

=== network.max.stub.length

* Data Type: double
* Default Value: `20.0`

The maximum allowable length of a stub connection (way to node match) when using network conflation.
Value in meters.

=== network.miss.threshold

* Data Type: double
* Default Value: `0.85`

The threshold at which a network miss is called a miss.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== network.optimization.iterations

* Data Type: int
* Default Value: `10`

The number of optimization iterations the network match creator will run when performing network
conflation.

=== network.review.threshold

* Data Type: double
* Default Value: `0.5`

The threshold at which a network review is called a review. Reviews are also declared in some
other situations when the relationship is not clear.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== node.comparison.circular.error.sensitivity

* Data Type: int
* Default Value: `6`

The number of decimal places taken into account when comparing node circular error values.  Used by
node hash calculation.

=== node.comparison.coordinate.sensitivity

* Data Type: int
* Default Value: `7`

The number of decimal places taken into account when comparing node coordinates.  Used by node
hash calculation.

=== node.matcher.strictness

* Data Type: double
* Default Value: `2`

Determines how strictly the angle should be considered when calculating intersection tie points for
rubber sheeting. A value of 0 will ignore angle entirely. Large will make the angle comparison more
strict.

=== ogr.append.data

* Data Type: bool
* Default Value: `false`

If the OGR output file/layer exists when exporting, append the data instead of trying to create a
new file/layer.

=== ogr.debug.addfcode

* Data Type: bool
* Default Value: `false`

Debugging: Add the FCODE as the OSM source:fcode tag during translation.

=== ogr.debug.dumptags

* Data Type: bool
* Default Value: `false`

Debugging: Print out Attributes and OSM Tag values during translation. For each feature, this will
show what keys and values go into the translation and what the translated output is.

=== ogr.debug.dumpvalidate

* Data Type: bool
* Default Value: `false`

Debugging: Print out which attributes are dropped during export validation.

=== ogr.debug.lookupclash

* Data Type: bool
* Default Value: `false`

Debugging: When building internal lookup tables, print values that clash.

=== ogr.debug.lookupcolumn

* Data Type: bool
* Default Value: `false`

Debugging: Print the columns that are not matched during one2one translation. This will show all
Attribute columns and values that do not match a one2one rule.

=== ogr.esri.fcsubtype

* Data Type: bool
* Default Value: `true`

Add the ESRI specific FCSUBTYPE field to the output.

=== ogr.esri.fdname

* Data Type: string
* Default Value: `TDS`

The name to use for the ESRI Feature Dataset on export. Note: This only applies to ESRI File
Geodatabases.

=== ogr.import.filter

* Data Type: string
* Default Value: ``

The regexp to be used to filter the layer names when importing layers from an ESRI File
Geodatabase. The default is to import all layers from a FGDB.  Setting this variable will
override the filter value that can be set by the layerNameFilter function inside a translation
script.

=== ogr.note.extra

* Data Type: string
* Default Value: `attribute`

When exporting to TDSv40 and TDSv61:
- "attribute" Add unused tags to the "ZI006_MEM" field.
- "file" Save the unused tags in a new layer (extra_[PLA]).
- "none" Don't save the unused tags, just drop them.

When exporting to MGCP:
- "attribute" Add unused tags to the "TXT" field.
- "file" Save the unused tags in a new layer (extra_[PLA]).
- "none" Don't save the unused tags, just drop them.

NOTE: According to the MGCP and Shapefile specifications, the "TXT" field has a maximum length of
255 characters. Extra text will be truncated.

=== ogr.reader.bounding.box

* Data Type: string
* Default Value: ``

If specified the OGR reader will limit data read from the data source to only features that
intersect the given bounding box. The format is "minx,miny,maxx,maxy" specified in the projection
of the input data source.

The method OGRLayer::SetSpatialFilterRect is used to limit the bounding box. Some formats will
intelligently use indexes, others will simply filter features after reading from the data source.

Example Usage:

----
hoot convert-ogr2osm -D ogr.reader.bounding.box=106.851,-6.160,107.052,-5.913 translations/Identity.js output.osm test-files/jakarta_raya_coastline.shp
----

=== ogr.reader.bounding.box.latlng

* Data Type: string
* Default Value: ``

Similar to `ogr.reader.bounding.box` but uses WGS84 to specify the bounds rather than the source
projection. Only one of the two options can be specified.

A best effort will be made to convert between the two projections. The translated bounding box
will approximate the minimum bounding rectangle of the lat/lng bounding box. In some cases this
may be significantly larger.

=== ogr.reader.epsg.override

* Data Type: int
* Default Value: `-1`

If specified the OGR reader will override the reported projection with the specified EPSG code. If
the value is < 0 then the projection reported by the source data set will be used. In most cases
the default value is fine.

This can sometimes be necessary when reading from a DB created with osm2pgsql. E.g.

----
hoot convert -D ogr.reader.epsg.override=900913 PG:"dbname='gis' host='localhost' port='5432' user='hoot' password='blahblah'" tmp/output.shp
----

=== ogr.reader.node.id.field.name

* Data Type: string
* Default Value: ``

If set, the ogr reader will use the value at the specified field to populate node IDs.

=== ogr.split.o2s

* Data Type: bool
* Default Value: `false`

If the list of o2s tags is > 255 char, split it into into 254 char long pieces. If this is false,
it will be exported as one big string.

=== ogr.strict.checking

* Data Type: string
* Default Value: `on`

Turn OGR related errors into warnings or turn them off. Valid values are: on, off, warn

=== ogr.tds.add.etds

* Data Type: bool
* Default Value: `true`

Add the eLTDS specific attributes (SCAMIN, SCAMAX, LINK_ID) to the output.

=== ogr.tds.extra

* Data Type: string
* Default Value: `note`

When exporting to TDSv40 and TDSv61:
- "note" Add unused tags to the "ZI006_MEM" field.
- "file" Save the unused tags in a new layer (extra_[PLA]).
- "none" Don't save the unused tags, just drop them.

NOTE: If exporting to Shapefile, this field will be truncated to 255 characters.

=== ogr.thematic.structure

* Data Type: bool
* Default Value: `true`

Where applicable, export data in Thematic Groups (TransportationGroundCrv, StructurePnt etc) instead of one
FCODE per file/layer (ROAD_L, BUILDING_P etc).

=== ogr.throw.error

* Data Type: bool
* Default Value: `false`

For the schema switcher, throw errors instead of returning a partial translation/o2s_X feature
from a translation.

=== ogr.writer.create.all.layers

* Data Type: bool
* Default Value: `false`

Create all layers when using the OGR writer whether or not the layers contain features. Setting
this to true can be useful when conforming to strict specifications.

=== ogr.writer.pre.layer.name

* Data Type: string
* Default Value: ``

TODO: description

=== ogr.writer.script

* Data Type: string
* Default Value: ``

Set the script to use with OGR writer. For example:

----
hoot convert \
  -D ogr.writer.script=test-files/io/SampleTranslation.js \
  -D ogr.writer.pre.layer.name=bar \
  test-files/io/SampleTranslation.osm \
  PG:"dbname='osm_gis2' host='localhost' port='5432' user='hoot' password='hoottest'"
----

=== ogr2osm.ops

* Data Type: list
* Default Value:
** `hoot::MergeNearbyNodes` - Merges nodes within the distance defined by merge.nearby.nodes.distance.
** `hoot::BuildingPartMergeOp` - Implicitly merges certain individual building parts into a single part.

Operations that should be applied to ingested OGR data before saving the data.

=== osmapidb.bulk.inserter.disable.database.constraints.during.write

* Data Type: bool
* Default Value: `false`

If true, the OSM API database writer drops the database constraints before writing the data and
re-enables them after the writing is complete.  This can only be used with databases that have been
taken offline from other users.

=== osmapidb.bulk.inserter.disable.database.indexes.during.write

* Data Type: bool
* Default Value: `false`

If true, the OSM API database writer drops the database indexes before writing the data and
re-enables them after the writing is complete.  This can only be used with databases that have been
taken offline from other users.

=== osmapidb.bulk.inserter.reserve.record.ids.before.writing.data

* Data Type: bool
* Default Value: `false`

If true, the OSM API database writer will update the database to reserve the range of record IDs
parsed from the input data *before* writing the data to output.  IMPORTANT:  This option should
always be enabled in online environments (other writers present).  If it is not enabled in online
environments, the risk of record ID conflicts will be present in the database.  The output
destination must be an OSM API database or this setting will always be treated as being "false".
If the output destination is a SQL file, the SQL statements to update the record IDs will be
written to the SQL output for later execution.

=== osmapidb.bulk.inserter.write.sql.file.id.sequence.updates

* Data Type: bool
* Default Value: `true`

If true, the OSM API database bulk inserter write element ID sequence update SQL statements when
the output is a SQL file.  If false, the ID update statements will not be written.

=== osmapidb.id.aware.url

* Data Type: string
* Default Value: ``

This is required when using either the OsmApiDbAwareHootApiDbReader or the OsmApiDbAwareHootApiDbWriter
It forces database reading/writing use the specified OSM API database as master for determining the
sequencing of element ID's.

=== osm.map.reader.factory.reader

* Data Type: string
* Default Value: ``

Specifies the reader that the OsmMapReaderFactory will use. This overrides any information derived
from the URL.

=== osm.map.writer.factory.writer

* Data Type: string
* Default Value: ``

Specifies the writer that the OsmMapWriterFactory will use. This overrides any information derived
from the URL.

=== osm.map.writer.format.xml

* Data Type: bool
* Default Value: `true`

Turns on autoformatting (line breaks, indentation etc) for XML output.

=== osm.map.writer.schema

* Data Type: string
* Default Value: ``

Sets the value for a "schema" attribute when writeing a map to OSM XML.  NOTE: this will only be
written if the value is not empty.

=== osm.map.writer.skip.empty.map

* Data Type: bool
* Default Value: `false`

If true, the OSM map writer will NOT write a file if the map is empty.
The default is to write a file even if the map is empty.

=== osm2ogr.ops

* Data Type: list
* Default Value:
** ``

User specified operations for converting OSM files to OGR compatible file types.

=== perty.apply.rubber.sheet

* Data Type: bool
* Default Value: `true`

If true, the data is rubbersheeted before conflation, moving perturbed data closer to reference data.

=== perty.csm.D

* Data Type: double
* Default Value: `1000`

The PERTY D value. D is used in e ^ (-perty.grid.spacing / D). Defaults to 1000. Larger values
result in a more correlated permutation grid.

=== perty.duplicate.poi.duplicate.sigma

* Data Type: double
* Default Value: `1.0`

The number of duplicate POIs is set as `round(abs(N(0, sigma^2))) + 1`. Setting sigma to 0 will
guarantee that there will always be exactly one duplicate.

=== perty.duplicate.poi.move.multiplier

* Data Type: double
* Default Value: `1.0`

The distance that a feature is moved is based on the circular error of the source point. The
new point will be put within N(0, sigma^2) * moveMultiplier meters of the source point where
sigma is the standard deviation associated with the source point.

=== perty.duplicate.poi.probability

* Data Type: double
* Default Value: `0.10`

The probability of at least one duplicate being created. See setDuplicateSigma to determine
how many duplicates will be created.

=== perty.grid.spacing

* Data Type: double
* Default Value: `100`

The size of the PERTY grid spacing in meters.

=== perty.name.change.probability

* Data Type: double
* Default Value: `0.05`

The probability of a change to each character in the name. The expected number of changes is
`perty.name.change.probability` * str.size().

=== perty.name.probability

* Data Type: double
* Default Value: `0.05`

The probability that a name will be modified.

=== perty.ops

* Data Type: list
* Default Value:
** `hoot::PertyWaySplitVisitor` - Randomly splits ways.
** `hoot::PertyWayGeneralizeVisitor` - Randomly generalizes ways.
** `hoot::PertyRemoveRandomElementVisitor` - Randomly removes elements.
** `hoot::PertyDuplicatePoiOp` - Randomly adds duplicated POIs.
** `hoot::PertyRemoveTagVisitor` - Randomly removes element tags.
** `hoot::PertyNameVisitor` - Randomly modifies element name tags.

A list of operations that should be applied after the geometries have been shifted by PERTY.

=== perty.random.error.x

* Data Type: double
* Default Value: `0`

The sigma rx parameter for PERTY (random error in X). This is only relevant when perty.algorithm
is set to FullCovariance.

=== perty.random.error.y

* Data Type: double
* Default Value: `0`

The sigma ry parameter for PERTY (random error in Y). This is only relevant when perty.algorithm
is set to FullCovariance.

=== perty.remove.random.probability

* Data Type: double
* Default Value: `0.05`

The probability that a feature will be removed.

=== perty.remove.tag.probability

* Data Type: double
* Default Value: `0.05`

Set the probability that a tag will be removed.

=== perty.remove.tag.visitor.exempt.tag.keys

* Data Type: list
* Default Value:
** `REF1`
** `REF2`
** `hoot:status`
** `uuid`

A list of tag keys which are exempt from the tag removal done by PertyRemoveTagsVisitor.  This is
useful for preventing the removal of tags Hootenanny relies on during conflation.

=== perty.remove.tag.visitor.substitution.keys

* Data Type: list
* Default Value:
** `highway`

A list of tag keys which, rather than being removed by the PertyRemoveTagVisitor, will have their
values replaced instead.  The tag keys in the list match one to one with the replacement values in
perty.remove.tag.visitor.subsitution.values.

=== perty.remove.tag.visitor.substitution.values

* Data Type: list
* Default Value:
** `road`

A list of tag values which, should be substituted by PertyRemoveTagVisitor.  The tag values in the
list match one to one with the replacement values in perty.remove.tag.visitor.subsitution.keys.

=== perty.search.distance

* Data Type: double
* Default Value: `15`

Distance parameter (in meters) that determines how far out to search when trying to match features
during conflation of reference and perturbed datasets.  This is equivalent in nature to the
'error:circular' tag used in Hootenanny conflation, however this setting is used instead for
PERTY scoring only.

=== perty.seed

* Data Type: int
* Default Value: `-1`

A random seed integer passed to the random number generator accessed by PERTY to give consistent
results over multiple runs. A value of -1 will generate a seed based on the time to provide
pseudo-random results in the output.  Other seed values will yield repeatable results when the
same seed is used in consecutive calls to the PERTY related commands.

=== perty.systematic.error.x

* Data Type: double
* Default Value: `50`

The sigma sx parameter for PERTY. This controls how much correlated error in the
X direction is in the output permutation. Units in meters.

=== perty.systematic.error.y

* Data Type: double
* Default Value: `50`

The sigma sy parameter for PERTY. This controls how much correlated error in the
Y direction is in the output permutation. Units in meters.

=== perty.test.allowed.score.variance

* Data Type: double
* Default Value: `0.025`

A score variance in the range of 0.0 to 1.0 by which a `perty-test` test run score may vary
while still allowing the test run's status to be described as passing.  Test run score differences
larger than this value will cause the test run's status to be described as failing.  If you are
not sure what your expected scores should be and want to bypass this check, create a list with
all entries equal to "1.0" of the same size as perty.test.num.runs, and then
set perty.test.allowed.score.variance to "1.0".  This effectively disables the score validation.

=== perty.test.dynamic.variable.increment

* Data Type: double
* Default Value: `0.1`

Amount by which the dynamic input variables specified in perty.test.dynamic.variables are
incremented during each test run by perty-test.

=== perty.test.dynamic.variable.start.value

* Data Type: double
* Default Value: `0`

Dynamic variable value initially assigned to a PERTY test dynamic variable when executed by
`perty-test`.

=== perty.test.dynamic.variables

* Data Type: list
* Default Value:
** ``

A list of one or more numeric PERTY variables to be assigned a start value (specified in
perty.test.dynamic.variable.start.value) and then incremented once per test run by
`perty-test` (specified in perty.test.dynamic.variable.increment) to the value of.  The list is
restricted to Hootenanny PERTY options only (perty.*) of a numeric type.

=== perty.test.expected.scores

* Data Type: list
* Default Value:
** `1.0`

A list of expected PERTY scores in the range of 0.0 to 1.0 for a `perty-test` run.  The number of
scores must match the value assigned to perty.test.num.runs.  If you are not sure what your
expected scores should be and want to bypass this check, create a list with all entries equal
to "1.0" of the same size as perty.test.num.runs, and then set perty.test.allowed.score.variance
to "1.0".  This effectively disables the score validation.

=== perty.test.fail.on.better.score

* Data Type: bool
* Default Value: `false`

If true, the `perty-test` will mark a test as failing if its test run score is higher than the
expected score and outside of the allowable score variance; if false, will always allow higher
test run scores to result in a passing test run, despite being outside of the allowable score
variance.

=== perty.test.generate.map.stats

* Data Type: bool
* Default Value: `false`

If true, Hootenanny map statistics files are output for all PERTY outputs created by `perty-test`.

=== perty.test.num.runs

* Data Type: int
* Default Value: `1`

The number of test runs executed by `perty-test`.  A single input variable, or multiple variables
(specified in perty.test.dynamic.variable) assigned identical starting values (specified in
perty.test.dynamic.variable.start.value), is/are altered by an increment during each test
(specified in perty.test.dynamic.variable.increment).

=== perty.test.num.simulations

* Data Type: int
* Default Value: `3`

The number of simulations per test run executed by `perty-test`.  A test run is made up of
multiple simulations.  Scores all simulation executed by the test run are averaged to give the
final PERTY score for the test run.

=== perty.way.generalize.epsilon

* Data Type: double
* Default Value: `1`

Distance parameter, in meters, that determines to what degree a way is generalized by PERTY.
Higher values result in more generalization (more nodes removed).

=== perty.way.generalize.probability

* Data Type: double
* Default Value: `0.1`

The probability between 0.0 and 1.0 that a way will be generalized by PERTY.

=== perty.way.split.min.node.spacing

* Data Type: double
* Default Value: `1`

The minimum spacing, in meters, that may occur between nodes created by PERTY way splits.

=== perty.way.split.probability

* Data Type: double
* Default Value: `0.1`

The probability between 0.0 and 1.0 that a way will be split into multiple features by PERTY.

=== plugin.context.includes

* Data Type: list
* Default Value:
** `HootLib.js`

A list of scripts to include before loading the user's plugin script. The path will be search as:
current directory (CWD), $CWD/rules, $HOOT_HOME/rules.

=== poi.ignore.type.if.name.present

* Data Type: bool
* Default Value: `false`

If true, POI to POI conflation will ignore the types of the features being compared completely as
long as those being compared have a populated name field.

=== poi.match.threshold

* Data Type: double
* Default Value: `${conflate.match.threshold.default}`

The threshold at which a match is called a match for POIs.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== poi.miss.threshold

* Data Type: double
* Default Value: `${conflate.miss.threshold.default}`

The threshold at which a miss is called a miss for POIs.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== poi.polygon.disable.same.source.conflation

* Data Type: bool
* Default Value: `false`

If true, POI to polygon conflation will not attempt to conflate two features with the same source
tag value.  e.g. both have 'source=osm' tag  The source tag key is specified by
poi.polygon.source.tag.key.  How strictly the source tag key must be matched is controlled by
poi.polygon.disable.same.source.conflation.match.tag.key.prefix.only.  This setting is useful when
you have a data layer where data has been collected as both POIs and polygons for the same source
and you never want the two source to be conflated together.

=== poi.polygon.disable.same.source.conflation.match.tag.key.prefix.only

* Data Type: bool
* Default Value: `true`

If set to false and poi.polygon.disable.same.source.conflation is set to true, POI to polygon
conflation will disable conflation only between features who have the exact same source tag value.
e.g. both have 'source=osm' tag  If set to true and poi.polygon.disable.same.source.conflation is
set to true, then the tag matcher is less strict and will attempt to match the prefix of the source
tag value when delimited by a colon.  e.g. 'source=mgcp:buildp_clip;osm' will match
'source=mgcp:builda_clip;osm' since both tag values begin with 'mgcp:'.

=== poi.polygon.enable.advanced.matching

* Data Type: bool
* Default Value: `false`

If true, POI to polygon conflation will perform additional checks against surrounding features
for match evidence.  This setting allows for detailed conflation customization but can be runtime
expensive when enabled.

=== poi.polygon.enable.review.reduction

* Data Type: bool
* Default Value: `true`

If true, POI to polygon conflation will attempt to reduce unnecessary reviews without increasing
incorrect matches.  This setting is somewhat experimental and can be runtime expensive when
enabled.

=== poi.polygon.match.distance.threshold

* Data Type: double
* Default Value: `5.0`

The maximum distance, in meters, between a POI and a polygon where they can still be considered
a match based on distance criteria only.

=== poi.polygon.match.evidence.threshold

* Data Type: int
* Default Value: `3`

The minimum evidence score at which a POI will be matched to a polygon.  Valid values are 1 to 4.
If an evidence score for a feature pair falls below this value, the relationship between the
features will be classified as a review or miss, depending on the value of
'poi.polygon.review.evidence.threshold'.  Generally, this setting should not be changed except
when working with specific POI/Polygon conflation use cases that require it.

=== poi.polygon.match.threshold

* Data Type: double
* Default Value: `${conflate.match.threshold.default}`

The threshold at which a match is called a match when comparing POIs to polygons.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== poi.polygon.miss.threshold

* Data Type: double
* Default Value: `${conflate.miss.threshold.default}`

The threshold at which a miss is called a miss when comparing POIs to polygons.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== poi.polygon.name.score.threshold

* Data Type: double
* Default Value: `0.8`

The minimum similarity the name scores of two features can have and be considered a name
match, with 0.0 being the least similar and 1.0 being the most similar (-1.0 if there are no names
present (null).

=== poi.polygon.print.match.distance.truth

* Data Type: bool
* Default Value: `false`

If true, debug match distance output will be obtained from manually matched source data and printed
if running 'hoot score-matches' with POI to polygon conflation.

=== poi.polygon.promote.points.with.addresses.to.pois

* Data Type: bool
* Default Value: `false`

If true, POI to polygon conflation will classify all points with OSM address tags as POIs even if
they do not have specific type tags.

=== poi.polygon.review.distance.threshold

* Data Type: double
* Default Value: `125.0`

The maximum distance, in meters, between a POI and a polygon where they can still be considered
for review based on distance criteria only (value is added to the circular error of the compared
features).

=== poi.polygon.review.evidence.threshold

* Data Type: int
* Default Value: `1`

The minimum evidence score at which a POI will be reviewed against a polygon, if the evidence score
does not meet the threshold defined by 'poi.polygon.match.evidence.threshold'.  Valid values are
0 to 3.  If an evidence score for a feature pair falls below this value, the relationship between
the features will be classified as a miss.  If the value is set to 0, all feature pairs which did
not match will be reviewed.  If the value is set greater than or equal to
'poi.polygon.match.evidence.threshold', an error will occur.  Generally, this setting
should not be changed except when working with specific POI/Polygon conflation use cases that
require it.

=== poi.polygon.review.if.matched.types

* Data Type: list
* Default Value:
** ``

List of key value pairs in the format 'key=value' or  'key,value' (UI only) for features to always
review if marked as matches with POI to polygon conflation.  Delimit the individual types with ';'.
e.g. 'amenity=school;shop=mall' or 'amenity,school;shop,mall'  Also, when specifying the list from
the command line, surround the entire value string in double quotes.

=== poi.polygon.review.multiuse.buildings

* Data Type: bool
* Default Value: `false`

If true, POI to polygon conflation always marks matches between POIs and polygons where multi-use
building polygons are present as needing review.  The definition of multi-use buildings is
controlled by the Hootenanny schema.

=== poi.polygon.review.threshold

* Data Type: double
* Default Value: `${conflate.review.threshold.default}`

The threshold at which a review is called a review for PoiPolygon. See
`conflate.review.threshold.default`.

=== poi.polygon.source.tag.key

* Data Type: string
* Default Value: `source`

The source tag key to be used in conjunction with poi.polygon.disable.same.source.conflation.

=== poi.polygon.type.score.threshold

* Data Type: double
* Default Value: `0.7`

The minimum similarity the type scores a POI and polygon can have and be considered a type
match, with 0.0 being the least similar and 1.0 being the most similar.

=== poi.review.threshold

* Data Type: double
* Default Value: `${conflate.review.threshold.default}`

The threshold at which a review is called a review for POIs. See `conflate.review.threshold.default`.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== preserve.unknown1.element.id.when.modifying.features

* Data Type: bool
* Default Value: `false`

If true, the element ID of features with status=unknown1 will be preserved when modifying features
(merging, splitting, etc. during conflation, cleaning, etc.).  If false, the modified feature will
be given a new, unique element ID.  This is useful when writing conflated data output back to a
reference data store (associated with the unknown1 status) where modifying existing features is
preferred over replacing them for provenance purposes.  Not honored by all visitors, map operations,
or mergers which modify features.

=== progress.reporting.format

* Data Type: string
* Default Value: ``

Sets the progress reporting format to the type specified for classes that support progress
reporting.  Currently, 'json' is the only valid reporting format. If left blank, progress is not
reported.

=== reader.add.source.datetime

* Data Type: bool
* Default Value: `true`

By default add the `source:datetime` or `source:ingest:datetime` stamp when reading files.  Not
honored by all readers.

=== reader.conflate.use.data.source.ids.1

* Data Type: bool
* Default Value: `false`

Determines whether the reader used by the conflate command to read the first input dataset will
use the element ID's specified by the input datasets (true) or use internal ID management for the
inputs (false).

=== reader.conflate.use.data.source.ids.2

* Data Type: bool
* Default Value: `false`

Determines whether the reader used by the conflate command to read the second input dataset will
use the element ID's specified by the input datasets (true) or use internal ID management for the
inputs (false).

=== reader.keep.status.tag

* Data Type: bool
* Default Value: `false`

If reader.use.file.status is true, the default action is to drop the status tag from the file
during reading.  Setting this to true preserves the status tag on the element.  Not honored by
all readers.

=== reader.preserve.all.tags

* Data Type: bool
* Default Value: `false`

If true, all tags from the input data will be preserved.  Not honored by all readers.  e.g.
an 'accuracy' tag will not be replaced by a 'error:circular' tag; both tags will be kept.

=== reader.set.default.status

* Data Type: string
* Default Value: `unknown1`

Sets the status on data being read.  Valid values are "unknown1" and "unknown2".  Not honored by all
readers.

=== reader.use.data.source.ids

* Data Type: bool
* Default Value: `true`

If true, the element IDs in the source data will be assigned to written elements.  Otherwise,
Hootenanny manages element IDs internally.  This should not be set to true if any source elements
have negative IDs.  Not honored by all readers.

=== reader.use.file.status

* Data Type: bool
* Default Value: `false`

By default should a reader use the file status from the file. Not honored by all readers.

=== remove.attribute.visitor.types

* Data Type: list
* Default Value:
** ``

List of element attributes to remove with the RemoveAttributeVisitor.  See ElementAttributeType for
valid values.

=== remove.duplicate.areas.diff

* Data Type: string
* Default Value: `hoot::ExactTagDifferencer`

Use this class for calculating the difference between element tags. If the difference is exactly
0 then they'll be a candidate for merging.

=== remove.elements.visitor.filter

* Data Type: string
* Default Value: ``

The plugin name of a filter used to select the elements to delete.

=== remove.elements.visitor.recursive

* Data Type: bool
* Default Value: `true`

Should the element remover remove the elements recursively?

=== remove.tag.visitor.keys

* Data Type: list
* Default Value:
** ``

A list of tag keys the RemoveTagVisitor will remove on elements.

=== rubber.sheet.debug

* Data Type: bool
* Default Value: `false`

If set to true, then debug symbols will be added to nodes and additional tags will be added to
matched nodes. This is a destructive operation that is only useful when debugging and should not
be used during serious conflation.

=== rubber.sheet.fail.when.minimum.tie.points.not.found

* Data Type: bool
* Default Value: `false`

If set to true, rubber sheeting will return an error if less than rubber.sheet.minimum.ties tie
points are found.  Otherwise, a warning will be logged and rubber sheeting will be skipped.

=== rubber.sheet.log.missing.requirements.as.warning

* Data Type: bool
* Default Value: `true`

If set to true, rubber sheeting will log a warning if any requirement for rubber sheeting is not
met.  e.g less than rubber.sheet.minimum.ties tie points are found.  Otherwise, an info level log
statement will be logged instead.  This setting is completely ignored if
rubber.sheet.fail.when.minimum.tie.points.not.found is set to true.

=== rubber.sheet.minimum.ties

* Data Type: int
* Default Value: `4`

Sets the minimum number of tie points that will be used when calculating a rubbersheeting solution.

=== rubber.sheet.ref

* Data Type: bool
* Default Value: `true`

If this configuration setting is set to true, then the first layer is treated as the reference
layer and will not be moved. If set to false the two layers will be moved towards each other. The
weighting is determined based on the circular error.

=== score.graph.debug.images

* Data Type: bool
* Default Value: `false`

Export some of the images used when evaluating the graph connections between two maps (`score`
command).

=== score.matches.remove.nodes

* Data Type: bool
* Default Value: `false`

Remove REF tags from nodes before match scoring when using the score-matches command.

=== script.test.max.exec.time

* Data Type: int
* Default Value: `-1`

For script test debugging only.  Sets a maximum allowed time, in seconds, for a script test to run.
If the script runs longer than the specified time, then it is forcefully stopped by the system.  If
the value is set to -1, then there is no time limit for script tests.  This is useful when
debugging tests which may hang on a remote build server.

=== search.radius.default

* Data Type: double
* Default Value: `-1.0`

The default search radius to use when conflating features. If two features are within the search
radius then they will be considered for conflation.  If the value is -1 then the circular error will
be used to calculate an appropriate search radius.  Not all feature matching routines will honor
the default value.

=== search.radius.generic.line

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius to use when conflating generic lines.  See `search.radius.default`.

=== search.radius.generic.polygon

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius to use when conflating generic polygons.  See `search.radius.default`.

=== search.radius.highway

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius to use when conflating highways.  See `search.radius.default`.

=== search.radius.waterway

* Data Type: double
* Default Value: `${search.radius.default}`

The search radius to use when conflating waterways.  Not used if
waterway.auto.calc.search.radius = true.  See `search.radius.default`.

=== set.tag.visitor.append.to.existing.value

* Data Type: bool
* Default Value: `false`

If true, any element with a value populated for the key defined by the set.tag.visitor.key option
will have the value specified in the set.tag.visitor.value option appended to it.

=== set.tag.visitor.element.type

* Data Type: string
* Default Value: ``

An optional element type filter for the SetTagVisitor.  Valid values are: 'node', 'way', or
'relation'.  If left empty, all elements will receive tag additions.

=== set.tag.visitor.key

* Data Type: list
* Default Value: ``

Set the key member in the SetTagVisitor class.  SetTagVisitor allows for adding/modifying a
particular tag on all elements in a map. The number of keys in `set.tag.visitor.key` should match
the number of keys in `set.tag.visitor.value`.

=== set.tag.visitor.overwrite

* Data Type: bool
* Default Value: `true`

If true, the SetTagVisitor class will overwrite any existing tag it finds with
key=set.tag.visitor.key, otherwise it will skip updating the tag.

=== set.tag.visitor.value

* Data Type: list
* Default Value: ``

Set the value member in the SetTagVisitor class.  SetTagVisitor allows for adding/modifying a
particular tag on all elements in a map.

=== small.way.merger.diff

* Data Type: string
* Default Value: `hoot::ExactTagDifferencer`

Use this class for calculating the difference between element tags. If the difference is exactly 0
then they'll be a candidate for merging.

=== small.way.merger.threshold

* Data Type: double
* Default Value: `15`

If highways are smaller than threshold and the tags matched, then they will be merged together into
a single way.

=== spark.changeset.writer.element.payload.format

* Data Type: string
* Default Value: `json`

The format used to write the element payload portion of the Spark changeset file.  Valid options are
'json' or 'xml'.

=== stats.format

* Data Type: string
* Default Value: `pdf`

Format type for the statistics generated from conflate.  Can be 'pdf', 'html' or 'asciidoc'.

=== stats.output

* Data Type: string
* Default Value: ``

Path to the output document for the statistics.  If left empty, it will not output to a file, only
to screen.

=== stats.script

* Data Type: string
* Default Value: `${HOOT_HOME}/report/csr-default.js`

Path to the statistics generator rules in javascript format.

=== stats.translate.script

* Data Type: string
* Default Value: `${HOOT_HOME}/translations/TDSv61.js`

Path to the translation script to use when translating tags for stats. If the path is empty, then
all translation stats are disabled.

=== status.criterion.status

* Data Type: string
* Default Value: `Invalid`

The default status to match with a status criterion.  Used by various element visitors and map
operations.

=== status.update.visitor.only.update.invalid.status

* Data Type: bool
* Default Value: `false`

If true, the SetTagVisitor class will only update statuses on elements when the existing status is
'Invalid'.

=== status.update.visitor.status

* Data Type: string
* Default Value: ``

Adds the specified status to elements.  Valid values are: 'Unknown1', 'Unknown2', 'Conflated', or
'Invalid'.  If left empty, all elements will receive tag additions.

=== tag.ancestor.differencer.name

* Data Type: string
* Default Value: ``

The default ancestor to use when using the hoot::TagAncestorDifferencer class for comparing tags.
Primarily, this is useful within the node.js interface.

=== tag.category.differencer.name

* Data Type: string
* Default Value: ``

The default category to use when using the hoot::TagCategoryDifferencer class for comparing tags.
Primarily, this is useful within the node.js interface.

=== tag.criterion.kvp

* Data Type: string
* Default Value: ``

The key/value pair to use in the tag criterion by default. E.g. 'highway,road'  Used by various
element visitors and map operations.

=== tag.merger.default

* Data Type: string
* Default Value: `hoot::OverwriteTag2Merger`

Specifies the default way of merging tags. This is used by most merge routines, but may be overriden
depending on the specifics of the merger.

Possible options include:

* <<Average-Tags,`hoot::AverageTagMerger`>> - Attempts to take the average of the two tag sets.
* <<Generalize-Tag-Merger,`hoot::GeneralizeTagMerger`>> - Attempt to take the most general
  interpretation of the tags.
* `hoot::OverwriteTagMerger` - Aliased to `hoot::OverwriteTag2Merger`
* <<Overwrite-Tag-1,`hoot::OverwriteTag1Merger`>> - Overwrite the tags in the first input.
* <<Overwrite-Tag-2,`hoot::OverwriteTag2Merger`>> - Overwrite the tags in the second input.
* <<Provenance-Aware-Overwrite-Tag-Merger,`hoot::ProvenanceAwareOverwriteTagMerger`>> - Overwrite
the tags in the first input except the provenance tag, hoot:source, which will be merged using
values from both features.

=== tag.printing.format

* Data Type: string
* Default Value: `asciidoc`

Output format to use when printing OSM+ Tag documentation. Valid formats are: 'csv', 'html',
'redmine' & 'asciidoc' (default)

=== tag.printing.script

* Data Type: string
* Default Value: `${HOOT_HOME}/translations/PrintOsmDocs.js`

The translation script to use when printing OSM+ Tag documentation.

=== tag.rename.visitor.new.key

* Data Type: string
* Default Value: ``

The key to used to replace an existing by the TagRenameKeyVisitor.  TagRenameKeyVisitor allows for
renaming existing tag keys on all elements in a map.

=== tag.rename.visitor.old.key

* Data Type: string
* Default Value: ``

The key to be replaced by the TagRenameKeyVisitor.  TagRenameKeyVisitor allows for
renaming existing tag keys on all elements in a map.

=== task.status.update.interval

* Data Type: long
* Default Value: `10000`

For commands supporting it, the iteration count at which a status message should be logged. This
setting may have a negative impact on performance if set to a very low value.

=== test.case.cmd

* Data Type: string
* Default Value: `hoot::ConflateCmd`

Set the conflate command that should be used in a test case. This is only useful when writing
test cases (`test-files/cases/`) and was originally added to support the MultiaryConflateCmd.

=== test.force.orthographic.projection

* Data Type: bool
* Default Value: `false`

Always force the orthographic projection when determining a proper planar projection. In typical
usage this will never be used (the automatically selected projection should always be at least as
good). This is most useful if you want to get consistent results even if the list of potential
projections change over time. Very handy in unit tests.

=== token.keep.non.words

* Data Type: bool
* Default Value: `false`

This does a rudimentary check to see if the string contains any letters/numbers. If the string
doesn't contain any letters or numbers then it will be dropped. Examples that would be dropped
if the value is `true` include:

* `&`
* `--`

Examples that will be kept if the value is `true` include:

* `1&2`
* `Joe's`

=== token.min.size

* Data Type: double
* Default Value: `3`

This is the minimum string size that the string tokenizer should accept as a token. If the string
length is less than this value, then it will not be accepted. Set the value to 0 if you want to
accept all strings.

This setting primarily applies to string comparison functions and will eliminate comparing very
short strings such as "of" or "&".

=== token.separator

* Data Type: string
* Default Value: `\s+`

The token separator defined as a regular expression. This is used in some methods for tokenizing
names. The default value matches multiple whitespace characters.

Another useful option is `[\s-,';]+`. This will split on white space, or several forms of
options.

=== translate.string.distance.tokenize

* Data Type: bool
* Default Value: `true`

Set to true if the strings should be tokenized (split into words) before translating the values.

=== translated.tag.differencer.ignore.list

* Data Type: string
* Default Value: ``

Semi-colon delimited list of tags that should be ignored when comparing a list of tags using the
hoot::TranslatedTagDifferencer.

See also:
* `translated.tag.differencer.script`

=== translated.tag.differencer.script

* Data Type: string
* Default Value: ``

Path to the translation script when using the hoot::TranslatedTagDifferencer. The
hoot::TranslatedTagDifferencer is most useful when deciding how difference between two sets of
tags should be calculated.

This differencer can be used with:

* `small.way.merger.diff`
* `remove.duplicate.areas.diff`

=== translation.direction

* Data Type: string
* Default Value: `toosm`

The direction that the translation script should translate. `toogr` will translate from OSM to OGR.
`toosm` will translate from OSM to OGR. This is useful with the hoot::TranslationOp.

=== translation.override

* Data Type: string
* Default Value: ``

Override the value of translated tags and attributes.

VERY IMPORTANT NOTE: The changes apply to ALL elements and are applied to the OSM+ tags either before or
after the translation. E.g.
* After attributes are translated to OSM+ tags during Import
* Before OSM+ tags are translated to attributes on Export

NOTE: This assumes that you know exactly what tags you want to modify/delete

=== translation.script

* Data Type: string
* Default Value: ``

The script to use for translation.

=== unify.enable.optimal.constrained.matches

* Data Type: bool
* Default Value: `true`

Enable the calculation of Optimal Constrained Matches during conflation. When enabled, Hootenanny
will use either Optimal Constrained Matches (via GLPK) or Greedy Constrained Matches. If disabled,
Hootenanny will only use Greedy Constrained Matches.

=== unify.optimizer.time.limit

* Data Type: double
* Default Value: `60`

The maximum amount of time in seconds to wait for the optimizer to complete. A value of -1 makes
the wait time limit unlimited.

If this value is set to something other than -1 your conflation results may change between multiple
runs. Especially if the machine Hoot is running on is under heavy load. If the "CM Score:" value
is changing between runs and GLPK isn't finding an optimal solution then this is likely causing
different output.  Just because the output is changing doesn't mean it is wrong, but this can be
problematic if you're doing testing or expecting repeatable output for other.

=== unify.post.ops

* Data Type: list
* Default Value:
** `hoot::SuperfluousNodeRemover` - Removes all the nodes from a map that aren't part of a way.
** `hoot::SmallWayMerger` - Merges small ways using the threshold determined by the small.way.merger.threshold setting along with other criteria.

List of operations to apply immediately after conflation when using Unifying Conflation only.  Runs
before the operations in `conflate.post.ops`.

=== unify.pre.ops

* Data Type: list
* Default Value:
** ``


List of operations to apply immediately before conflating when using Unifying Conflation only.  Runs
after the operations in `conflate.pre.ops`.

=== uuid.helper.repeatable

* Data Type: bool
* Default Value: `false`

Creates a repeatable UUID for the features. This is useful for debugging, but shouldn't be used in
normal operation.

=== waterway.angle.sample.distance

* Data Type: double
* Default Value: `20.0`

Distance, in meters, used for sampling river data during angle histogram extraction with the
SampledAngleHistogramExtractor

=== waterway.auto.calc.search.radius

* Data Type: bool
* Default Value: `true`

Automatically calculates the search radius to be used during conflation of waterways using rubber
sheet tie point distances.  When this setting is enabled, rubbersheeting is not allowed as a
pre-conflation operation on the input data to be conflated.

=== waterway.match.threshold

* Data Type: double
* Default Value: `${conflate.match.threshold.default}`

The threshold at which a match is called a match for waterways.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== waterway.matcher.heading.delta

* Data Type: double
* Default Value: `150.0`

The distance around a point on a waterway to look when calculating the heading. See
`way.matcher.heading.delta`.

=== waterway.matcher.max.angle

* Data Type: double
* Default Value: `90.0`

Sets that maximum angle that is still considered a waterway match. Units in degrees.

=== waterway.miss.threshold

* Data Type: double
* Default Value: `${conflate.miss.threshold.default}`

The threshold at which a miss is called a miss for waterways.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== waterway.review.threshold

* Data Type: double
* Default Value: `${conflate.review.threshold.default}`

The threshold at which a review is called a review for waterways.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== waterway.rubber.sheet.minimum.ties

* Data Type: int
* Default Value: `5`

Sets the minimum number of tie points that will be used when calculating a rubber sheeting solution
with river data.

=== waterway.rubber.sheet.ref

* Data Type: bool
* Default Value: `true`

See `rubber.sheet.ref`.  Used during waterway conflation.

=== waterway.subline.matcher

* Data Type: string
* Default Value: `hoot::MaximalSublineMatcher`

The way subline matcher to use when determining matching sublines.

=== way.angle.sample.distance

* Data Type: double
* Default Value: `10.0`

Distance, in meters, used for sampling way data during angle histogram extraction with the
SampledAngleHistogramExtractor

=== way.matcher.heading.delta

* Data Type: double
* Default Value: `5.0`

The distance around a point on a way to look when calculating the heading. A larger value will
smooth out the heading values on a line. A smaller value will make the heading values correspond
directly to the heading on the way at that point. This is primarily used in subline matching.
Values are in meters.

=== way.matcher.max.angle

* Data Type: double
* Default Value: `60`

Sets the maximum angle that is still considered a way match. Units in degrees.

=== way.max.nodes.per.way

* Data Type: int
* Default Value: `1900`

If unset, or set to zero, there will be no maximum number of nodes stored in a way. If the value is
set to a non-zero positive value, all ways which contain more nodes than this value will be broken
up into two or more separate ways, and all of them will contain this number of nodes (or less).
The original way will be removed from the map. Default set to 1900 as OSM imports through OSM API
databases are capped at 2000 nodes per way.

=== way.merger.min.split.size

* Data Type: double
* Default Value: `5`

The minimum size that a way should be split into for merging. Units in meters.

=== way.splitter.max.length

* Data Type: double
* Default Value: `5000`

This configuration option is used by hoot::WaySplitterOp. If a way is longer than this length
(in meters) then it will be split into smaller ways.

=== way.subline.matcher

* Data Type: string
* Default Value: `hoot::MaximalNearestSublineMatcher`

The way subline matcher to use when determining matching sublines.

=== way.subline.string.matcher

* Data Type: string
* Default Value: `hoot::MaximalSublineStringMatcher`

The way subline string matcher to use when determining matching sublines.

=== weighted.metric.distance.extractor.point.aggregator

* Data Type: string
* Default Value: `hoot::MeanAggregator`

Type of point aggregator used by the WeightedMetricDistanceExtractor.

=== weighted.metric.distance.extractor.search.radius

* Data Type: double
* Default Value: `-1.0`

The search radius used by the WeightedMetricDistanceExtractor.  Units in meters.  Defaults to a
value computed from the circular error for each way being examined.

=== weighted.word.distance.abridged.dictionary

* Data Type: string
* Default Value: `dictionary/WordsAbridged.sqlite`

Location of the abridged word frequency dictionary. This is not ideal and you'll get repeated
warnings if you use it, but at least you won't need to download a 400MB+ file.

=== weighted.word.distance.dictionary

* Data Type: string
* Default Value: `dictionary/words.sqlite`

Location of the word frequency dictionary. If the absolute file path isn't found, then
the local `conf` and `$HOOT_HOME/conf` directories will be searched.

This file is typically downloaded from:

=== weighted.word.distance.probability

* Data Type: double
* Default Value: `1.0`

The weight used will be `1.0 / (w ^ p)` where w is the frequency. Valid values are >= 0, but
generally it should be `1 >= p >= 0`.

=== writer.clean.review.tags

* Data Type: bool
* Default Value: `true`

If true, Hootenanny review tags are treated as metadata tags and will be removed by the
NoInformationElementRemover cleaning operation.

=== writer.include.circular.error.tags

* Data Type: bool
* Default Value: `true`

When true, writers will include circular error information. Not honored by all writers.

=== writer.include.conflate.review.detail.tags

* Data Type: bool
* Default Value: `true`

Add detailed review tags to review relations during conflation.  Turning this setting off is
generally only done in debugging environments.  This setting allows for partitioning the level of
detail in the review relation tags into two groups.  Turning this setting off can be useful during
debugging in situations where you are comparing map outputs and want to see reviews in the output
but are not concerned with a higher level of review detail.  Disabling this setting will also
disable AddHilbertReviewSortOrderOp, the output of which is depended upon by the Hootenanny user
interface.

=== writer.include.conflate.score.tags

* Data Type: bool
* Default Value: `false`

Add match/miss/review score values to elements with matches during Unifying Conflation. This is
useful for debugging.

=== writer.include.debug.tags

* Data Type: bool
* Default Value: `false`

When true, writers will include debug information (hoot:* tags; e.g. status). Not honored by all
writers.

=== writer.precision

* Data Type: int
* Default Value: `16`

Set the output precision when writing. Not honored by all writers.

=== writer.text.status

* Data Type: bool
* Default Value: `false`

Add hoot:status values as text (Reference, Merged etc) instead of numbers (1,2,3)

=== writer.xml.sort.by.id

* Data Type: bool
* Default Value: `true`

If true, OSM elements written to XML file output (.osm) are sorted by ID.  Setting this to true
will require reading the entire source dataset into memory.  Setting it to false may result in
using smaller amounts of memory during writing if the data source being written is also a streamable
format (see the "Supported Data Formats" section in README.md).

Listing all option names containing 'poi.polygon'...

poi.polygon.disable.same.source.conflation
poi.polygon.disable.same.source.conflation.match.tag.key.prefix.only
poi.polygon.enable.advanced.matching
poi.polygon.enable.review.reduction
poi.polygon.match.distance.threshold
poi.polygon.match.evidence.threshold
poi.polygon.match.threshold
poi.polygon.miss.threshold
poi.polygon.name.score.threshold
poi.polygon.print.match.distance.truth
poi.polygon.promote.points.with.addresses.to.pois
poi.polygon.review.distance.threshold
poi.polygon.review.evidence.threshold
poi.polygon.review.if.matched.types
poi.polygon.review.multiuse.buildings
poi.polygon.review.threshold
poi.polygon.source.tag.key
poi.polygon.type.score.threshold

Listing all option names containing 'poi.polygon' and their descriptions...

=== poi.polygon.disable.same.source.conflation

* Data Type: bool
* Default Value: `false`

If true, POI to polygon conflation will not attempt to conflate two features with the same source
tag value.  e.g. both have 'source=osm' tag  The source tag key is specified by
poi.polygon.source.tag.key.  How strictly the source tag key must be matched is controlled by
poi.polygon.disable.same.source.conflation.match.tag.key.prefix.only.  This setting is useful when
you have a data layer where data has been collected as both POIs and polygons for the same source
and you never want the two source to be conflated together.

=== poi.polygon.disable.same.source.conflation.match.tag.key.prefix.only

* Data Type: bool
* Default Value: `true`

If set to false and poi.polygon.disable.same.source.conflation is set to true, POI to polygon
conflation will disable conflation only between features who have the exact same source tag value.
e.g. both have 'source=osm' tag  If set to true and poi.polygon.disable.same.source.conflation is
set to true, then the tag matcher is less strict and will attempt to match the prefix of the source
tag value when delimited by a colon.  e.g. 'source=mgcp:buildp_clip;osm' will match
'source=mgcp:builda_clip;osm' since both tag values begin with 'mgcp:'.

=== poi.polygon.enable.advanced.matching

* Data Type: bool
* Default Value: `false`

If true, POI to polygon conflation will perform additional checks against surrounding features
for match evidence.  This setting allows for detailed conflation customization but can be runtime
expensive when enabled.

=== poi.polygon.enable.review.reduction

* Data Type: bool
* Default Value: `true`

If true, POI to polygon conflation will attempt to reduce unnecessary reviews without increasing
incorrect matches.  This setting is somewhat experimental and can be runtime expensive when
enabled.

=== poi.polygon.match.distance.threshold

* Data Type: double
* Default Value: `5.0`

The maximum distance, in meters, between a POI and a polygon where they can still be considered
a match based on distance criteria only.

=== poi.polygon.match.evidence.threshold

* Data Type: int
* Default Value: `3`

The minimum evidence score at which a POI will be matched to a polygon.  Valid values are 1 to 4.
If an evidence score for a feature pair falls below this value, the relationship between the
features will be classified as a review or miss, depending on the value of
'poi.polygon.review.evidence.threshold'.  Generally, this setting should not be changed except
when working with specific POI/Polygon conflation use cases that require it.

=== poi.polygon.match.threshold

* Data Type: double
* Default Value: `${conflate.match.threshold.default}`

The threshold at which a match is called a match when comparing POIs to polygons.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== poi.polygon.miss.threshold

* Data Type: double
* Default Value: `${conflate.miss.threshold.default}`

The threshold at which a miss is called a miss when comparing POIs to polygons.

See also:

 * _Estimate Pairwise Relationships_, <<hootalgo>>

=== poi.polygon.name.score.threshold

* Data Type: double
* Default Value: `0.8`

The minimum similarity the name scores of two features can have and be considered a name
match, with 0.0 being the least similar and 1.0 being the most similar (-1.0 if there are no names
present (null).

=== poi.polygon.print.match.distance.truth

* Data Type: bool
* Default Value: `false`

If true, debug match distance output will be obtained from manually matched source data and printed
if running 'hoot score-matches' with POI to polygon conflation.

=== poi.polygon.promote.points.with.addresses.to.pois

* Data Type: bool
* Default Value: `false`

If true, POI to polygon conflation will classify all points with OSM address tags as POIs even if
they do not have specific type tags.

=== poi.polygon.review.distance.threshold

* Data Type: double
* Default Value: `125.0`

The maximum distance, in meters, between a POI and a polygon where they can still be considered
for review based on distance criteria only (value is added to the circular error of the compared
features).

=== poi.polygon.review.evidence.threshold

* Data Type: int
* Default Value: `1`

The minimum evidence score at which a POI will be reviewed against a polygon, if the evidence score
does not meet the threshold defined by 'poi.polygon.match.evidence.threshold'.  Valid values are
0 to 3.  If an evidence score for a feature pair falls below this value, the relationship between
the features will be classified as a miss.  If the value is set to 0, all feature pairs which did
not match will be reviewed.  If the value is set greater than or equal to
'poi.polygon.match.evidence.threshold', an error will occur.  Generally, this setting
should not be changed except when working with specific POI/Polygon conflation use cases that
require it.

=== poi.polygon.review.if.matched.types

* Data Type: list
* Default Value:
** ``

List of key value pairs in the format 'key=value' or  'key,value' (UI only) for features to always
review if marked as matches with POI to polygon conflation.  Delimit the individual types with ';'.
e.g. 'amenity=school;shop=mall' or 'amenity,school;shop,mall'  Also, when specifying the list from
the command line, surround the entire value string in double quotes.

=== poi.polygon.review.multiuse.buildings

* Data Type: bool
* Default Value: `false`

If true, POI to polygon conflation always marks matches between POIs and polygons where multi-use
building polygons are present as needing review.  The definition of multi-use buildings is
controlled by the Hootenanny schema.

=== poi.polygon.review.threshold

* Data Type: double
* Default Value: `${conflate.review.threshold.default}`

The threshold at which a review is called a review for PoiPolygon. See
`conflate.review.threshold.default`.

=== poi.polygon.source.tag.key

* Data Type: string
* Default Value: `source`

The source tag key to be used in conjunction with poi.polygon.disable.same.source.conflation.

=== poi.polygon.type.score.threshold

* Data Type: double
* Default Value: `0.7`

The minimum similarity the type scores a POI and polygon can have and be considered a type
match, with 0.0 being the least similar and 1.0 being the most similar.

Listing all option names...

  SampledAngleHistogramExtractor               Calculates the angle of each line segment in a sampled fashion and adds it to a histogram

Listing a format that is both input and output...

hootapidb://
hootapidb://

Listing an input format...

.osm.bz2

Listing an output format...

.shp

Listing detectable languages...

detectable languages:

Code: de
Name: German
Available: yes

Code: es
Name: Spanish
Available: yes

2 languages are supported for detection.
Currently, 2 of those languages are available for detection.

Listing translatable languages...

translatable languages:

Code: de
Name: German
Available: yes

Code: es
Name: Spanish
Available: yes

2 languages are supported for translation.
Currently, 2 of those languages are available for translation.

Listing available language detectors...

Available language detectors:

Name: TikaLanguageDetector
Description: blah
URL: https://tika.apache.org
Supports confidence: yes

Name: OpenNlpLanguageDetector
Description: more blah
URL: https://opennlp.apache.org
Supports confidence: no

2 detectors are available.

Listing available to English language translators...

Available language translators:

Name: JoshuaLanguageTranslator
Description: blah
URL: https://cwiki.apache.org/confluence/display/JOSHUA

Name: HootLanguageTranslator
Description: more blah
URL: N/A

2 translators are available.

Listing a match creator...

  HighwayMatchCreator                             Matches roads with the non-greedy algorithm

Listing a script match creator...

  ScriptMatchCreator,PoiGeneric.js                Matches POIs

Listing a merger...

  PoiPolygonMergerCreator                         Merges POIs into polygons

Listing a script merger...

  ScriptMergerCreator                             Script merge creator required by all script match creators

Listing an op...

  MapCleaner                                   operation         Cleans map data

Listing a visitor...

  RemoveEmptyAreasVisitor                      visitor           Removes empty areas

Listing a criterion...

  NonBuildingAreaCriterion                     criterion         Identifies features that are areas but not buildings

Listing a tag merger...

  AverageTagMerger                   Keeps tags from both features; overlapping tags are averaged together

Listing cleaning operations...

  DuplicateWayRemover                          operation         Removes duplicate ways from a map

Listing subline matchers...

  FrechetSublineMatcher         Matches lines based on the Frechet Distance algorithm

Listing subline string matchers...

  MaximalSublineStringMatcher   Matches lines based on the maximal subline string found

Listing pre-conflation operations...

  MapCleaner                                   operation         Cleans map data

Listing post-conflation operations...

  SuperfluousNodeRemover                       operation         Removes all nodes no part of a way

