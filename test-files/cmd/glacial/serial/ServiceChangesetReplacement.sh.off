#!/bin/bash
set -e

# This script tests the replacement changeset generation workflow for various geometry types. It is called from the 
# ServiceChangesetReplacement*.sh tests
#
# Multiple input formats are tested here. Each time the resultant changeset is written back to an OSM API database regardless of the 
# source format, as that allows for ease of visual inspection of the changes and makes debugging easier.
#
# Pay close attention to the modify change counts, as you can end up with output that looks correct but isn't due to ways being deleted and 
# re-created when they should have been modified.

# Input Parameters (see changeset-derive-replacement command doc for more detail):
# 1  - test name
# 2  - ref input file path
# 3  - sec input file path - (use "test-files/Empty.osm" for cut only; that's hackish, but we already use the existing of an empty second 
#                            input to determine whether generate the second input via perturbation)
# 4  - replacement aoi - what section is being replaced; e.g. "-71.4698,42.4866,-71.4657,42.4902"
# 5  - crop aoi - an initial aoi to crop both datasets down to in order to save processing time; use a global bounds to bypass cropping: 
#                 "-180,-90,180,90" 
# 6  - geometry filters - what types of geometries are being replaced?; delimited ElementCriterion class name list; leave empty to bypass
# 7  - replacement filters - what types of features are we removing?; delimited ElementCriterion class name list; leave empty to bypass
# 8  - chain replacement filters together (logical AND)?; true or false
# 9  - replacement filter options - semicolon delimited list of config opts to be applied to the replacement filters only; leave empty to 
#                                   bypass
# 10 - retainment filters - what types of features are we keeping?; delimited ElementCriterion class name list; leave empty to bypass
# 11 - chain retainment filters together (logical AND)?; true or false
# 12 - retainment filter options - semicolon delimited list of config opts to be applied to the retainment filters only; leave empty to bypass
# 13 - file formats - what types of outputs do we want to generate?; semicolon delimited list: db, xml, and/or json
# 14 - way snap tolerance (m) - how far can we snap ways to other ways?; leave empty to specify 0.0m 
# 15 - way snap node tolerance (m) - how far can we snap way nodes directly to other way nodes?; leave empty to specify 0.0m 
# 17 - extra params; anything extra params or config options you want to pass in for a custom config; applied to all commands

# TODO: 
# - consolidate the three replacement workflows into a single function

# PROCESS INPUTS

TEST_NAME=$1
echo "test name: " $TEST_NAME

# There may be multiple source files delimited with ';'. For multiple file inputs we'll run multiple consecutive replacements in a loop.
SOURCE_FILE_1=$2
echo "source file 1: " $SOURCE_FILE_1

# This has to come before parsing SOURCE_FILE_2.
CROP_AOI=$5
echo "crop aoi: " $CROP_AOI
CROP_OPTS="-D crop.bounds=$CROP_AOI"
if [[ "$CROP_AOI" == "-180,-90,180,90" ]]; then # If a global crop bounds was passed in, then skip cropping.
  CROP_OPTS=""
fi

SOURCE_FILE_2=$3
# If the second source file input parameter was not passed in, we'll perturb the first input source file and use the original data for the 
# secondary and the perturbed for the ref.
if [ "$SOURCE_FILE_2" == "" ]; then
  SOURCE_FILE_2=$SOURCE_FILE_1
  if [ "$CROP_OPTS" == "" ]; then
    REF_CONVERT_OPS="hoot::SetTagValueVisitor;hoot::PertyOp"
    SEC_CONVERT_OPS="hoot::SetTagValueVisitor"
  else
    REF_CONVERT_OPS="hoot::MapCropper;hoot::SetTagValueVisitor;hoot::PertyOp"
    SEC_CONVERT_OPS="hoot::MapCropper;hoot::SetTagValueVisitor"
  fi
  PERTURBING_REF="true" 
else
  if [ "$CROP_OPTS" == "" ]; then
    REF_CONVERT_OPS="hoot::SetTagValueVisitor"
    SEC_CONVERT_OPS="hoot::SetTagValueVisitor"
  else
    REF_CONVERT_OPS="hoot::MapCropper;hoot::SetTagValueVisitor"
    SEC_CONVERT_OPS="hoot::MapCropper;hoot::SetTagValueVisitor"
  fi
  PERTURBING_REF="false"
fi 
echo "source file 2: " $SOURCE_FILE_2
echo "REF_CONVERT_OPS: " $REF_CONVERT_OPS
echo "SEC_CONVERT_OPS: " $SEC_CONVERT_OPS

REPLACEMENT_AOI=$4
echo "replacement aoi: " $REPLACEMENT_AOI

if [ "$6" == "" ]; then
  GEOMETRY_FILTERS=""
  TAG_ELEMENT_CRITERIA="hoot::BuildingCriterion;hoot::HighwayCriterion;hoot::PoiCriterion"
else
  GEOMETRY_FILTERS=" --geometry-filters "$6
  TAG_ELEMENT_CRITERIA=$6
fi 
echo "geometry filters: " $GEOMETRY_FILTERS
echo "tag element criteria: " $TAG_ELEMENT_CRITERIA

if [ "$7" == "" ]; then
  REPLACEMENT_FILTERS=""
else
  REPLACEMENT_FILTERS=" --replacement-filters "$7
fi
echo "replacement filters: " $REPLACEMENT_FILTERS

CHAIN_REPLACEMENT_FILTERS=$8
if [ "$CHAIN_REPLACEMENT_FILTERS" == "true" ]; then
  CHAIN_REPLACEMENT_FILTERS="--chain-replacement-filters"
else
  CHAIN_REPLACEMENT_FILTERS=""
fi
echo "chain replacement filters: " $CHAIN_REPLACEMENT_FILTERS 

if [ "$9" == "" ]; then
  REPLACEMENT_FILTER_OPTIONS=""
else
  REPLACEMENT_FILTER_OPTIONS=" --replacement-filter-options "$9
fi
echo "replacement filter options: " $REPLACEMENT_FILTER_OPTIONS

if [ "${10}" == "" ]; then
  RETAINMENT_FILTERS=""
else
  RETAINMENT_FILTERS=" --retainment-filters "${10}
fi
echo "retainment filters: " $REPLACEMENT_FILTERS

CHAIN_RETAINMENT_FILTERS=${11}
if [ "$CHAIN_RETAINMENT_FILTERS" == "true" ]; then
  CHAIN_RETAINMENT_FILTERS="--chain-retainment-filters"
else
  CHAIN_RETAINMENT_FILTERS=""
fi
echo "chain retainment filters: " $CHAIN_RETAINMENT_FILTERS 

if [ "${12}" == "" ]; then
  RETAINMENT_FILTER_OPTIONS=""
else
  RETAINMENT_FILTER_OPTIONS=" --retainment-filter-options "${12}
fi
echo "retainment filter options: " $RETAINMENT_FILTER_OPTIONS

SOURCE_FORMATS=${13}
echo "source formats: " $SOURCE_FORMATS 

if [ "${14}" == "" ]; then
  WAY_SNAP_TOLERANCE="0.0"
else
  WAY_SNAP_TOLERANCE=${14}
fi
echo "way snap tolerance: " $WAY_SNAP_TOLERANCE 

if [ "${15}" == "" ]; then
  EXISTING_WAY_NODE_TOLERANCE="0.0"
else
  EXISTING_WAY_NODE_TOLERANCE=${15}
fi
echo "existing way node tolerance: " $EXISTING_WAY_NODE_TOLERANCE 

EXTRA_PARAMS=${17}
echo "extra params: " $EXTRA_PARAMS

# SET UP TEST FILES

IN_DIR=test-files/cmd/glacial/serial/$TEST_NAME
OUT_DIR=test-output/cmd/glacial/serial/$TEST_NAME
rm -rf $OUT_DIR
mkdir -p $OUT_DIR

# INIT REF DATABASE VARS

source conf/database/DatabaseConfig.sh
export OSM_API_DB_URL="osmapidb://$DB_USER:$DB_PASSWORD@$DB_HOST:$DB_PORT/$DB_NAME_OSMAPI"
export PSQL_DB_AUTH="-h $DB_HOST -p $DB_PORT -U $DB_USER"
export PGPASSWORD=$DB_PASSWORD_OSMAPI
REF_DB_INPUT=$OSM_API_DB_URL

HOOT_EMAIL="${TEST_NAME}@hoottestcpp.org"

# SET UP HOOT CONFIGURATION

# Had to set changeset.max.size to a large number due to the fact with certain larger datasets (debugging data only being larger than we 
# would include in actual tests) the osm api db bulk inserter would write multiple changesets for the input data and then the sql changeset 
# applier would pick up the wrong latest changeset ID. Worth fixing, but since we only use sql changesets internally for testing...not that 
# big of a deal for now. 

# debug.maps.remove.missing.elements=false is useful for debugging but it can make output unviewable in JOSM.
# convert.bounding.box.remove.missing.elements=false ensures that we don't drop any missing elements except when writing out our debug maps.

LOG_LEVEL="--warn"
GENERAL_OPTS="-C UnifyingAlgorithm.conf -C Testing.conf -D uuid.helper.repeatable=true -D writer.include.debug.tags=true -D reader.add.source.datetime=false -D writer.include.circular.error.tags=false -D convert.bounding.box.remove.missing.elements=false -D log.warnings.for.missing.elements=false -D debug.maps.write=false -D debug.maps.remove.missing.elements=false -D element.hash.visitor.non.metadata.ignore.keys=note $EXTRA_PARAMS -D log.class.filter= "
# Holding onto missing child element refs does not work yet with cropping, so disable it when cropping is specified.
# TODO: bug issue creation pending. 
# TODO: This needs to be only added for the initial write and not all convert ops in the script.
if [ "$CROP_OPTS" == "" ]; then
  GENERAL_OPTS=$GENERAL_OPTS" -D map.reader.add.child.refs.when.missing=true"
fi
DB_OPTS="-D api.db.email=$HOOT_EMAIL -D hootapi.db.writer.create.user=true -D hootapi.db.writer.overwrite.map=true -D changeset.user.id=1 -D changeset.max.size=999999 $EXTRA_PARAMS"
PERTY_OPTS="-D random.seed=1 -D perty.systematic.error.x=15 -D perty.systematic.error.y=15 $EXTRA_PARAMS -D perty.ops= "
CHANGESET_DERIVE_OPTS="-D changeset.user.id=1 -D bounds.output.file=$OUT_DIR/$TEST_NAME-bounds.osm -D snap.unconnected.ways.existing.way.node.tolerance=$EXISTING_WAY_NODE_TOLERANCE -D snap.unconnected.ways.snap.tolerance=$WAY_SNAP_TOLERANCE $EXTRA_PARAMS "
CUSTOM_TAG_KEY="note"
CUSTOM_TAG_VAL="Source"

# DB SOURCE WORKFLOW

if [[ $SOURCE_FORMATS == *"db"* ]]; then

  # SET UP PER TEST HOOT VARS

  HOOT_DB_URL="hootapidb://$DB_USER:$DB_PASSWORD@$DB_HOST:$DB_PORT/$DB_NAME"
  SEC_DB_INPUT="$HOOT_DB_URL/$TEST_NAME-sec"
  CHANGESET_DB=$OUT_DIR/$TEST_NAME-changeset-db.osc.sql
  CHANGESET_DB_DEBUG=$OUT_DIR/$TEST_NAME-changeset-db.osc
  OUT_DB=$TEST_NAME-db-replaced.osm

  # DATA PREP

  echo ""
  if [[ "$CROP_OPTS" == "" ]]; then
    echo "Writing reference dataset from: $SOURCE_FILE_1 to an osm api db (contains features to be replaced)..."
  else
    echo "Cropping the reference dataset from: $SOURCE_FILE_1 to: $CROP_AOI, then writing to an osm api db (contains features to be replaced)..."
  fi
  echo ""
  scripts/database/CleanAndInitializeOsmApiDb.sh
  # Note that we're only throwing out source ids here b/c we have some ref data in the tests that happens to have negative IDs and we want 
  # them to be positive to better resemble OSM API data. Generally, you'd want reader.use.data.source.ids=true here. Same applies to the 
  # other workflows below.
  hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS $CROP_OPTS $PERTY_OPTS -D debug.maps.filename=$OUT_DIR/data-prep-ref-db.osm -D reader.use.data.source.ids=false -D id.generator=hoot::PositiveIdGenerator -D convert.ops=$REF_CONVERT_OPS -D set.tag.value.visitor.element.criteria=$TAG_ELEMENT_CRITERIA -D set.tag.value.visitor.keys=$CUSTOM_TAG_KEY -D set.tag.value.visitor.values=$CUSTOM_TAG_VAL" 1" $SOURCE_FILE_1 $REF_DB_INPUT 
  echo ""
  if [[ "$CROP_OPTS" == "" ]]; then
    echo "Writing the secondary dataset from: $SOURCE_FILE_2 to a hoot api db (contains features to replace with)..."
  else
    echo "Cropping the secondary dataset from: $SOURCE_FILE_2 to: $CROP_AOI, then writing it to a hoot api db (contains features to replace with)..."
  fi
  echo ""
  # Note that we're throwing out source ids here and treating the secondary data as new data in order to avoid possible id conflicts with the
  # reference, since both may have been derived from the same input data if perturbation is being used.
  hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS $CROP_OPTS -D debug.maps.filename=$OUT_DIR/data-prep-sec-db.osm -D reader.use.data.source.ids=false -D convert.ops=$SEC_CONVERT_OPS -D set.tag.value.visitor.element.criteria=$TAG_ELEMENT_CRITERIA -D set.tag.value.visitor.keys=$CUSTOM_TAG_KEY -D set.tag.value.visitor.values=$CUSTOM_TAG_VAL" 2" $SOURCE_FILE_2 $SEC_DB_INPUT

  # CHANGESET DERIVATION

  echo ""
  echo "Deriving a changeset between the osm api db and the hoot api db layers over: $REPLACEMENT_AOI, to file: $CHANGESET_DB that replaces features in the reference dataset with those from a secondary dataset..."
  echo ""
  if [ "$SOURCE_FILE_2" == "test-files/Empty.osm" ]; then
    # cut only
    hoot changeset-derive-replacement $LOG_LEVEL $GENERAL_OPTS $DB_OPTS $CHANGESET_DERIVE_OPTS -D debug.maps.filename=$OUT_DIR/changeset-derive-db.osm $REF_DB_INPUT $REPLACEMENT_AOI $CHANGESET_DB $REF_DB_INPUT $GEOMETRY_FILTERS $REPLACEMENT_FILTERS $CHAIN_REPLACEMENT_FILTERS $REPLACEMENT_FILTER_OPTIONS --write-bounds
  else
    # cut and replace
    hoot changeset-derive-replacement $LOG_LEVEL $GENERAL_OPTS $DB_OPTS $CHANGESET_DERIVE_OPTS -D debug.maps.filename=$OUT_DIR/changeset-derive-db.osm $REF_DB_INPUT $SEC_DB_INPUT $REPLACEMENT_AOI $CHANGESET_DB $REF_DB_INPUT $GEOMETRY_FILTERS $REPLACEMENT_FILTERS $CHAIN_REPLACEMENT_FILTERS $REPLACEMENT_FILTER_OPTIONS --write-bounds
  fi


  # CHANGESET APPLICATION

  echo ""
  echo "Applying the changeset: $CHANGESET_DB to the reference data in the osm api db..."
  echo ""
  hoot changeset-apply $LOG_LEVEL $GENERAL_OPTS $DB_OPTS $CHANGESET_DERIVE_OPTS -D debug.maps.filename=$OUT_DIR/changeset-apply-db.osm $CHANGESET_DB $OSM_API_DB_URL

  # CHECK THE RESULTS

  echo ""
  echo "Reading the entire reference dataset out of the osm api db to: $OUT_DB for verification..."
  echo ""
  # We strive not to remove missing elements throughout this process in order to minimize the impact of the changeset. 
  # debug.maps.remove.missing.elements=false can temporarily be set to prevent removing them from debug output but in our final test output
  # here, we'll explicitly remove them so the output can be viewed in JOSM.
  hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS -D convert.ops="hoot::RemoveMissingElementsVisitor" -D debug.maps.filename=$OUT_DIR/final-write-db.osm $OSM_API_DB_URL $OUT_DIR/$OUT_DB
  hoot diff $LOG_LEVEL $GENERAL_OPTS $IN_DIR/$OUT_DB $OUT_DIR/$OUT_DB

  # CLEANUP

  hoot db-delete $LOG_LEVEL $GENERAL_OPTS $DB_OPTS -D debug.maps.filename=$OUT_DIR/cleanup-db.osm $SEC_DB_INPUT

fi

# XML SOURCE WORKFLOW

if [[ $SOURCE_FORMATS == *"xml"* ]]; then

  # SET UP PER TEST HOOT VARS

  if [ "$PERTURBING_REF" == "true" ]; then
    REF_XML_INPUT=$OUT_DIR/ref-perturbed-original.osm
  else
    REF_XML_INPUT=$OUT_DIR/ref-original.osm
  fi
  SEC_XML_INPUT=$OUT_DIR/sec-original.osm
  CHANGESET_XML=$OUT_DIR/$TEST_NAME-changeset-xml.osc.sql
  CHANGESET_XML_DEBUG=$OUT_DIR/$TEST_NAME-changeset-xml.osc
  OUT_XML=$TEST_NAME-xml-replaced.osm

  # DATA PREP

  echo ""
  if [[ "$CROP_OPTS" == "" ]]; then
    echo "Writing the reference dataset from: $SOURCE_FILE_1 to an osm api db (contains features to be replaced)..."
  else
    echo "Cropping the reference dataset from: $SOURCE_FILE_1 to: $CROP_AOI, then writing it to an osm api db (contains features to be replaced)..."
  fi
  echo ""
  scripts/database/CleanAndInitializeOsmApiDb.sh
  hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS $CROP_OPTS $PERTY_OPTS -D debug.maps.filename=$OUT_DIR/data-prep-ref-xml.osm -D reader.use.data.source.ids=false -D id.generator=hoot::PositiveIdGenerator -D convert.ops=$REF_CONVERT_OPS -D set.tag.value.visitor.element.criteria=$TAG_ELEMENT_CRITERIA -D set.tag.value.visitor.keys=$CUSTOM_TAG_KEY -D set.tag.value.visitor.values=$CUSTOM_TAG_VAL" 1" $SOURCE_FILE_1 $REF_DB_INPUT
  # To get a test more accurate to the production environment, use this instead of the line above.
  #hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS $CROP_OPTS $PERTY_OPTS -D debug.maps.filename=$OUT_DIR/data-prep-ref-xml.osm $SOURCE_FILE_1 $REF_DB_INPUT
  # Don't remove missing elements for these file conversions (even if you need to view them in JOSM), since they are the input data and we 
  # want to see any errors caused by them having missing elements.
  echo ""
  echo "Writing the reference dataset from the osm apidb to an xml file: $REF_XML_INPUT (contains features to be replaced)..."
  echo ""
  hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS -D debug.maps.filename=$OUT_DIR/data-prep-ref-xml.osm -D reader.use.data.source.ids=true $REF_DB_INPUT $REF_XML_INPUT
  echo ""
  if [[ "$CROP_OPTS" == "" ]]; then
    echo "Writing the secondary dataset from: $SOURCE_FILE_2 to an xml file: $SEC_XML_INPUT (contains features to replace with)..."
  else
    echo "Cropping the secondary dataset from: $SOURCE_FILE_2 to: $CROP_AOI, then writing it to an xml file: $SEC_XML_INPUT (contains features to replace with)..."
  fi
  echo ""
  hoot convert $LOG_LEVEL $GENERAL_OPTS $CROP_OPTS -D debug.maps.filename=$OUT_DIR/data-prep-sec-xml.osm -D reader.use.data.source.ids=false -D convert.ops=$SEC_CONVERT_OPS -D set.tag.value.visitor.element.criteria=$TAG_ELEMENT_CRITERIA -D set.tag.value.visitor.keys=$CUSTOM_TAG_KEY -D set.tag.value.visitor.values=$CUSTOM_TAG_VAL" 2" $SOURCE_FILE_2 $SEC_XML_INPUT
  # To get a test more accurate to the production environment, use this instead of the line above.
  #hoot convert $LOG_LEVEL $GENERAL_OPTS $CROP_OPTS -D debug.maps.filename=$OUT_DIR/data-prep-sec-xml.osm $SOURCE_FILE_2 $SEC_XML_INPUT

  # CHANGESET DERIVATION

  echo ""
  echo "Deriving a changeset between $REF_XML_INPUT and $SEC_XML_INPUT over: $REPLACEMENT_AOI, to file: $CHANGESET_XML that replaces features in the reference dataset with those from a secondary dataset..."
  echo ""
  if [ "$SOURCE_FILE_2" == "test-files/Empty.osm" ]; then
    hoot changeset-derive-replacement $LOG_LEVEL $GENERAL_OPTS $CHANGESET_DERIVE_OPTS -D debug.maps.filename=$OUT_DIR/changeset-derive-xml.osm $REF_XML_INPUT $REPLACEMENT_AOI $CHANGESET_XML $REF_DB_INPUT $GEOMETRY_FILTERS $REPLACEMENT_FILTERS $CHAIN_REPLACEMENT_FILTERS $REPLACEMENT_FILTER_OPTIONS --write-bounds
  else
    hoot changeset-derive-replacement $LOG_LEVEL $GENERAL_OPTS $CHANGESET_DERIVE_OPTS -D debug.maps.filename=$OUT_DIR/changeset-derive-xml.osm $REF_XML_INPUT $SEC_XML_INPUT $REPLACEMENT_AOI $CHANGESET_XML $REF_DB_INPUT $GEOMETRY_FILTERS $REPLACEMENT_FILTERS $CHAIN_REPLACEMENT_FILTERS $REPLACEMENT_FILTER_OPTIONS --write-bounds
  fi
  
  # CHANGESET APPLICATION

  echo ""
  echo "Applying the changeset: $CHANGESET_XML to the reference data in the osm api db..."
  echo ""
  hoot changeset-apply $LOG_LEVEL $GENERAL_OPTS $DB_OPTS $CHANGESET_DERIVE_OPTS -D debug.maps.filename=$OUT_DIR/changeset-apply-xml.osm $CHANGESET_XML $OSM_API_DB_URL

  # CHECK THE RESULTS

  echo ""
  echo "Reading the entire reference dataset out of the osm api db to: $OUT_XML for verification..."
  echo ""
  hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS -D convert.ops="hoot::RemoveMissingElementsVisitor" -D debug.maps.filename=$OUT_DIR/final-write-xml.osm $OSM_API_DB_URL $OUT_DIR/$OUT_XML
  #hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS -D debug.maps.filename=$OUT_DIR/final-write-xml.osm $OSM_API_DB_URL $OUT_DIR/$OUT_XML
  # Not completely sure what the differences between the xml output and db output are yet, but the output maps look identical.
  hoot diff $LOG_LEVEL $GENERAL_OPTS $IN_DIR/$OUT_XML $OUT_DIR/$OUT_XML

fi

# JSON SOURCE WORKFLOW

if [[ $SOURCE_FORMATS == *"json"* ]]; then

  # SET UP PER TEST HOOT VARS

  if [ "$PERTURBING_REF" == "true" ]; then
    REF_JSON_INPUT=$OUT_DIR/ref-perturbed-original.json
  else
    REF_JSON_INPUT=$OUT_DIR/ref-original.json
  fi
  SEC_JSON_INPUT=$OUT_DIR/sec-original.json
  CHANGESET_JSON=$OUT_DIR/$TEST_NAME-changeset-json.osc.sql
  CHANGESET_JSON_DEBUG=$OUT_DIR/$TEST_NAME-changeset-json.osc
  OUT_JSON=$TEST_NAME-json-replaced.osm

  # DATA PREP

  echo ""
  if [[ "$CROP_OPTS" == "" ]]; then
    echo "Writing the reference dataset from: $SOURCE_FILE_1 to an osm api db (contains features to be replaced)..."
  else
    echo "Cropping the reference dataset from: $SOURCE_FILE_1 to: $CROP_AOI, then writing it to an osm api db (contains features to be replaced)..."
  fi
  echo ""
  scripts/database/CleanAndInitializeOsmApiDb.sh
  hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS $CROP_OPTS $PERTY_OPTS -D debug.maps.filename=$OUT_DIR/data-prep-ref-json.osm -D reader.use.data.source.ids=false -D id.generator=hoot::PositiveIdGenerator -D convert.ops=$REF_CONVERT_OPS -D set.tag.value.visitor.element.criteria=$TAG_ELEMENT_CRITERIA -D set.tag.value.visitor.keys=$CUSTOM_TAG_KEY -D set.tag.value.visitor.values=$CUSTOM_TAG_VAL" 1" $SOURCE_FILE_1 $REF_DB_INPUT
  echo ""
  echo "Writing the reference dataset from the osm api db to a json file: $REF_JSON_INPUT (contains features to be replaced)..."
  echo ""
  hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS -D debug.maps.filename=$OUT_DIR/data-prep-ref-json.osm -D reader.use.data.source.ids=true $REF_DB_INPUT $REF_JSON_INPUT
  echo ""
  if [[ "$CROP_OPTS" == "" ]]; then
    echo "Writing the secondary dataset from: $SOURCE_FILE_2 to a json file: $SEC_JSON_INPUT (contains features to replace with)..."
  else
    echo "Cropping the secondary dataset from: $SOURCE_FILE_2 to: $CROP_AOI, then writing it to a json file: $SEC_JSON_INPUT (contains features to replace with)..."
  fi
  echo ""
  hoot convert $LOG_LEVEL $GENERAL_OPTS $CROP_OPTS -D debug.maps.filename=$OUT_DIR/data-prep-sec-json.osm -D reader.use.data.source.ids=false -D convert.ops=$SEC_CONVERT_OPS -D set.tag.value.visitor.element.criteria=$TAG_ELEMENT_CRITERIA -D set.tag.value.visitor.keys=$CUSTOM_TAG_KEY -D set.tag.value.visitor.values=$CUSTOM_TAG_VAL" 2" $SOURCE_FILE_2 $SEC_JSON_INPUT

  # CHANGESET DERIVATION

  echo ""
  echo "Deriving a changeset between $REF_JSON_INPUT and $SEC_JSON_INPUT over: $REPLACEMENT_AOI, to file: $CHANGESET_JSON that replaces features in the reference dataset with those from a secondary dataset..."
  echo ""
  if [ "$SOURCE_FILE_2" == "test-files/Empty.osm" ]; then
    hoot changeset-derive-replacement $LOG_LEVEL $GENERAL_OPTS $CHANGESET_DERIVE_OPTS -D debug.maps.filename=$OUT_DIR/changeset-derive-json.osm $REF_JSON_INPUT $REPLACEMENT_AOI $CHANGESET_JSON $REF_DB_INPUT $GEOMETRY_FILTERS $REPLACEMENT_FILTERS $CHAIN_REPLACEMENT_FILTERS $REPLACEMENT_FILTER_OPTIONS --write-bounds
  else
    hoot changeset-derive-replacement $LOG_LEVEL $GENERAL_OPTS $CHANGESET_DERIVE_OPTS -D debug.maps.filename=$OUT_DIR/changeset-derive-json.osm $REF_JSON_INPUT $SEC_JSON_INPUT $REPLACEMENT_AOI $CHANGESET_JSON $REF_DB_INPUT $GEOMETRY_FILTERS $REPLACEMENT_FILTERS $CHAIN_REPLACEMENT_FILTERS $REPLACEMENT_FILTER_OPTIONS --write-bounds
  fi

  # CHANGESET APPLICATION

  echo ""
  echo "Applying the changeset: $CHANGESET_JSON to the reference data in the osm api db..."
  echo ""
  hoot changeset-apply $LOG_LEVEL $GENERAL_OPTS $DB_OPTS $CHANGESET_DERIVE_OPTS -D debug.maps.filename=$OUT_DIR/changeset-apply-json.osm $CHANGESET_JSON $OSM_API_DB_URL

  # CHECK THE RESULTS

  echo ""
  echo "Reading the entire reference dataset out of the osm api db to: $OUT_JSON for verification..."
  echo ""
  hoot convert $LOG_LEVEL $GENERAL_OPTS $DB_OPTS -D convert.ops="hoot::RemoveMissingElementsVisitor" -D debug.maps.filename=$OUT_DIR/final-write-json.osm $OSM_API_DB_URL $OUT_DIR/$OUT_JSON
  # json output matches xml output
  hoot diff $LOG_LEVEL $GENERAL_OPTS $IN_DIR/$OUT_XML $OUT_DIR/$OUT_JSON

fi

# Delete the user
psql $PSQL_DB_AUTH -c "DELETE FROM users WHERE email='$HOOT_EMAIL';" > /dev/null

