
[[Introduction]]
=== Detail Summary

https://github.com/ngageoint/hootenanny/blob/master/docs/user/SummaryDetail.asciidoc[Detail Summary]

=== Conflation Background

[quote,Seth and Samal,Encyclopedia of GIS]
_____
In GIS, conflation is defined as the process of combining geographic information
from overlapping sources so as to retain accurate data, minimize redundancy, and
reconcile data conflicts.
_____

Check out the quick Hootenanny overview http://github.com/ngageoint/hootenanny#readme[here]. Also, 
there is a brief (https://github.com/ngageoint/hootenanny/wiki/Frequently-Asked-Questions)[FAQ].

Conflation within GIS can generally be grouped into several high level
categories:

* Vector to Vector (V2V) - Merges two vector data sets into a single output vector
  data set.
* Vector to Image (V2I) - Snaps a vector data set to an image and possibly performs
  feature extraction.
* Image to Vector (I2V) - Warps an image to a vector data set.
* Image to Image (I2I) - Aligns two images.

.Simple V2V Conflation
image::images/SimpleConflation.png[]

Hootenanny deals exclusively with vector to vector conflation. The following
sections discuss when Hootenanny is an appropriate tool for conflation and
general guidance in determining what strategy to employ when using Hootenanny.

=== Conflation Workflow

Hootenanny is a tool to help the user work through a conflation problem.
Many aspects of the conflation workflow are automated or semi-automated to help
the user. Generally the workflow looks something like the following:

. Determine what data is worth conflating
. Normalize and prepare the input data for conflation
. Conflate a pair of data sets at a time
. Review conflated result
. Repeat as necessary
. Export the conflated data

The following sections go into the details of each of the above steps.

==== Selecting Appropriate Data

Many factors play into which data is appropriate for conflation. Not all data is suitable for conflation. Below is a short list of examples of both appropriate and inappropriate conflation scenarios.

Inappropriate data for conflation:

* Conflating two extremely different data sets. For instance, conflating Rome
  before the http://en.wikipedia.org/wiki/Great_Fire_of_Rome[Great Fire of Rome]
  with modern Rome.
* Data sets with dramatically different positional accuracy. For instance,
  conflating 1:1,000,000 scale  http://en.wikipedia.org/wiki/Vector_map[VMAP0]
  with city level NAVTEQ will not produce meaningful results.
* Garbage data. It may seem obvious, but garbage in, garbage out applies in
  conflation just like any other system.
* Pristine and complete data vs. poor data. If the pristine data is superior in
  nearly every way conflating it with poor data will likely just introduce
  errors.

Appropriate data for conflation:

* Both data sets provide significant complimentary benefit.
* Conflating sparse country data with good positional accuracy with dense city
  data.
* Sparse <<OpenStreetMap,OpenStreetMap>> (OSM) with complete vector data
  extracted from imagery. In some regions OSM provides sparse data with lots of
  local information that isn't available from imagery (e.g. street names). By
  conflating you get the complete coverage along with rich OSM attribution.

==== Normalizing and Preparing Data

Before conflation can occur Hootenanny expects that all data is provided in a
modified OSM schema and data model that is a superset of the
http://wiki.openstreetmap.org/wiki/Map_Features[OSMschema]. The http://wiki.openstreetmap.org/wiki/Element[OSM data model] provides
a connected topology that aids conflation of multiple "layers" at one time while
the extendable OSM schema provides flexibility in handling many data types.

Hootenanny provides a number of utilities for converting Shapefiles and other
common formats into the OSM data model as well as translating existing schemas
into OSM. See the <<Translation,Translation>> section for further details.

Hootenanny also provides some functions for automatically cleaning many bad data
scenarios. Many of the operations are performed prior to conflation.

See also:

* <<clean,clean command>>
* <<MapCleanerTransforms, map.cleaner.transforms>>

==== Conflation Strategies

These are the conflation strategies supported by Hootenanny:

* Reference Conflation (aka Vertical Conflation) - Both data sets contain useful information and significant overlap.  Conflate the best
geometry and tag parts of map B into map A.
* Horizontal Conflation - There is a small amount of overlap between the two data sets.
* Cookie Cutter & Horizontal Conflation - One data set is superior to the other in every way but does not cover the same region. The
lesser data set will be cropped and the seams stitched back in using Horizontal Conflation.  Define a specific region in map A that should
not be modified at all and stitch in data from map B around it.
* Differential Conflation - Conflate map A with B where the only data added to the output from B is in areas that don't overlap with A.  Optionally, you can configure to overwrite tags in A from B even when there is overlap.
* Attribute Conflation - Conflate map A with B where only tags are transferred from B to A and no changes are made to A's geometry (with some configurable exceptions).
* Average Conflation - Averages geometries together in the output.

See also:

* _Unifying Conflation_, <<hootuser>>

*_Reference Conflation_*

.Vertical Conflation.  Red and blue boxes represent different data sets.  This is a good candidate for Reference Conflation because of the high degree of overlap between the two data sets.
image::images/VerticalConflation.png[]

Reference conflation is most applicable when both data sets provide value and there is significant overlap between the data sets. In this scenario many of the features will be evaluated for conflation and possibly merged or marked as needing review. The primary advantage to using this strategy is maintaining much of the information available in both data sets. Because a large amount of the data is being evaluated for conflation it also increases the chances that errors will be introduced or unnecessary reviews may be generated.

To use, pass `ReferenceConflation.conf` to the conflate command.

e.g.
--------
hoot conflate -C ReferenceConflation.conf input1.osm input2.osm output.osm
--------

See also:

* <<conflate,conflate command>>

*_Average Conflation_*

Average Conflation attempts to find a midway point between two features when conflating. Neither
input is considered more important than the other (this was the original Hootenanny conflation 
strategy). Both geometries and tag values are averaged together to create the conflated output.

NOTE: Average Conflation is currently only supported for linear features.

*_Horizontal Conflation_*

.Horizontal Conflation.  This is a good candidate for Horizontal Conflation because there is a small amount of overlap between the two data sets.
image::images/HorizontalConflation.png[]

Programmatically there is no difference between Reference and Horizontal conflation. The difference is solely conceptual.

[[UnsupportedHorizontalConflation]]
.Unsupported Horizontal Conflation due to the complete lack of overlap between the two data sets.
image::images/NotHorizontalConflation.png[]

As demonstrated in <<UnsupportedHorizontalConflation>> two vector layers that don't quite touch are not conflated. If this is of interest please create an issue at the https://github.com/ngageoint/hootenanny[Hootenanny GitHub page].

To use, pass `HorizontalConflation.conf` to the conflate command.

e.g.
--------
hoot conflate -C HorizontalConflation.conf input1.osm input2.osm output.osm
--------

See also:

* <<conflate,conflate command>>

[[CookieCutter]]
*_Cookie Cutter & Horizontal_*

[[CookieCutterImage]]
.Cookie Cutter & Horizontal.  The left image depicts the overlap of a high quality, smaller area data set overlayed on a coarser regional data set that is typical for Reference/Horizontal Conflation.  The shaded area in the right image depicts the -1km buffer that is applied during the Cookie Cutter operation.
image::images/CookieCutter.png[]

The cookie cutter operation is designed for situations where two data sets contain significant overlap, but one data set is better in _every way_. A typical scenario that warrants this strategy is coarse country wide data that needs to be conflated with high quality city level data. When employing cookie cutter a polygon that approximates the bounds of the city will be removed from the coarse country data before conflation.

[[horizontalconflate_Boulder1]]
.Boulder, CO with Street centerlines (gray) and OpenStreetMap Highways (red).  Right image depicts alpha-shape (red polygon).  Street centerline data obtained from the link:$$https://www-static.bouldercolorado.gov/docs/opendata/Streets.zip$$[City of Boulder] and Highway data set downloaded from an OSM data provider.  The basemap shown here is OSM.
image::images/hootid-horizconfl.png[]

[[horizontalconflate_hootid]]
.Process depicted in the Hootenanny User interface. The Horizontal & Cookie Cutter conflation performs an edge matching to merge the Street centerline data with the OSM data.  The resulting conflated dataset shown in bottom image (green).  Boulder, CO with DigitalGlobe Global Basemap (GBM).
image::images/hootiD_horizontalconflation_boulder.png[scaledwidth="50%"]

To use, pass `HorizontalConflation.conf` to the conflate command.

e.g.
--------
hoot conflate -C HorizontalConflation.conf input1.osm input2.osm output.osm
--------

See also:

* <<alpha-shape,alpha-shape command>>
* <<conflate,conflate command>>
* <<cut,cut command>>
* <<crop,crop command>>
* <<hootuser, horizontal conflation example>>

*_Differential Conflation_*

To use, pass `DifferentialConflation.conf` to the conflate command.

e.g.
--------
hoot conflate -C DifferentialConflation.conf input1.osm input2.osm output.osm
--------

More details: <<hootuser, DifferentialConflation>>

*_Attribute Conflation_*

To use, pass `AttributeConflation.conf` to the conflate command.

e.g.
--------
hoot conflate -C AttributeConflation.conf input1.osm input2.osm output.osm
--------

More details: <<hootuser, AttributeConflation>>

==== Review Conflated Results

There are inevitably data scenarios that do not contain a clear solution when conflating. To handle this Hootenanny presents the user with _reviews_. These reviews are primarily the result of bad input data or ambiguous situations. During the conflation process Hootenanny will merge any features it considers to have a high confidence match and flag features for review if one of the aforementioned scenarios occurs.

NOTE: Fill in hoot:review tag details.

Each review flags one or more features. The features are referenced using the <<UUID,uuid>> field. A `hoot:review:note` field is also populated with a brief description of why the features were flagged for review.

*_Reviewing from the Command Line Interface_*

Reviewable items are flagged with several `hoot:review` tags during the conflation process. The user can then edit the resulting output file with an editor of their choosing to resolve the reviewable items. It is worth noting that this review process should occur before the data is exported as exporting the data using the `convert` command or similar will likely strip the review tags.

NOTE: Add directions for removing reviewable items from the output using config options.

See also:

* <<conflate,conflate command>>
* <<convert,convert command>>

*_Reviewing from the Web Interface_*

The web interface exposes reviewable items through an intuitive interface that guides the user through the review process.  For additional background on the review process within the user interface please refer to the Hootenanny User Interface Guide.

==== Repeat Conflation Process

In some cases there are more than two files that must be conflated. If this is the case the data must be conflated in a pairwise fashion. For instance if you are conflated three data sets, A, B & C, then the conflation may go as follows:

.Pairwise Conflation Example

[graphviz, images/__PairwiseConflation.png]
---------------------------------------------------------------------
digraph G
{
  rankdir = LR;
  node [shape=ellipse,width=2,height=1,style=filled,fillcolor="#e7e7f3"];
  conflate1 [label = "Conflate 1",shape=record];
  conflate2 [label = "Conflate 2",shape=record];
  A -> conflate1;
  B -> conflate1;
  conflate1 -> AB;
  AB -> conflate2;
  C -> conflate2;
  conflate2 -> ABC;
}
---------------------------------------------------------------------

==== Export

If you desire your data in an OSM compatible format then this step is
unnecessary, however, if you would like to use the data in a more typical GIS
format then an export step is required.

Typically hootenanny conflates the data using one of three intermediate file
formats:

* `.osm` The standard OSM XML file format. This is easy to read and is usable my
  many OSM tools, but can create very large files that are slow to parse.
* `.osm.pbf` A relatively new OSM standard that uses Google Protocol Buffers
  <<google2013>> to store the data in a compressed binary format. This format is
  harder to read and supported by fewer OSM tools but is very fast and space
  efficient.
* Hootenanny Services Database - This is used by the Hootenanny services to
  support the Web Interface. This is convenient for supporting multiple ad-hoc
  requests for reading and writing to the data, but is neither very fast nor
  very space efficient.

Despite the potential for some minor changes to data precision (see
<<hootuser>>, _Sources of Processing Error_ for details), these formats maintain
the full richness of the topology and tagging structure.

Hootenanny also uses GDAL/OGR footnote:[http://www.gdal.org/] for reading and
writing to a large number of common GIS formats. Only Shapefile, PostGIS and
FileGDB are tested, but others may also work. Using this interface Hootenanny
can either automatically generate a number of files for the common geometry
types, or the user can specify an output schema and translation. See the _OSM to
OGR Translation_ section for details.

See also:

* <<OSM-to-OGR-Translation,OSM to OGR Translation>>
* <<File-Formats,File Formats>>
* <<convert,convert command>>

