
== Using Validation Checks to Improve Conflated Maps

It is quite easy to produce conflated map output that initially seems accurate but upon further 
examination has quality issues. https://josm.openstreetmap.de/[JOSM] has an extensive collection of 
validation tools that can be used to detect such issues. Hootenanny is integrated with 
https://josm.openstreetmap.de/[JOSM] via the 
https://en.wikipedia.org/wiki/Java_Native_Interface[Java Native Interface (JNI)]. This allows 
Hootenanny C++ core code to invoke JOSM validators by making calls into its Java code. The 
integration code resides in the `hoot-josm` library and is used by the `validate` command, which 
uses the `JosmMapValidator` class, and the `JosmMapCleaner` class.

=== Generating Validation Reports

The Hootenanny/JOSM integration is a useful tool to detect undesirable changes to conflated output 
caused by code changes before they make it to the production environment. The `validate` command 
provides the capability for running validation checks on selected conflated output after it has been 
generated by `HootTest`. Here is an example:
-----
# Generate some conflate output. Here a case test is used to do it.
HootTest --slow '--include=.*AreaConflateStandaloneTest.*'
# Now, generate the validation report for the same test using the test output previously generated 
# in the test-output directory.
hoot validate test-output/cmd/slow/AreaConflateStandaloneTest/Output.osm \
  --report-output=test-output/cmd/slow/AreaConflateStandaloneTest/MyValidationReport
-----

`validate` as used above will generate a single validation report at the specified report output 
location with multiple entries for each test output geospatial file encountered in the input 
directory.

Notes:

* Not all validation failures are critical and some may be unavoidable in conflated output under 
certain circumstances.
* Validation failures from multiple validators are sometimes contradictory with each other.
* "Total failing validators" in the validation reports refer to the number of validators which 
exited program execution abnormally due to not being able to properly validate the input data 
provided. It does not refer to the number of validators which had validation errors. That total can
be inferred from the total number of unique validation error types that occurred.


=== Unit Test Integration

To enable validation during testing, enable the `test.validation.enable` configuration option within 
the `Testing.conf` configuration file. Currently, only the case tests have their output validated 
(that may change). TODO: finish

TODO: .off file, script properties, etc






