
[[RoadConflation]]
=== Road Conflation

==== Unifying Roads Algorithm

This section describes conflating roads with the Unifying Roads Algorithm, which is machine 
learning based. Roads may also be conflated with the Network Roads Algorithm, which uses a graph 
based approach. See the Network Roads Algorithm section in this document for more information.

Road Conflation refers to conflating all road-like linear transportations
features. The list of road-like features includes:

* Typical roads (residential, primary, secondary, motorway, etc.)
* Roads with bridges
* Roads with tunnels
* Paths (footpath, cycleway, bridleway, etc.)
* Cart tracks

This does not include other linear features such as railways, rivers and walls.

The following sections discuss the approach used to conflate roads. To see how
this fits within the larger conflation picture please see the
<<UnifyingConflation,Unifying Conflation>> section.

===== Road Match Candidate

Like other conflation types within unifying conflation the road types first
identify all candidate matches. This process is described in pseudocode below.

[[RoadMatchCandidatePseudocode]]
.Road Match Candidate Pseudocode
[source,python]
-----
# Go through all the roads in the first input
for road1 in input1:
  # get the circular error of the current road
  ce = road.getCircularError();
  # get all the neighbors that intersect the current road's envelope + ce.
  neighbors = findAllElements(road.envelope().expandBy(ce));
  # go through all the neighbors
  for n in neighbors:
    # if it is a legit road
    if n != road1 && n.isLinearHighway() && n.isFromSecondInput():
      # do a thorough check for a match. See below
      m = new HighwayMatch(road1, n);
      if m.getType() != miss:
        result.add(m);
-----

The `findAllElements` function above uses the internal Hilbert R-Tree
<<kamel1993>> index to limit the number of candidates based on the distance.
This provides _O(M log~M~n)_ average query performance where _M_ is the number
of children at each level.

The astute reader may notice that the circular error of the second input is not
being accounted for when searching the R-Tree for neighboring elements. The
elements in the R-Tree contain the envelope of the element buffered by the
circular error. This creates an efficient way to query out only the elements
whose envelopes are within `ce1` + `ce2` distance.

As mentioned in the <<RoadConflationFutureWork,Future Work>> section below,
building an index made up solely of candidate roads may be more efficient than
searching the larger, existing index. This may be especially true if the map
contains many non-road types such as buildings and rivers.

NOTE: As of 12/9/2014, _M_ is 20 in Hootenanny

===== Road Matching Criteria

All candidate matches as determined using the method described above are
evaluated further for the associated match score. This is depicted by the
`HighwayMatch` class in <<RoadMatchCandidatePseudocode>>. Within this class the
road match is further evaluated to determine the match relationship.

[[RoadMatchingFlow]]
.Road Matching Flow
[graphviz, images/__RoadMatching.png]
---------------------------------------------------------------------
digraph G
{
rankdir = LR;
node [shape=record,width=2,height=1,style=filled,fillcolor="#e7e7f3"];
review [label = "If Needs\nReview",shape=diamond,height=1.5];
addreview [label = "Add Review\nExplanation"]
{ rank = same; "Done"; addreview };
"Determine Matching\nSublines" -> "Classify the Match";
"Classify the Match" -> review;
review -> addreview [tailport=e, label = "yes"];
review -> "Done" [tailport=s, label = "no"];
addreview -> "Done";
}
---------------------------------------------------------------------

*_Determine the Matching Subline_*

Before two lines can be classified as a match, the matching subline must be
determined. In the simplest case both of the lines match in their entirety.
However, we must also handle the cases when there is only a partial match. The
details of determining a subline match will be addressed in another section.

At a high level the subline matching routines use the distance between the lines
and the difference in angle between the lines to determine what portion of the
subline match.

See also:

* `way.matcher.heading.delta` configuration option, <<hootuser>>
* `way.matcher.max.angle` configuration option, <<hootuser>>
* `way.subline.matcher` configuration option, <<hootuser>>
* `way.subline.string.matcher` configuration option, <<hootuser>>

[[ClassifyTheMatch]]
*_Classify the Match_*

The match relationship is determined using a trained Random Forests
<<breiman2001>> classifier. The model is trained using the following manually
matched highway data:

* <<MGCP,MGCP>> matched to <<OpenStreetMap,OpenStreetMap>> - Laascaanood, Somalia
** 174km of roads
** 184 road features
* <<MGCP,MGCP>> matched to <<OpenStreetMap,OpenStreetMap>> - Beledweyne, Somalia
** 15km of roads
** 66 road features
* <<MGCP,MGCP>> matched to <<UFD,UFD>> - Hargeysa, Somalia
** 144km of roads
** 464 road features
* <<OpenStreetMap,OpenStreetMap>> matched to <<UFD,UFD>> - Hargeysa, Somalia
** 93km of roads
** 1,155 road features
* <<MGCP,MGCP>> matched to <<OpenStreetMap, OpenStreetMap>> - Port au Prince, Haiti
** 562km of roads
** 1,258 road features

The manually matched data is then broken into three groups:

* All data
* Training group 1 - Half of the data
* Training group 2 - Half of the data that does not overlap with Training group
  1.

The two training groups are used to train and test a model without using
training data for the testing data. (AKA 2-fold cross validation) By using such
coarse testing groups it simplifies the testing process and avoids using data
from a single geographic region for both training and testing.

After evaluation is complete all the data is used to train the final model that
is utilized by Hootenanny. The trained model is stored in the Hootenanny source
tree as `conf/HighwayModel.rf`. The trained model uses the following features
for classification:

* Edge distance with <<RMSE,RMSE>> aggregation - Edge distance samples each
  input feature at regular intervals and calculates the distance between those
  each sample. The aggregator is used combine all the distance measures into a
  single feature. In this case the aggregator is RMSE.
* Edge distance with http://en.wikipedia.org/wiki/Standard_deviation[standard
  deviation] aggregation - Similar to above, but the aggregator is the standard
  deviation of the distance samples.
* Angle Histogram (taken from RoadMatcher) - Creates a histogram of the angles
  of each input and then calculates the difference between those histograms.
* Weighted Metric Distance with RMSE aggregation - Similar to metric distance
  described in <<savary2005>>.

The features above were determined by using various feature selection techniques
within Weka <<hall2009>>. Approximately 50 different feature extraction
approaches were evaluated. Many of those were simply parameterized versions of
11 different extraction approaches. The features evaluated include:

* Name comparison - using various combinations of comparison techniques and
  distance algorithms including:
** Treat name as a bag of words
** Translate/transliterate the names before comparison
** Exact string match
** http://en.wikipedia.org/wiki/Levenshtein_distance[Levenshtein distance]
   <<levenshtein1966>>
** http://en.wikipedia.org/wiki/Soundex[Soundex]
* Hausdorff distance
* Attribute distance
* Attribute score
* Distance score
* Weighted shape distance <<savary2005>>

NOTE: If you would like more details on any of these feature extracting
techniques please create an issue at the https://github.com/ngageoint/hootenanny[Hootenanny GitHub page].

The model is trained on all three relationship types: match, miss and review.
The classification generated by the model is used directly for determining the
match type. See <<EstimatePairwiseRelationships>> for a description of how the
relationship scores are resolved into a single relationship value.

*_Add Review Explanation_*

In addition to the reviews generated using the classifier, sometimes line
matches are either too computationally complex to establish, or simply too
complex to definitively mark as being either a match or miss. In these cases the
features will be marked as needing a review.

Examples where these situations may occur include:

* Invalid geometries (e.g. `multilinestring` relation that contains nodes)
* MultiLineStrings:
** Star pattern
** Parallel lines within a MultiLineString
** MultiLineStrings with too man sublines (computationally complex)

If these situations occur the review will contain a description of the issue
encountered in the `hoot:review:note` tag.

===== Road Conflict Criteria

Two road matches are considered conflicts if applying one of the resulting
merges causes the other match to be a non- _match_. This usually occurs if
applying one match does not leave enough of the feature left over to apply the
other match though it could also occur if the remaining portion of the feature
could be matched, but results in a _miss_ or _review_ classification.

===== Road Merging Logic

The legacy road conflation routine (no longer available) supported road averaging by default. The
newer unifying road conflation routine only supports snapping roads together. In
this case it means snapping the roads from the second input to the first input.
Besides breaking roads where necessary, the first input will not be moved.

Tags are merged using the default tag merging approach as defined by the
`tag.merger.default` configuration option.

See also:

* `tag.merger.default` configuration option <<hootuser>>

===== Median To Divided Highway Matching

Road conflation has an alternate workflow that allows for transferring selected tags from single
secondary road median features to associated reference divided roads (dual carriageways). The 
configuration option which enables median to divided road matching is 
`highway.median.to.dual.highway.match`. The configuration option that identifies features as road 
medians is `highway.median.identifying.tags`. If a feature has any tag in the option's list, it will 
be considered a road median feature. 

In this workflow, median to divided road merging is done with tags only. No geometry merging is
performed. The keys of the tags transferred from secondary medians to reference divided roads are 
identified in `highway.median.to.dual.highway.transfer.keys`.

[[NetworkConflation]]
==== Network Roads Algorithm

This document describes conflating roads with the Network Roads Algorithm, which uses a graph based 
approach. Roads may also be conflated with the Unifying Roads Algorithm, which uses a machine 
learning based approach. See the Unifying Roads Algorithm section within this document for more 
information.

The Network Algorithm is theoretically capable of conflating any type of linear feature. At this
time, Hootenanny only uses it with road features. If this ever changes, this documentation should be
relocated and expanded.

In the <<UnifyingConflation,unifying>> and greedy implementations of road conflation line matching
 information is limited to the lines being matched and in some cases the immediate
 neighbors and intersections. Once match relationships have been established between roads the
 set of matches that persist is established by searching the match candidates for a non-conflicting
 set that maximizes a score. Unfortunately, this optimization at all costs approach can be
 problematic when a road in input1 can match two roads in input2 equally well. When this happens
 one of the matches will persist to increase the overall score even though it should likely be
 treated as a review.

Network conflation treats the two input maps as a network or graph of roads and intersections. This
 allows a more holistic approach to the optimization stage of conflation where we can use nearby
 matches to inform match candidates as well as flag ambiguous situations as reviews. The holistic
 approach also dramatically reduces the number of multi-linestrings produced during the merge phase
 of conflation.

The network conflation work-flow is broken into a series of stages. These stages will be discussed
 in more detail below.

1. Convert the OSM node/way/relation data structure into an edge/vertex network.
2. Establish vertex match candidates and confident matches.
3. Establish edge match candidates.
4. Refine match candidate scores.
5. Label candidate matches.
6. Apply merge operations.

While this approach could be generalized to any network (e.g. pipelines, railways or rivers) the
 current implementation focuses specifically on road networks that include roads, cart tracks,
 bridges, tunnels and other similar types.

===== Convert the OSM Map to a Network

The OSM map already contains enough information in the node/way/relation structure to establish
 network relationships. During this stage of the operation we simplify the information
 presented in the OSM map into edges and vertices. We only evaluate elements that are of the
 appropriate type (e.g. roads). Any node that is at the endpoint of a way has a corresponding
 vertex created. All ways have a corresponding edge created that connects two vertices at its
 endpoints. The map is not altered during this process.

===== Establish Vertex Match Candidates

The second stage in network conflation is matching vertices. This is an important aspect to the
 quality of the network match. Omitting a valid vertex match from the match candidates will ensure
 an error, but creating too many vertex match candidates dramatically increases the complexity of
 the problem which will increase both compute time and errors.

Utilizing the tie point matching techniques established in Rubber Sheeting scores
 are applied to all the match candidates. Confident tie points are a special form of a vertex match.
 This uses the same confident tie point definition and calculation as is used in
 Rubber Sheeting. By establishing confident tie points we can eliminate significant
 portions of possible match situations which improves overall match quality and reduces computation.
 If a confident tie point is established then all other vertex matches associated that overlap with
 a confident tie point are removed. In other words, if vertex `A` and vertex `B` is a
 confident tie point (`AB`) and `AC` is a vertex match candidate then `AC` will be removed as it
 conflicts with a confident tie point. The math associated with confident tie points is such that
 two confident tie points cannot overlap.

===== Establish Edge Match Candidates

Edge match candidates are established by iterating over all edges in the first network and
 comparing those edges to edges in the second network. An R-Tree index is used speed the search
 process. If two edges are determined to be within the required search radius the two edges are the
 further evaluated for a match.

In the simplest case both ends of the edge will have matching vertices and the whole edge will be
 within the specified search radius and angular difference. If this is the case, we have complete
 1:1 match and the search is over. However, most of the complexity of finding edge match candidates
 occurs in the more complex cases, such as 1:m, n:m and partial matches.

If the edges do not end at a vertex match new edges are added on to the match recursively in
 both directions until the both ends of the match are found. The end may be either a partial
 match, or a matching vertex. To keep computational complexity down no more than 20 edges will be
 added to the match before the algorithm will stop searching. While this may result in unmatched
 edges in very complex situations the compute time is reduced dramatically.

===== Refine Match Candidate Scores

Over time multiple approaches to refining scores were evaluated. A short description of each
 approach will be presented here as well as a long description of the best performing "Conflicts
 Matcher".

. Vagabond Network Matcher - The idea presented behind this approach is that you can simulate an
 actor (vagabond) randomly walking between matched pairs across the network. The more often the
 vagabond traverses a matched pair the more likely that pair is to be a valid match. Unfortunately
 this approach failed to converge on a many common cases and closely resembled a greedy approach in
 some cases.
. Iterative Matcher - Iteratively assign a score from each edge to all its matching pairs from input
 1 to input 2, then conversely from input 2 to input 1. Also perform this for each vertex. Once
 complete combine these score into a single value for each edge and vertex. This worked well in many
 cases, but became cumbersome to improve and maintain due to all the special cases.
. Single Sided Network Matcher - In this case rather than scoring in both directions like the
 iterative approach, a single sided matching was performed from input 1 to input 2. This succeeded in
 simplifying the code, but the performance wasn't acceptable in many common cases.
. Conflicts Network Matcher - This proved to be the most successful approach and incidentally has
 many analogies with <<UnifyingConflation,unifying>>. In this approach we do not score vertices in
 any meaningful way, but score edges. Each edge match is marked as either supporting or conflicting
 with its neighboring matches and by using that support/conflict information we are able to improve
 or reduce an edge's score.

Several other variations on each of these approaches were also explored, but they came and went
 quickly and are not worth discussing here.

*_Conflicts Network Matcher_*

Similar to the other matching techniques, the conflicts network matcher first identifies candidate
 vertex matches and edge matches. There is a special case where an intersection may match a short
 segment of road. These are referred to as stub matches and are discussed in more detail below. A
 summary of the Conflict Network Matcher specific steps is below:

1. Establish support and conflict relationships between matches.
2. Seed edge scores.
3. Iteratively adjust scores until they converge or reach another stopping criteria.
4. Assign relationships to scored matches.

_Establish Relationships_

After edge matches have been established each match is evaluated to determine which matches it
 supports (e.g. shares an intersection) and which matches are conflicting (applying two
 conflicting matches would be illegal). These values are recorded in an index for easy retrieval.

_Stubs_

Stubs are introduced during the edge matching phase to represent situations where small road
 segments match an intersection.

Unfortunately this can introduce a large amount of complexity in some situations as the number of
 possible options goes up significantly. To help counteract this problem stub matches are given a
 lower weight than other matches. More details are available below in the _Iteratively Adjust
 Scores_ section.

_Seed Edge Scores_

All candidate edge matches are seeded with a score of 1. In the future it may make sense to seed
 with a score that more directly relates to probability of a match or similar, but for now a value
 of 1 seems to work well enough.

_Iteratively Adjust Scores_

In each iteration the previous scores are stored and a new set of scores are calculated. The new
 score is calculated as follows:

x - The match we are scoring.
y~i~ - One of the neighboring matches (either supports or contradicts)
s~o~ - old score for x.
s~n~ - new score for x.
partialHandicap - The handicap applied if `x` is a partial match.
 `network.conflicts.partial.handicap`
W(m) - A weighting method that determines the relevance of a neighbor.
SW(m) - If the two neighbors aren't directly connected, but connected by a stub. Return
 the highest weight of all the stubs that connect the two matches. Otherwise, return 1.
stubThrough - `network.conflicts.stub.through.weighting`, defaults to 0.59

At this point 10 iterations are executed of score adjustments before the scores are accepted. In the
 future it may be worth experimenting with dynamically running the converging process. For example,
 if the largest score change is less than a threshold then stop iterating. In a number of
 small real-world datasets 10 iterations is enough to converge.

===== Label Candidate Matches

After match candidate scores have been refined a new match record is created for all matches

===== Apply Merge Operations

After match records have been created, features involved in matches are then merged.


[[RoadConflationFutureWork]]
==== Future Work

* Creating a custom index (rather than using the global index) will likely be faster.
* There has been discussion around creating a new conflation approach that uses collective 
classifiers with intersections to improve performance.
* Expand the training data to include a more diverse set of regions and input types.

