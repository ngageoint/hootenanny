

=== Approach & Assumptions

Hootenanny is designed to facilitate automated and semi-automated conflation of
critical Foundation GEOINT features in the topographic domain, namely roads (polylines),
buildings (polygons), and points-of-interest (POIs) (points). While a number of
small tools are built into the suite for file conversion and evaluation, the main
function of Hootenanny is to take two input files and produce a single conflated
output file.

Conflation happens at the dataset level, where the user’s workflow determines the
best reference dataset and source content, geometry and attributes, to transfer to
the output map. The input data must be normalized to allow processing and matching
of features and attributes from different schemas. Hootenanny internal processing
leverages the key value pair structure of OpenStreetMap (OSM) for improved utility
and applicability to broader user groups, e.g. normalized attributes can be used
to aid in feature matching and OSM’s free tagging system allows the map to include
an unlimited number of attributes describing each feature (OpenStreetMap/Map Features, 2015).

Hootenanny is designed from the ground up to properly handle topology as well as
a standard set of attributes and unique data model of the OpenStreetMap (OSM)
data format. To accommodate these requirements, Hootenanny requires that all
data be provided in the OSM format and schema. This provides many benefits to
internal data structure and assumptions that can be made within algorithms.
However, it also adds challenges to data preparation and conversion, which we
discuss in <<HootExplFileConversion>>.

Further, we have limited the scope to pairwise conflation operations. More than
two data sets can be merged by performing multiple pairwise operations; however,
limiting the scope to deal with two data sets at a time dramatically reduces
algorithmic complexity in some situations.

No attempt has been made to accurately handle data that spans the anti-meridian
(International Date Line) or data at the poles. An approach for handling the
anti-meridian problem is proposed in <<HootExplFutureWork>>.

[[HootConflationWorkflow]]
==== Conflation Workflow

The general case of the Hootenanny conflation workflow is shown in <<HootConflationWorkflowDiagram>>
and depicts the high-level steps necessary to conflate data and generate an output
map in Hootenanny. It is important for the user to understand these functions as
each have implications on the conflated results. The squares represent a specific
conflation task, while the oval canisters represent a database function. The
workflow is described as follows:

[[HootConflationWorkflowDiagram]]
.Hootenanny Conflation Workflow.
image::images/hoot_general_workflow.png[]

[[HootExplFileConversion]]
==== File Conversion

Before any data set is used by Hootenanny, it must be converted to the OSM
format and schema. In the case of FACC data this means performing conversions
such as:

.*FACC to OSM Conversion*
[width="40%"]
|======
| *FACC* | *OSM*
| RST=1 | surface=paved
| TUC=37 | highway=path, horse=designated
| MCC=73 | surface=pebblestone
|======

FACC to OSM conversions can become quite complex depending on how the FACC
specification was interpreted by the digitizer and on subtle interactions
between FACC fields that impact one or more OSM tags. Despite this complexity,
the OSM schema is rich enough to accommodate most FACC fields. In some cases,
we've introduced new non-standard tags into the OSM schema to handle more
obscure tags such as `building:shape=with_cupola` and some military specific
tags.

As part of Hootenanny, we have implemented a _shp2osm_ conversion tool that uses
simple python scripts to convert tags while performing the file format
conversion. This tool is based heavily on the work done in convert-ogr2osm.py (Ortega,
2012) but fixes several bugs, improves performance, and provides intersection
matching of nodes that are at nearly the same location.

When conflation is complete, a similar process can be performed to export the
data to other formats such as File Geodatabase with the FACC or NFDD schema.

NOTE: Hootenanny allows users to append new non-standard tags to OSM schema in
order to retain unique values from input data sets.

==== Conflation

Hootenanny provides both a web based User Interface and command line interface
for performing data manipulations and conflation. While there are tunable
parameters that can be set, all the conflation steps are fully automated.

[[ExplDataCurrency]]
==== Data Currency

While merging two data sets that represent the same world is difficult, merging
two data sets that represent the world at different times is significantly
harder. This increase in complexity comes mainly from a lack of metadata
describing when the feature was current and, more importantly, marking features
as removed rather than removing them without notation. This is most easily
described with an example:

Given two data sets, A & B, if we do not know when the data sets were created,
and Feature _x_ exists in A but does not exist in B, there are the following
possibilities:

1. B has incomplete data, and _x_ was not properly mapped
2. A has extra erroneous data, and _x_ was not properly mapped
3. _x_ was created after B was digitized
4. _x_ was removed before B was digitized

While any one of these scenarios could be true, incomplete data is by far the
most common. For this reason, in almost all scenarios when we find an unmatched
feature, we assume that the other data set is incomplete and keep the feature.

