
=== Existing Technology

==== NGA R&D Framework Paper 

In 2009, the National Technology Alliance prepared a paper titled "Fusion in an
R&D environment" (National Technology Alliance, 2009)for the NGA.  This paper
highlights:

* A R&D roadmap for multi-source, multi-modal data fusion, a major component of
  which is conflation of vector datasets. 
* A functional analysis of conflation techniques
* A comprehensive census of existing conflation tools

This paper provided valuable context and direction to this effort.

==== Variants of Conflation

There are three main forms of Conflation:

* Raster-to-raster conflation – rectifies differences in georeferenced rasters
* Raster-to-vector conflation – matches raster and vector data to improve the
  georeferencing of the vector or raster data
* Vector-to-vector conflation – matches vector-to-vector to improve the data in
  one or both vector data sets

NOTE: Hootenanny is currently focused on vector-to-vector conflation.

===== Conflation implementation

Vector conflation can be executed in two ways: fused and related.  From a
conventional standpoint, the conflation of vector datasets is implemented by
correlating one or more overlapping datasets to produce a unified database that
contains the best available geometry and attributes (National Technology
Alliance, 2009), (Linna Li, 2011).  The results of this method are typically
easier to manage and can be used to produce better maps in a straightforward
fashion, in addition to providing a better baseline for analytic functions such
as routing and geocoding.  Edwards and Scott presented a concept that uses
feature matching/correlation while maintaining a feature-level relationship
between datasets, rather than merging the datasets into one (Edwards, 2002).
Such an approach has a less destructive impact on the original data whereby the
geometry and attributes are not merged, but instead the matching features
between datasets are related to one another through a database relationship.

===== Conflation across multiple dimensions

Geometry matching is closely associated with feature matching in the conflation
process.  In this type of processing, features are considered similar based on
proximity, orientation, or even topology.  In most cases, geometric processing
provides a reasonable link between similar geographic features, but there are
cases where geometry alone cannot distinguish between a railroad and a highway
that run parallel to each other.  Given this possibility, Sehgal suggests
implementing multi-dimensional feature matching, specifically combining
geometric matching to feature attributes and names (Sehgal, 2006).

===== Attributes/Semantics/Ontology

Feature attributes and related semantic/ontological relationships can be used to
correlate features between two datasets to extend geometry capabilities. 
According to Adams et al (2010) "More recently the matching of the semantics of
geospatial features has been identified as a key component of the conflation
problem" (Adams Benjamin, 2010)In particular, this technique would help weed out
possible matches that could link very different features to each other (i.e., a
highway to a railroad).

_Formal name variants_

In cases where formal names exist for features, their similarities can be used
to link features to each other. Linna Li, 2011 and Sehgal, 2006 suggest using
Levenshtein distance (VI, 1966) to measure the closeness of feature names, then
merging these similarities into the scores that characterize the geometric
similarities.

==== Potential Contributions to the Conflation R&D Agenda

National Technology Alliance suggests a need for "… a service-oriented
architecture to call conflation functions from other data fusion software via
open interfaces" (National Technology Alliance, 2009). Such services would
enable conflation capabilities to be widely available in conjunction with common
desktop Geographic Information Systems (GIS) applications.  With this potential
comes an increased need for performance and scalability.    To support this
requirement, large conflation jobs can be divided into smaller components and
addressed and processed in parallel (Linna Li, 2011). Such an approach would
lend itself well to modern cloud computing techniques that are designed to
operate on discrete tasks in parallel.

