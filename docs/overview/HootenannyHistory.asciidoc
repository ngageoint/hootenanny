
=== Hootenanny History

The purpose of this research is developing a fully automated conflation
capability that scales to support big geographic datasets. The rationale is that
such a conflation capability could create a consolidated data set that leverages
feature content from diverse inputs without involving expensive manual conflation.
While the quality of the output will not be the same as manually conflated data,
the cost should be much lower and the quality good enough for many uses.

Hootenanny was spawned out of the need for a fully automated conflation capability to support an effort to load a mix of national and city scale datasets. The rationale is that
such a conflation capability could create a consolidated data set that leverages
feature content from diverse inputs without involving expensive manual conflation. While the quality of the output will not be the same as manually conflated data,
the cost should be much lower and the quality good enough for many uses. 

While ingesting customer data, it quickly became apparent that multiple data sets contained redundant data that was being rendered as duplicated geometries and exported in a similar fashion. Developing a set of automated/semi-automated conflation tools became a consistent discussion topic spawning the evolution of the Hootenanny. During the process, the need to support an array of customer specific data schemas in addition to OSM became quickly apparent which gave rise to another capability which was the ability to translate data between different product standard schemas such as the Multinational Geospatial Co-production Program (MGCP) TRD3&4, NSG Topographic Data Store (TDS) v4.0, v. 6.1, and OSM. 

We have since matured the product into a stand-alone web-based application that sits on top of an extensible set of core conflation algorithms and data translation tools, which are accessed via Node.js and REST services.

==== Phase I

Following discussions related to the Perty evaluation, funding was allocated through NGA's InnoVision to further the development of Hootenanny. This development funded the R&D necessary to take Hootenanny from a research tool to a demonstrable tool that could be used by users. The majority of the work centered around RESTful and OGC web services, modifying the iD UI for conflation, translation of additional data sets and increasing conflation performance and features.

==== Phase II

On September 1, 2014 Phase II began with the focus on enhancing the usability of Hootenanny, integrating with other systems and increasing the breadth of features that can be conflated. One of the central goals of this phase was to release Hootenanny to the Open Source community, which occurred in June 2015.

==== Beyond Phase II To Present Day

Hootenanny has since transitioned into NGA's production environment as part of the NGA Open Mapping 
Enclave (NOME) project. It exists as NOME's main geodata conflation tool and sits besides several
other mostly open source and mostly OpenStreetMap influenced software tools.

